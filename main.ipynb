{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOptxgB+cwla4Yy+M4HhQa4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nV3lTg_3uKq",
        "outputId": "08194fd9-c49d-4ddd-e770-1edacfbdd92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "drive.mount('/content/drive')\n",
        "API_KEY = userdata.get('API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fredapi\n",
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ZIRwnu4kd8",
        "outputId": "1107803c-e3c9-4966-db8c-ac3972ba653c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fredapi in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fredapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AijC_5G6d77V",
        "outputId": "24407e06-dcdb-4064-c9ce-33f7c1f644f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fredapi as fa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "import pickle\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "brier_score_loss, roc_auc_score, precision_recall_fscore_support, recall_score, make_scorer, precision_score, precision_recall_curve, PrecisionRecallDisplay, f1_score, average_precision_score)\n",
        "import sklearn.model_selection as skm\n",
        "from sklearn.decomposition import PCA, FactorAnalysis, SparsePCA\n",
        "from statsmodels.multivariate.pca import PCA as smPCA\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.tree import (DecisionTreeClassifier as DTC, plot_tree, export_text)\n",
        "from sklearn.metrics import (accuracy_score)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA)\n",
        "from imblearn.pipeline import Pipeline\n",
        "import xgboost as xgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import shap\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy.stats import randint, uniform\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "wrZZj7gA4Kun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup\n",
        "### Loading"
      ],
      "metadata": {
        "id": "aN8XIq5P5wiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars_raw = pd.read_csv('/content/drive/MyDrive/Diffusion Indices/2025-04-MD.csv')\n",
        "all_vars_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "tmBpIq_q4iCu",
        "outputId": "4ac05bf2-0501-4a1a-d254-d86b6e0852f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sasdate        RPI  W875RX1  DPCERA3M086SBEA     CMRMTSPLx  \\\n",
              "0    Transform:      5.000      5.0            5.000  5.000000e+00   \n",
              "1      1/1/1959   2583.560   2426.0           15.188  2.766768e+05   \n",
              "2      2/1/1959   2593.596   2434.8           15.346  2.787140e+05   \n",
              "3      3/1/1959   2610.396   2452.7           15.491  2.777753e+05   \n",
              "4      4/1/1959   2627.446   2470.0           15.435  2.833627e+05   \n",
              "..          ...        ...      ...              ...           ...   \n",
              "791   11/1/2024  20091.169  16376.8          122.396  1.545040e+06   \n",
              "792   12/1/2024  20101.629  16387.7          123.077  1.558008e+06   \n",
              "793    1/1/2025  20148.969  16391.2          122.614  1.543178e+06   \n",
              "794    2/1/2025  20209.351  16389.5          122.742  1.556553e+06   \n",
              "795    3/1/2025  20311.260  16500.4          123.601           NaN   \n",
              "\n",
              "          RETAILx    INDPRO   IPFPNSS   IPFINAL   IPCONGD  ...  \\\n",
              "0         5.00000    5.0000    5.0000    5.0000    5.0000  ...   \n",
              "1     17689.23968   21.9616   23.3868   22.2620   31.6664  ...   \n",
              "2     17819.01912   22.3917   23.7024   22.4549   31.8987  ...   \n",
              "3     17967.91336   22.7142   23.8459   22.5651   31.8987  ...   \n",
              "4     17978.97983   23.1981   24.1903   22.8957   32.4019  ...   \n",
              "..            ...       ...       ...       ...       ...  ...   \n",
              "791  712145.00000  101.9619   99.3808   98.8609  100.8691  ...   \n",
              "792  717662.00000  103.1177  100.4976   99.9719  101.6868  ...   \n",
              "793  711461.00000  103.3418  101.0766  100.6319  102.1879  ...   \n",
              "794  711680.00000  104.2202  101.8233  101.4377  102.7245  ...   \n",
              "795  722025.00000  103.8892  101.6665  101.1465  101.7332  ...   \n",
              "\n",
              "     DNDGRG3M086SBEA  DSERRG3M086SBEA  CES0600000008  CES2000000008  \\\n",
              "0              6.000            6.000           6.00           6.00   \n",
              "1             18.294           10.152           2.13           2.45   \n",
              "2             18.302           10.167           2.14           2.46   \n",
              "3             18.289           10.185           2.15           2.45   \n",
              "4             18.300           10.221           2.16           2.47   \n",
              "..               ...              ...            ...            ...   \n",
              "791          119.230          129.380          31.59          36.26   \n",
              "792          119.746          129.875          31.72          36.43   \n",
              "793          120.457          130.281          31.91          36.56   \n",
              "794          120.615          130.990          32.00          36.66   \n",
              "795          119.760          131.192          32.21          36.79   \n",
              "\n",
              "     CES3000000008  UMCSENTx  DTCOLNVHFNM   DTCTHFNM     INVEST  VIXCLSx  \n",
              "0             6.00       2.0         6.00       6.00     6.0000   1.0000  \n",
              "1             2.04       NaN      6476.00   12298.00    84.2043      NaN  \n",
              "2             2.05       NaN      6476.00   12298.00    83.5280      NaN  \n",
              "3             2.07       NaN      6508.00   12349.00    81.6405      NaN  \n",
              "4             2.08       NaN      6620.00   12484.00    81.8099      NaN  \n",
              "..             ...       ...          ...        ...        ...      ...  \n",
              "791          28.22      71.8    556011.41  938335.20  5381.4576  15.9822  \n",
              "792          28.33      74.0    559364.75  943484.76  5366.6686  15.6997  \n",
              "793          28.58      71.7    559087.09  944167.06  5350.2541  16.8122  \n",
              "794          28.68      64.7    556142.06  941199.49  5367.9408  17.0705  \n",
              "795          28.92      57.0          NaN        NaN  5406.5887  21.6579  \n",
              "\n",
              "[796 rows x 127 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dbf1af4-f17a-4909-ba3a-501b27bb0a23\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sasdate</th>\n",
              "      <th>RPI</th>\n",
              "      <th>W875RX1</th>\n",
              "      <th>DPCERA3M086SBEA</th>\n",
              "      <th>CMRMTSPLx</th>\n",
              "      <th>RETAILx</th>\n",
              "      <th>INDPRO</th>\n",
              "      <th>IPFPNSS</th>\n",
              "      <th>IPFINAL</th>\n",
              "      <th>IPCONGD</th>\n",
              "      <th>...</th>\n",
              "      <th>DNDGRG3M086SBEA</th>\n",
              "      <th>DSERRG3M086SBEA</th>\n",
              "      <th>CES0600000008</th>\n",
              "      <th>CES2000000008</th>\n",
              "      <th>CES3000000008</th>\n",
              "      <th>UMCSENTx</th>\n",
              "      <th>DTCOLNVHFNM</th>\n",
              "      <th>DTCTHFNM</th>\n",
              "      <th>INVEST</th>\n",
              "      <th>VIXCLSx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Transform:</td>\n",
              "      <td>5.000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.000</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>6.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>6.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/1959</td>\n",
              "      <td>2583.560</td>\n",
              "      <td>2426.0</td>\n",
              "      <td>15.188</td>\n",
              "      <td>2.766768e+05</td>\n",
              "      <td>17689.23968</td>\n",
              "      <td>21.9616</td>\n",
              "      <td>23.3868</td>\n",
              "      <td>22.2620</td>\n",
              "      <td>31.6664</td>\n",
              "      <td>...</td>\n",
              "      <td>18.294</td>\n",
              "      <td>10.152</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.45</td>\n",
              "      <td>2.04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6476.00</td>\n",
              "      <td>12298.00</td>\n",
              "      <td>84.2043</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2/1/1959</td>\n",
              "      <td>2593.596</td>\n",
              "      <td>2434.8</td>\n",
              "      <td>15.346</td>\n",
              "      <td>2.787140e+05</td>\n",
              "      <td>17819.01912</td>\n",
              "      <td>22.3917</td>\n",
              "      <td>23.7024</td>\n",
              "      <td>22.4549</td>\n",
              "      <td>31.8987</td>\n",
              "      <td>...</td>\n",
              "      <td>18.302</td>\n",
              "      <td>10.167</td>\n",
              "      <td>2.14</td>\n",
              "      <td>2.46</td>\n",
              "      <td>2.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6476.00</td>\n",
              "      <td>12298.00</td>\n",
              "      <td>83.5280</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3/1/1959</td>\n",
              "      <td>2610.396</td>\n",
              "      <td>2452.7</td>\n",
              "      <td>15.491</td>\n",
              "      <td>2.777753e+05</td>\n",
              "      <td>17967.91336</td>\n",
              "      <td>22.7142</td>\n",
              "      <td>23.8459</td>\n",
              "      <td>22.5651</td>\n",
              "      <td>31.8987</td>\n",
              "      <td>...</td>\n",
              "      <td>18.289</td>\n",
              "      <td>10.185</td>\n",
              "      <td>2.15</td>\n",
              "      <td>2.45</td>\n",
              "      <td>2.07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6508.00</td>\n",
              "      <td>12349.00</td>\n",
              "      <td>81.6405</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4/1/1959</td>\n",
              "      <td>2627.446</td>\n",
              "      <td>2470.0</td>\n",
              "      <td>15.435</td>\n",
              "      <td>2.833627e+05</td>\n",
              "      <td>17978.97983</td>\n",
              "      <td>23.1981</td>\n",
              "      <td>24.1903</td>\n",
              "      <td>22.8957</td>\n",
              "      <td>32.4019</td>\n",
              "      <td>...</td>\n",
              "      <td>18.300</td>\n",
              "      <td>10.221</td>\n",
              "      <td>2.16</td>\n",
              "      <td>2.47</td>\n",
              "      <td>2.08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6620.00</td>\n",
              "      <td>12484.00</td>\n",
              "      <td>81.8099</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>11/1/2024</td>\n",
              "      <td>20091.169</td>\n",
              "      <td>16376.8</td>\n",
              "      <td>122.396</td>\n",
              "      <td>1.545040e+06</td>\n",
              "      <td>712145.00000</td>\n",
              "      <td>101.9619</td>\n",
              "      <td>99.3808</td>\n",
              "      <td>98.8609</td>\n",
              "      <td>100.8691</td>\n",
              "      <td>...</td>\n",
              "      <td>119.230</td>\n",
              "      <td>129.380</td>\n",
              "      <td>31.59</td>\n",
              "      <td>36.26</td>\n",
              "      <td>28.22</td>\n",
              "      <td>71.8</td>\n",
              "      <td>556011.41</td>\n",
              "      <td>938335.20</td>\n",
              "      <td>5381.4576</td>\n",
              "      <td>15.9822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>12/1/2024</td>\n",
              "      <td>20101.629</td>\n",
              "      <td>16387.7</td>\n",
              "      <td>123.077</td>\n",
              "      <td>1.558008e+06</td>\n",
              "      <td>717662.00000</td>\n",
              "      <td>103.1177</td>\n",
              "      <td>100.4976</td>\n",
              "      <td>99.9719</td>\n",
              "      <td>101.6868</td>\n",
              "      <td>...</td>\n",
              "      <td>119.746</td>\n",
              "      <td>129.875</td>\n",
              "      <td>31.72</td>\n",
              "      <td>36.43</td>\n",
              "      <td>28.33</td>\n",
              "      <td>74.0</td>\n",
              "      <td>559364.75</td>\n",
              "      <td>943484.76</td>\n",
              "      <td>5366.6686</td>\n",
              "      <td>15.6997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>1/1/2025</td>\n",
              "      <td>20148.969</td>\n",
              "      <td>16391.2</td>\n",
              "      <td>122.614</td>\n",
              "      <td>1.543178e+06</td>\n",
              "      <td>711461.00000</td>\n",
              "      <td>103.3418</td>\n",
              "      <td>101.0766</td>\n",
              "      <td>100.6319</td>\n",
              "      <td>102.1879</td>\n",
              "      <td>...</td>\n",
              "      <td>120.457</td>\n",
              "      <td>130.281</td>\n",
              "      <td>31.91</td>\n",
              "      <td>36.56</td>\n",
              "      <td>28.58</td>\n",
              "      <td>71.7</td>\n",
              "      <td>559087.09</td>\n",
              "      <td>944167.06</td>\n",
              "      <td>5350.2541</td>\n",
              "      <td>16.8122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>2/1/2025</td>\n",
              "      <td>20209.351</td>\n",
              "      <td>16389.5</td>\n",
              "      <td>122.742</td>\n",
              "      <td>1.556553e+06</td>\n",
              "      <td>711680.00000</td>\n",
              "      <td>104.2202</td>\n",
              "      <td>101.8233</td>\n",
              "      <td>101.4377</td>\n",
              "      <td>102.7245</td>\n",
              "      <td>...</td>\n",
              "      <td>120.615</td>\n",
              "      <td>130.990</td>\n",
              "      <td>32.00</td>\n",
              "      <td>36.66</td>\n",
              "      <td>28.68</td>\n",
              "      <td>64.7</td>\n",
              "      <td>556142.06</td>\n",
              "      <td>941199.49</td>\n",
              "      <td>5367.9408</td>\n",
              "      <td>17.0705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>3/1/2025</td>\n",
              "      <td>20311.260</td>\n",
              "      <td>16500.4</td>\n",
              "      <td>123.601</td>\n",
              "      <td>NaN</td>\n",
              "      <td>722025.00000</td>\n",
              "      <td>103.8892</td>\n",
              "      <td>101.6665</td>\n",
              "      <td>101.1465</td>\n",
              "      <td>101.7332</td>\n",
              "      <td>...</td>\n",
              "      <td>119.760</td>\n",
              "      <td>131.192</td>\n",
              "      <td>32.21</td>\n",
              "      <td>36.79</td>\n",
              "      <td>28.92</td>\n",
              "      <td>57.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5406.5887</td>\n",
              "      <td>21.6579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>796 rows Ã— 127 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dbf1af4-f17a-4909-ba3a-501b27bb0a23')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dbf1af4-f17a-4909-ba3a-501b27bb0a23 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dbf1af4-f17a-4909-ba3a-501b27bb0a23');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6181dabe-fd60-4091-b12d-b28baa53c1bf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6181dabe-fd60-4091-b12d-b28baa53c1bf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6181dabe-fd60-4091-b12d-b28baa53c1bf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f941f318-1087-4860-83a1-fbf5fff71c93\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_vars_raw')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f941f318-1087-4860-83a1-fbf5fff71c93 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_vars_raw');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_vars_raw"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting transformation codes\n",
        "tcodes = all_vars_raw.iloc[0].copy()\n",
        "tcodes = tcodes.drop('sasdate')"
      ],
      "metadata": {
        "id": "zmgt1XNC8CBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars_data = all_vars_raw.drop(0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "HU3kG0B48dbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set index and convert to datetime\n",
        "all_vars_data = all_vars_data.set_index('sasdate')\n",
        "all_vars_data.index = pd.to_datetime(all_vars_data.index)\n",
        "all_vars_data.index.name = 'Date'"
      ],
      "metadata": {
        "id": "uBcK3EtY8m4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cols = all_vars_data.columns\n",
        "for col in data_cols:\n",
        "  all_vars_data[col] = pd.to_numeric(all_vars_data[col], errors='coerce')"
      ],
      "metadata": {
        "id": "Umo1Z7Be8_S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars_data = all_vars_data['1959-01-01':'2025-03-01']"
      ],
      "metadata": {
        "id": "WsxawFiH9b7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed = pd.DataFrame(index=all_vars_data.index)\n",
        "nan_counts_per_transform = {1: 0, 2: 1, 3: 2, 4: 0, 5: 1, 6: 2, 7: 12}\n",
        "max_transform_nan = 0"
      ],
      "metadata": {
        "id": "gvPmHsCRfRW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing problematic variables\n",
        "vars_to_remove = ['ACOGNO', 'TWEXAFEGSMTHx', 'OILPRICEx', 'UMCSENTx', 'ANDENOx']\n",
        "\n",
        "# Remove them from the main data DataFrame AND the tcodes Series\n",
        "original_cols = list(all_vars_data.columns)\n",
        "removed_count = 0\n",
        "for var in vars_to_remove:\n",
        "    if var in all_vars_data.columns:\n",
        "        all_vars_data = all_vars_data.drop(columns=[var])\n",
        "        if var in tcodes.index:\n",
        "            tcodes = tcodes.drop(var)\n",
        "        print(f\"Removed problematic variable: {var}\")\n",
        "        removed_count += 1\n",
        "    else:\n",
        "        print(f\"Warning: Variable {var} listed for removal not found in DataFrame.\")\n",
        "\n",
        "print(f\"Removed {removed_count} variables based on McCracken & Ng (2016) recommendations.\")\n",
        "print(f\"Shape after removal: {all_vars_data.shape}\")\n",
        "\n",
        "# Update data_cols list if you use it later\n",
        "data_cols = all_vars_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPcCAZUW_Nfe",
        "outputId": "2e9b152f-ff76-445c-a70a-250a1af9aafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed problematic variable: ACOGNO\n",
            "Removed problematic variable: TWEXAFEGSMTHx\n",
            "Removed problematic variable: OILPRICEx\n",
            "Removed problematic variable: UMCSENTx\n",
            "Removed problematic variable: ANDENOx\n",
            "Removed 5 variables based on McCracken & Ng (2016) recommendations.\n",
            "Shape after removal: (795, 121)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming"
      ],
      "metadata": {
        "id": "RZH19U7ek-eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data_cols:\n",
        "  series = all_vars_data[col]\n",
        "  code = int(tcodes[col])\n",
        "  current_max_nan = nan_counts_per_transform[code]\n",
        "  max_transform_nan = max(max_transform_nan, current_max_nan)\n",
        "\n",
        "  if code == 1:\n",
        "    transformed_series = series\n",
        "  elif code == 2:\n",
        "    transformed_series = series.diff(1)\n",
        "  elif code == 3:\n",
        "    transformed_series = series.diff(1).diff(1)\n",
        "  elif code == 4:\n",
        "    transformed_series = np.log(series.clip(lower=1e-10))\n",
        "    if (series <= 0).any():\n",
        "      print(f\"Column {col} has negatives, logs will cause NaNs\")\n",
        "  elif code == 5:\n",
        "    series_clipped = series.clip(lower=1e-10)\n",
        "    transformed_series = np.log(series_clipped).diff(1)\n",
        "    if (series <= 0).any():\n",
        "      print(f\"Column {col} (Code 5) has non-positive values. Log difference applied, NaNs expected\")\n",
        "  elif code == 6:\n",
        "    series_clipped = series.clip(lower=1e-10)\n",
        "    transformed_series = np.log(series_clipped).diff(1).diff(1)\n",
        "    if (series <= 0).any():\n",
        "      print(f\"Column {col} (Code 5) has non-positive values. Log difference applied, NaNs expected\")\n",
        "  elif code == 7:\n",
        "    denominator = series.shift(12)\n",
        "    denominator = denominator.replace(0, np.nan)\n",
        "    denominator[denominator.abs() < 1e-10] = np.nan\n",
        "    transformed_series = ((series / denominator) - 1)\n",
        "  else:\n",
        "    print(f\"Unexpected code {code} for {col}, keeping original\")\n",
        "    transformed_series = series\n",
        "\n",
        "  X_transformed[col] = transformed_series\n",
        "\n",
        "print(f\"Transformations applied, max NaNs introduced by a single transform: {max_transform_nan}\")\n",
        "print(\"\\nTransformed Data Head (showing initial NaNs):\")\n",
        "print(X_transformed.head(max(15, max_transform_nan + 2))) # Show enough rows to see initial NaNs\n",
        "print(\"\\nNaN count per column after transformations (Top 20):\")\n",
        "print(X_transformed.isna().sum().sort_values(ascending=False).head(20))\n",
        "print(f\"\\nTransformed data shape: {X_transformed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF_ORP6XgRmx",
        "outputId": "37cb0750-54e7-44dd-dc4f-1928bd7849a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformations applied, max NaNs introduced by a single transform: 12\n",
            "\n",
            "Transformed Data Head (showing initial NaNs):\n",
            "                 RPI   W875RX1  DPCERA3M086SBEA  CMRMTSPLx   RETAILx  \\\n",
            "Date                                                                   \n",
            "1959-01-01       NaN       NaN              NaN        NaN       NaN   \n",
            "1959-02-01  0.003877  0.003621         0.010349   0.007336  0.007310   \n",
            "1959-03-01  0.006457  0.007325         0.009404  -0.003374  0.008321   \n",
            "1959-04-01  0.006510  0.007029        -0.003622   0.019915  0.000616   \n",
            "1959-05-01  0.005796  0.006618         0.012043   0.006839  0.007803   \n",
            "1959-06-01  0.003068  0.003012         0.003642  -0.000097  0.009064   \n",
            "1959-07-01 -0.000580 -0.000762        -0.003386   0.012155 -0.000330   \n",
            "1959-08-01 -0.005653 -0.005755         0.005998  -0.052521  0.006364   \n",
            "1959-09-01  0.000763  0.000000         0.010001   0.014660 -0.013157   \n",
            "1959-10-01  0.001271  0.001170        -0.006825   0.001620  0.007288   \n",
            "1959-11-01  0.007559  0.006670        -0.000444  -0.036718 -0.026704   \n",
            "1959-12-01  0.010192  0.011388        -0.001143   0.049614 -0.004644   \n",
            "1960-01-01  0.003226  0.004661         0.002791   0.016963  0.026606   \n",
            "1960-02-01  0.001147  0.000906         0.004361   0.014403  0.003696   \n",
            "1960-03-01  0.001877  0.000905         0.014089  -0.028040 -0.001102   \n",
            "\n",
            "              INDPRO   IPFPNSS   IPFINAL   IPCONGD  IPDCONGD  ...  \\\n",
            "Date                                                          ...   \n",
            "1959-01-01       NaN       NaN       NaN       NaN       NaN  ...   \n",
            "1959-02-01  0.019395  0.013405  0.008628  0.007309  0.005232  ...   \n",
            "1959-03-01  0.014300  0.006036  0.004896  0.000000  0.019397  ...   \n",
            "1959-04-01  0.021080  0.014339  0.014545  0.015652  0.006379  ...   \n",
            "1959-05-01  0.014954  0.008267  0.009580  0.004766  0.020152  ...   \n",
            "1959-06-01  0.001137  0.007035  0.007125 -0.004766  0.007453  ...   \n",
            "1959-07-01 -0.024237  0.001168  0.008251  0.013056  0.019609  ...   \n",
            "1959-08-01 -0.034464 -0.007027 -0.002350  0.001181 -0.028311  ...   \n",
            "1959-09-01 -0.001211 -0.004708 -0.003538 -0.003542 -0.030418  ...   \n",
            "1959-10-01 -0.007291 -0.002364 -0.004733 -0.004738  0.022900  ...   \n",
            "1959-11-01  0.006079 -0.010710 -0.016746 -0.021609 -0.131556  ...   \n",
            "1959-12-01  0.059982  0.029466  0.023837  0.032241  0.120172  ...   \n",
            "1960-01-01  0.025919  0.024097  0.029021  0.031234  0.103833  ...   \n",
            "1960-02-01 -0.008937 -0.005686 -0.003436 -0.011454 -0.013856  ...   \n",
            "1960-03-01 -0.009021 -0.003427 -0.001151  0.001151 -0.019967  ...   \n",
            "\n",
            "            DDURRG3M086SBEA  DNDGRG3M086SBEA  DSERRG3M086SBEA  CES0600000008  \\\n",
            "Date                                                                           \n",
            "1959-01-01              NaN              NaN              NaN            NaN   \n",
            "1959-02-01              NaN              NaN              NaN            NaN   \n",
            "1959-03-01         0.000676        -0.001148         0.000292      -0.000022   \n",
            "1959-04-01        -0.000253         0.001312         0.001760      -0.000022   \n",
            "1959-05-01         0.000657        -0.001695        -0.001867      -0.000021   \n",
            "1959-06-01         0.000326         0.003334         0.001946      -0.004619   \n",
            "1959-07-01        -0.001504        -0.001204        -0.000013       0.000000   \n",
            "1959-08-01        -0.005139         0.000870        -0.000689       0.000000   \n",
            "1959-09-01         0.006349         0.000702         0.000088       0.000000   \n",
            "1959-10-01        -0.002401        -0.000223         0.000375       0.000000   \n",
            "1959-11-01         0.001506        -0.004066        -0.000778       0.000000   \n",
            "1959-12-01        -0.000345         0.001897        -0.000485       0.013730   \n",
            "1960-01-01        -0.002588        -0.001845        -0.001246      -0.004680   \n",
            "1960-02-01         0.003750         0.001683         0.000858      -0.004555   \n",
            "1960-03-01        -0.004537         0.001791        -0.001146      -0.000020   \n",
            "\n",
            "            CES2000000008  CES3000000008  DTCOLNVHFNM  DTCTHFNM    INVEST  \\\n",
            "Date                                                                        \n",
            "1959-01-01            NaN            NaN          NaN       NaN       NaN   \n",
            "1959-02-01            NaN            NaN          NaN       NaN       NaN   \n",
            "1959-03-01      -0.008147       0.004819     0.004929  0.004138 -0.014792   \n",
            "1959-04-01       0.012203      -0.004890     0.012134  0.006734  0.024929   \n",
            "1959-05-01      -0.004090      -0.004819     0.002828  0.002020 -0.015342   \n",
            "1959-06-01       0.003992       0.004796     0.009726  0.009007 -0.012252   \n",
            "1959-07-01      -0.004040      -0.004796    -0.004631 -0.001000  0.029341   \n",
            "1959-08-01       0.003945      -0.009615    -0.000472 -0.000502 -0.025495   \n",
            "1959-09-01      -0.003992       0.014435    -0.013088 -0.006685  0.016333   \n",
            "1959-10-01       0.003898      -0.009639    -0.001601 -0.003007 -0.003397   \n",
            "1959-11-01      -0.003945       0.004819    -0.012240 -0.004567  0.004214   \n",
            "1959-12-01      -0.007797       0.019139    -0.005539  0.005956  0.008364   \n",
            "1960-01-01       0.007797      -0.009705     0.004292 -0.011739 -0.013330   \n",
            "1960-02-01       0.003853      -0.004750     0.008268  0.005388 -0.018942   \n",
            "1960-03-01       0.030131      -0.004684     0.003472  0.000951  0.003490   \n",
            "\n",
            "            VIXCLSx  \n",
            "Date                 \n",
            "1959-01-01      NaN  \n",
            "1959-02-01      NaN  \n",
            "1959-03-01      NaN  \n",
            "1959-04-01      NaN  \n",
            "1959-05-01      NaN  \n",
            "1959-06-01      NaN  \n",
            "1959-07-01      NaN  \n",
            "1959-08-01      NaN  \n",
            "1959-09-01      NaN  \n",
            "1959-10-01      NaN  \n",
            "1959-11-01      NaN  \n",
            "1959-12-01      NaN  \n",
            "1960-01-01      NaN  \n",
            "1960-02-01      NaN  \n",
            "1960-03-01      NaN  \n",
            "\n",
            "[15 rows x 121 columns]\n",
            "\n",
            "NaN count per column after transformations (Top 20):\n",
            "VIXCLSx          42\n",
            "PERMIT           12\n",
            "PERMITMW         12\n",
            "PERMITS          12\n",
            "PERMITNE         12\n",
            "NONBORRES        12\n",
            "PERMITW          12\n",
            "S&P div yield     4\n",
            "NONREVSL          3\n",
            "S&P PE ratio      3\n",
            "DTCOLNVHFNM       3\n",
            "DTCTHFNM          3\n",
            "CP3Mx             3\n",
            "TOTRESNS          2\n",
            "CONSPI            2\n",
            "BUSLOANS          2\n",
            "REALLN            2\n",
            "ISRATIOx          2\n",
            "BOGMBASE          2\n",
            "BUSINVx           2\n",
            "dtype: int64\n",
            "\n",
            "Transformed data shape: (795, 121)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Target"
      ],
      "metadata": {
        "id": "2qxWor2elO28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fred = fa.Fred(api_key=API_KEY)\n",
        "y_raw = fred.get_series('USRECM', observation_start='1959-01-01', observation_end='2025-03-01')\n",
        "print(len(y_raw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q326J2NJjd3t",
        "outputId": "e36e919d-ad3c-4296-9669-0cd6a78b57d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift target\n",
        "prediction_horizon = 6\n",
        "y_shifted = y_raw.shift(-prediction_horizon).rename('Target')\n",
        "print(y_shifted.tail(prediction_horizon+5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOJbfIDyl6_S",
        "outputId": "a8fefacc-bf32-43ca-9025-26ce3942047f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-01    0.0\n",
            "2024-06-01    0.0\n",
            "2024-07-01    0.0\n",
            "2024-08-01    0.0\n",
            "2024-09-01    0.0\n",
            "2024-10-01    NaN\n",
            "2024-11-01    NaN\n",
            "2024-12-01    NaN\n",
            "2025-01-01    NaN\n",
            "2025-02-01    NaN\n",
            "2025-03-01    NaN\n",
            "Name: Target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determining Analysis Window"
      ],
      "metadata": {
        "id": "FwZEduAymgiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_lag_later = 12\n",
        "total_initial_drop = max_transform_nan + max_lag_later\n",
        "first_usable_idx_pos = total_initial_drop\n",
        "first_usable_date = X_transformed.index[first_usable_idx_pos]\n",
        "last_usable_date = y_shifted.last_valid_index()\n",
        "print(f\"\\n--> Analysis Window START: {first_usable_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"--> Analysis Window END:   {last_usable_date.strftime('%Y-%m-%d')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8MIa3wPmbeG",
        "outputId": "ca160fd7-27be-49cd-e892-4a814245ec93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--> Analysis Window START: 1961-01-01\n",
            "--> Analysis Window END:   2024-09-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After last_usable_date = y_shifted.last_valid_index() in Cell 75\n",
        "print(f\"DEBUG: last_valid_index() from y_shifted used for last_usable_date: {last_usable_date}\")\n",
        "print(f\"DEBUG: Expected end based on data end and horizon: {pd.to_datetime('2024-12-01') - pd.DateOffset(months=prediction_horizon)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t69jvMINKy5h",
        "outputId": "c1c4c0e2-324f-44d7-d3b2-bc9889f198ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: last_valid_index() from y_shifted used for last_usable_date: 2024-09-01 00:00:00\n",
            "DEBUG: Expected end based on data end and horizon: 2024-06-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this AFTER Cell 74 (where y_shifted is created)\n",
        "print(f\"Last valid index calculated from y_shifted: {y_shifted.last_valid_index()}\")\n",
        "print(f\"Last date expected from y_raw: {last_usable_date}\") # last_valid_date used for y_raw fetch\n",
        "# Expected last_usable_date is 6 months before last_valid_date\n",
        "expected_last_usable = pd.to_datetime(last_usable_date) - pd.DateOffset(months=prediction_horizon)\n",
        "print(f\"Expected last usable date based on horizon: {expected_last_usable}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ijM2sdpIwZc",
        "outputId": "47c13652-bc3c-4ee8-805d-c144066210ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last valid index calculated from y_shifted: 2024-09-01 00:00:00\n",
            "Last date expected from y_raw: 2024-09-01 00:00:00\n",
            "Expected last usable date based on horizon: 2024-03-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed_core = X_transformed.loc[first_usable_date:last_usable_date].copy()\n",
        "print(f\"Shape of full set base: {X_transformed_core.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPAhGrA-o9Fi",
        "outputId": "cf37947a-8fd2-4a57-b1cd-65adba41c7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of full set base: (765, 121)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare final target variable for the window\n",
        "y_final = y_shifted.loc[first_usable_date:last_usable_date].copy()\n",
        "print(f\"Shape of final target: {y_final.shape}\")\n",
        "y_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "vHTnwKIoqKdt",
        "outputId": "cf162a0c-c3f3-495d-ddb0-a75eb8be95b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of final target: (765,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1961-01-01    0.0\n",
              "1961-02-01    0.0\n",
              "1961-03-01    0.0\n",
              "1961-04-01    0.0\n",
              "1961-05-01    0.0\n",
              "             ... \n",
              "2024-05-01    0.0\n",
              "2024-06-01    0.0\n",
              "2024-07-01    0.0\n",
              "2024-08-01    0.0\n",
              "2024-09-01    0.0\n",
              "Name: Target, Length: 765, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1961-01-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-02-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-03-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-04-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-05-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-06-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-09-01</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>765 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Validation"
      ],
      "metadata": {
        "id": "RwnjVGBQqXSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(y_final) == len(X_transformed_core), \"ERROR: Length mismatch between target and features.\""
      ],
      "metadata": {
        "id": "XZGzmRtHqT9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NaNs in X_transformed_core: {X_transformed_core.isna().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF5_OA04qj4J",
        "outputId": "b17f4e91-638a-4c88-f189-39892d16940a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs in X_transformed_core: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed_core.isna().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "gaFf4heSqt13",
        "outputId": "38d0a81e-1005-4aa1-fb5d-fffc3138ebb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VIXCLSx          18\n",
              "CP3Mx             2\n",
              "COMPAPFFx         1\n",
              "W875RX1           0\n",
              "RETAILx           0\n",
              "                 ..\n",
              "CES0600000008     0\n",
              "CES3000000008     0\n",
              "DTCOLNVHFNM       0\n",
              "DTCTHFNM          0\n",
              "INVEST            0\n",
              "Length: 121, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>VIXCLSx</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP3Mx</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COMPAPFFx</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W875RX1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RETAILx</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CES0600000008</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CES3000000008</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DTCOLNVHFNM</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DTCTHFNM</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INVEST</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to check if transformation caused NAs even in the core window"
      ],
      "metadata": {
        "id": "aY1dZtd2CIrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# col_to_check = 'COMPAPFFx'\n",
        "# print(f\"Transformation code for {col_to_check}: {tcodes.get(col_to_check)}\")\n",
        "\n",
        "# # Compare original vs transformed WITHIN the core window\n",
        "# print(\"\\nOriginal Data in Core Window (Head & Tail):\")\n",
        "# print(all_vars_data.loc[first_usable_date:last_usable_date, col_to_check].head(10))\n",
        "# print(all_vars_data.loc[first_usable_date:last_usable_date, col_to_check].tail(10))\n",
        "# print(f\"Original NaN count in core window: {all_vars_data.loc[first_usable_date:last_usable_date, col_to_check].isna().sum()}\")\n",
        "\n",
        "\n",
        "# print(f\"\\nTransformed {col_to_check} in Core Window (Head & Tail):\")\n",
        "# print(X_transformed_core[col_to_check].head(15)) # Show more to see effect\n",
        "# print(X_transformed_core[col_to_check].tail(15))\n",
        "# print(f\"Transformed NaN count in core window: {X_transformed_core[col_to_check].isna().sum()}\")\n",
        "\n",
        "# # If differencing, check for consecutive identical values in original\n",
        "# if tcodes.get(col_to_check) in [2, 3, 5, 6]:\n",
        "#      print(\"\\nChecking for consecutive duplicates in original data within core window + lookback:\")\n",
        "#      lookback = 2 if tcodes.get(col_to_check) in [3,6] else 1\n",
        "#      orig_slice_with_lookback = all_vars_data.loc[:last_usable_date, col_to_check] # Look from start up to end of core\n",
        "#      consecutive_duplicates = orig_slice_with_lookback[orig_slice_with_lookback == orig_slice_with_lookback.shift(1)]\n",
        "#      print(consecutive_duplicates.tail(20)) # See if recent duplicates exist that affect the core window diff\n",
        "\n",
        "# # If log, check for non-positive values\n",
        "# if tcodes.get(col_to_check) in [4, 5, 6]:\n",
        "#      print(\"\\nChecking for non-positive values in original data within core window:\")\n",
        "#      print(all_vars_data.loc[first_usable_date:last_usable_date, col_to_check][all_vars_data.loc[first_usable_date:last_usable_date, col_to_check] <= 0])\n",
        "\n",
        "#  # If YoY %, check denominator NaNs/Zeros\n",
        "# if tcodes.get(col_to_check) == 7:\n",
        "#     print(\"\\nChecking for NaNs/Zeros in original data 12 months prior within core window:\")\n",
        "#     denominator_slice = all_vars_data[col_to_check].shift(12).loc[first_usable_date:last_usable_date]\n",
        "#     print(denominator_slice[denominator_slice.isna() | (denominator_slice.abs() < 1e-9)].head(20)) # Check where denominator has issues"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l2Ur5bYJuS1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Predictor Set Building Blocks"
      ],
      "metadata": {
        "id": "HwI_X2TNpCsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Yield Curve"
      ],
      "metadata": {
        "id": "-44IhhviDHEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spread_data = pd.read_csv('/content/drive/MyDrive/Diffusion Indices/yieldspread.csv')\n",
        "spread_df = pd.DataFrame({'Date': spread_data['Date'], 'Spread': spread_data['Spread']})\n",
        "spread_df_og = spread_df.set_index('Date')\n",
        "spread_df = spread_df_og.loc['31-Jan-59':'30-Jun-17']\n",
        "spread_df['Spread']\n",
        "spread_index = spread_df.index\n",
        "date_index = []\n",
        "for date in spread_index:\n",
        "    datetime = pd.to_datetime(date, format='%d-%b-%y')\n",
        "    if datetime.year >= 2059:\n",
        "        datetime = datetime.replace(year=datetime.year-100)\n",
        "    date_index.append(datetime)\n",
        "print(len(date_index))\n",
        "spread_df = pd.DataFrame({'Date': date_index, 'Spread': spread_df['Spread']})\n",
        "spread_df_1 = spread_df.set_index('Date')\n",
        "spread_df_2 = spread_df_og.loc['7/31/2017':'12/31/2024']\n",
        "spread_index_2 = spread_df_2.index\n",
        "date_index_2 = []\n",
        "for date in spread_index_2:\n",
        "    datetime = pd.to_datetime(date)\n",
        "    if datetime.year >= 2059:\n",
        "        datetime = datetime.replace(year=datetime.year-100)\n",
        "    date_index_2.append(datetime)\n",
        "print(len(date_index))\n",
        "spread_df = pd.DataFrame({'Date': date_index_2, 'Spread': spread_df_2['Spread']})\n",
        "spread_df_2 = spread_df.set_index('Date')\n",
        "X_raw_spread = pd.concat([spread_df_1, spread_df_2])\n",
        "X_raw_spread = X_raw_spread.resample('MS').mean()\n",
        "X_raw_spread = X_raw_spread.loc[first_usable_date:last_usable_date]\n",
        "X_raw_spread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "3bguV-JADGNv",
        "outputId": "ed578985-6f72-4068-842f-31c1f7c8e246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "702\n",
            "702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Spread\n",
              "Date              \n",
              "1961-01-01    1.56\n",
              "1961-02-01    1.31\n",
              "1961-03-01    1.30\n",
              "1961-04-01    1.44\n",
              "1961-05-01    1.37\n",
              "...            ...\n",
              "2024-05-01   -0.91\n",
              "2024-06-01   -1.07\n",
              "2024-07-01   -1.09\n",
              "2024-08-01   -1.32\n",
              "2024-09-01   -1.12\n",
              "\n",
              "[765 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2a6ee69-1237-4bc3-b518-d51127c251a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spread</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1961-01-01</th>\n",
              "      <td>1.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-02-01</th>\n",
              "      <td>1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-03-01</th>\n",
              "      <td>1.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-04-01</th>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961-05-01</th>\n",
              "      <td>1.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-01</th>\n",
              "      <td>-0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-06-01</th>\n",
              "      <td>-1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-01</th>\n",
              "      <td>-1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-01</th>\n",
              "      <td>-1.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-09-01</th>\n",
              "      <td>-1.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>765 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2a6ee69-1237-4bc3-b518-d51127c251a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2a6ee69-1237-4bc3-b518-d51127c251a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2a6ee69-1237-4bc3-b518-d51127c251a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-08bac639-5be1-4a9c-bf43-558832667c81\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08bac639-5be1-4a9c-bf43-558832667c81')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-08bac639-5be1-4a9c-bf43-558832667c81 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_30e42c6e-8507-487e-9d01-b23a38210c0c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_raw_spread')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_30e42c6e-8507-487e-9d01-b23a38210c0c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_raw_spread');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_raw_spread",
              "summary": "{\n  \"name\": \"X_raw_spread\",\n  \"rows\": 765,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1961-01-01 00:00:00\",\n        \"max\": \"2024-09-01 00:00:00\",\n        \"num_unique_values\": 765,\n        \"samples\": [\n          \"1990-10-01 00:00:00\",\n          \"1982-08-01 00:00:00\",\n          \"2023-08-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3142136288567638,\n        \"min\": -3.51,\n        \"max\": 4.15,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          -0.12,\n          0.55,\n          2.53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Factor Set"
      ],
      "metadata": {
        "id": "0A18d5v8DTr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer_pca = KNNImputer(n_neighbors=5)\n",
        "X_filled_for_pca = pd.DataFrame(imputer_pca.fit_transform(X_transformed_core),\n",
        "                                index=X_transformed_core.index,\n",
        "                                columns=X_transformed_core.columns)\n",
        "scaler_sm_pca = StandardScaler()\n",
        "X_scaled_for_sm_pca = scaler_sm_pca.fit_transform(X_filled_for_pca)\n",
        "\n",
        "\n",
        "max_potential_factors = 50\n",
        "print(f\" Running statsmodels PCA considering up to {max_potential_factors} components...\")\n",
        "sm_pca_results = smPCA(X_scaled_for_sm_pca,\n",
        "                       ncomp=max_potential_factors,\n",
        "                       standardize=False, # Data is already scaled\n",
        "                       demean=True)\n",
        "\n",
        "print(\" Calculating Bai & Ng Information Criteria...\")\n",
        "ic_values_array = sm_pca_results.ic\n",
        "\n",
        "\n",
        "ICs_df = pd.DataFrame(ic_values_array,\n",
        "                      index=np.arange(0, max_potential_factors+1), # Index k = 1, 2, ...\n",
        "                      columns=['IC_p1', 'IC_p2', 'IC_p3']) # Name the columns\n",
        "\n",
        "\n",
        "print(\" Information Criteria DataFrame (IC_p1, IC_p2, IC_p3) Head:\")\n",
        "print(ICs_df.head())\n",
        "\n",
        "try:\n",
        "    optimal_k_ic2 = ICs_df['IC_p2'].idxmin() # Now works on the DataFrame\n",
        "    min_ic2_value = ICs_df['IC_p2'].min()\n",
        "    print(f\"\\n Optimal number of factors according to Bai & Ng IC_p2: {optimal_k_ic2}\")\n",
        "    print(f\"    (Minimum IC_p2 value: {min_ic2_value:.4f})\")\n",
        "\n",
        "    # Optionally find for others\n",
        "    optimal_k_ic1 = ICs_df['IC_p1'].idxmin()\n",
        "    optimal_k_ic3 = ICs_df['IC_p3'].idxmin()\n",
        "    print(f\"    (Optimal for IC_p1: {optimal_k_ic1}, IC_p3: {optimal_k_ic3})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" ERROR finding optimal k from ICs: {e}\")\n",
        "    print(\"  ICs DataFrame:\")\n",
        "    print(ICs_df) # Print the DataFrame for debugging\n",
        "    optimal_k_ic2 = 8 # Default if fails\n",
        "    print(f\"  Defaulting to {optimal_k_ic2} factors.\")\n",
        "\n",
        "\n",
        "final_n_factors = optimal_k_ic2\n",
        "all_eigenvals = sm_pca_results.eigenvals\n",
        "if isinstance(all_eigenvals, np.ndarray): # Ensure it's usable\n",
        "  total_variance = all_eigenvals.sum()\n",
        "  if total_variance > 1e-9:\n",
        "    all_explained_variance_ratios = all_eigenvals / total_variance\n",
        "    # Select the ratios ONLY for the 'final_n_factors' we chose\n",
        "    explained_variance_ratios_final = all_explained_variance_ratios[:final_n_factors] # Get as numpy array\n",
        "  else:\n",
        "    print(\"ERROR: Total variance (sum of eigenvalues) is zero or negative.\")\n",
        "    explained_variance_ratios_final = np.array([np.nan]*final_n_factors) # Error case\n",
        "else:\n",
        "  print(\"ERROR: Could not extract eigenvalues as expected Series/Array.\")\n",
        "  explained_variance_ratios_final = np.array([np.nan]*final_n_factors) # Error case\n",
        "\n",
        "print(f\" Extracting the top {final_n_factors} factors...\")\n",
        "\n",
        "factors_final_values = sm_pca_results.factors[:, :final_n_factors]\n",
        "\n",
        "X_factors_raw_final = pd.DataFrame(factors_final_values,\n",
        "                                   index=X_filled_for_pca.index,\n",
        "                                   columns=[f'Factor_{i+1}' for i in range(final_n_factors)])\n",
        "\n",
        "print(\"\\n Final Factor DataFrame head (using Bai & Ng factors):\")\n",
        "print(X_factors_raw_final.head())\n",
        "print(f\"\\n Final Factor DF shape: {X_factors_raw_final.shape}\")\n",
        "print(f\" Final Factor DF NaNs: {X_factors_raw_final.isna().sum().sum()}\")\n",
        "print(\"\\n--- End of Factor Generation using Bai & Ng Criteria ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FseXz9QJbj-I",
        "outputId": "64ccb4c5-2a88-49f5-850a-82a091166081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Running statsmodels PCA considering up to 50 components...\n",
            " Calculating Bai & Ng Information Criteria...\n",
            " Information Criteria DataFrame (IC_p1, IC_p2, IC_p3) Head:\n",
            "       IC_p1      IC_p2      IC_p3\n",
            "0  11.435666  11.435666  11.435666\n",
            "1  11.263452  11.264858  11.258589\n",
            "2  11.208322  11.211133  11.198595\n",
            "3  11.152950  11.157166  11.138359\n",
            "4  11.108241  11.113863  11.088787\n",
            "\n",
            " Optimal number of factors according to Bai & Ng IC_p2: 8\n",
            "    (Minimum IC_p2 value: 11.0435)\n",
            "    (Optimal for IC_p1: 9, IC_p3: 50)\n",
            " Extracting the top 8 factors...\n",
            "\n",
            " Final Factor DataFrame head (using Bai & Ng factors):\n",
            "            Factor_1  Factor_2  Factor_3  Factor_4  Factor_5  Factor_6  \\\n",
            "Date                                                                     \n",
            "1961-01-01  0.013078  0.020166  0.042480 -0.014670  0.026307 -0.049661   \n",
            "1961-02-01  0.018949  0.020867 -0.001431 -0.011311  0.004790 -0.058260   \n",
            "1961-03-01 -0.008520  0.008984  0.037110 -0.002201  0.021143 -0.045252   \n",
            "1961-04-01 -0.010558  0.012068  0.047813 -0.027879  0.025238 -0.055110   \n",
            "1961-05-01 -0.027446  0.025178  0.017083 -0.014977  0.010646 -0.037036   \n",
            "\n",
            "            Factor_7  Factor_8  \n",
            "Date                            \n",
            "1961-01-01 -0.060370  0.022584  \n",
            "1961-02-01 -0.003478 -0.016276  \n",
            "1961-03-01 -0.031028  0.005912  \n",
            "1961-04-01 -0.006899 -0.087388  \n",
            "1961-05-01 -0.010463 -0.060727  \n",
            "\n",
            " Final Factor DF shape: (765, 8)\n",
            " Final Factor DF NaNs: 0\n",
            "\n",
            "--- End of Factor Generation using Bai & Ng Criteria ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(explained_variance_ratios_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A06-icbOxkd",
        "outputId": "86ab3ed6-eba3-4bfc-9f47-2520a9252b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.21039765 0.08244777 0.07480166 0.06078296 0.05555053 0.03552527\n",
            " 0.02777145 0.02725729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing Category-Based Diffusion Index"
      ],
      "metadata": {
        "id": "2EIwDxksGPZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining categories (given by McCracken and Ng (2015))\n",
        "variable_groups = {\n",
        "    'Output_Income': ['RPI', 'W875RX1', 'INDPRO', 'IPFPNSS', 'IPFINAL', 'IPCONGD', 'IPDCONGD', 'IPNCONGD', 'IPBUSEQ', 'IPMAT', 'IPDMAT', 'IPNMAT', 'IPMANSICS', 'IPB51222S', 'IPFUELS', 'CUMFNS'],\n",
        "    'Labor_Market': ['HWI', 'HWIURATIO', 'CLF16OV', 'CE16OV', 'UNRATE', 'UEMPMEAN', 'UEMPLT5', 'UEMP5TO14', 'UEMP15OV', 'UEMP15T26', 'UEMP27OV', 'CLAIMSx', 'PAYEMS', 'USGOOD', 'CES1021000001', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP', 'SRVPRD', 'USTPU', 'USWTRADE', 'USTRADE', 'USFIRE', 'USGOVT', 'CES0600000007', 'AWOTMAN', 'AWHMAN', 'CES0600000008', 'CES2000000008', 'CES3000000008'],\n",
        "    'Housing': ['HOUST', 'HOUSTNE', 'HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE', 'PERMITMW', 'PERMITS', 'PERMITW'],\n",
        "    'Consumption_Orders_Inventories': ['DPCERA3M086SBEA', 'CMRMTSPLx', 'RETAILx', 'AMDMNOx', 'AMDMUOx', 'BUSINVx', 'ISRATIOx'],\n",
        "    'Money_Credit': ['M1SL', 'M2SL', 'M2REAL', 'BOGMBASE', 'TOTRESNS', 'NONBORRES', 'BUSLOANS', 'REALLN', 'NONREVSL', 'CONSPI', 'DTCOLNVHFNM', 'DTCTHFNM', 'INVEST'],\n",
        "    'Interest_Rates_Spreads': ['FEDFUNDS', 'CP3Mx', 'TB3MS', 'TB6MS', 'GS1', 'GS5', 'GS10', 'AAA', 'BAA', 'COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'T10YFFM', 'AAAFFM', 'BAAFFM'],\n",
        "    'FX_Rates': ['EXSZUSx', 'EXJPUSx', 'EXUSUKx', 'EXCAUSx'],\n",
        "    'Prices': ['WPSFD49207', 'WPSFD49502', 'WPSID61', 'WPSID62', 'PPICMM', 'CPIAUCSL', 'CPIAPPSL', 'CPITRNSL', 'CPIMEDSL', 'CUSR0000SAC', 'CUSR0000SAD', 'CUSR0000SAS', 'CPIULFSL', 'CUSR0000SA0L2', 'CUSR0000SA0L5', 'PCEPI', 'DDURRG3M086SBEA', 'DNDGRG3M086SBEA', 'DSERRG3M086SBEA'],\n",
        "    'Stock_Market': ['S&P 500', 'S&P div yield', 'S&P PE ratio', 'VIXCLSx']\n",
        "}\n",
        "\n",
        "# Other scenarios\n",
        "counter_cyclical_vars = {\n",
        "    'UNRATE', 'UEMPMEAN', 'UEMPLT5', 'UEMP5TO14', 'UEMP15OV', 'UEMP15T26', 'UEMP27OV',\n",
        "    'CLAIMSx', 'ISRATIOx'\n",
        "}\n",
        "\n",
        "level_log_positive_impact = {\n",
        "    'CES0600000007', 'AWHMAN', 'HOUST', 'HOUSTNE', 'HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE', 'PERMITMW', 'PERMITS', 'PERMITW', 'T10YFFM'\n",
        "}\n",
        "\n",
        "level_log_negative_impact ={\n",
        "    'VIXCLSx', 'COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'AAAFFM', 'BAAFFM'\n",
        "}\n",
        "leading_indicators_group = {\n",
        "    'Leading_Indicators': [\n",
        "        'AWOTMAN',          # Avg Weekly Overtime Hours, Mfg (tcode 2, Pro-cyclical >0)\n",
        "        'AWHMAN',           # Avg Weekly Hours, Mfg (tcode 1, level_pos: diff>0)\n",
        "        'HOUST',            # Housing Starts (tcode 4, level_pos: diff>0)\n",
        "        'PERMIT',           # Building Permits (tcode 4, level_pos: diff>0)\n",
        "        'CLAIMSx',          # Initial Claims (tcode 5, counter: <0)\n",
        "        'T10YFFM',          # 10-Year Treasury minus Fed Funds (tcode 1, level_pos: diff>0)\n",
        "        'S&P 500',          # S&P 500 Index (tcode 5, Pro-cyclical >0)\n",
        "        'AMDMNOx',          # New Orders, Durable Goods (tcode 5, Pro-cyclical >0) - *Check exact orders series used*\n",
        "        # Add others like M2REAL (Money Supply) if desired and tcode allows >0 logic easily\n",
        "        # Remove any from this list if not present in your final columns\n",
        "     ]\n",
        "}\n",
        "# Threshold for small increase relative to standard deviation\n",
        "small_change_threshold_fraction = 0.1"
      ],
      "metadata": {
        "id": "Q62nRs8MqBcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_indices = {}\n",
        "all_grouped_vars_found = set()\n",
        "imputer_core = KNNImputer(n_neighbors=5)\n",
        "X_imputed_core = pd.DataFrame(imputer_core.fit_transform(X_transformed_core),\n",
        "                                  index=X_transformed_core.index,\n",
        "                                  columns=X_transformed_core.columns)\n",
        "# Calculate standard deviations for thresholding\n",
        "std_devs = X_imputed_core.std()\n",
        "small_change_thresholds = std_devs * small_change_threshold_fraction\n",
        "\n",
        "for category_name, category_vars in variable_groups.items():\n",
        "  valid_category_vars = [var for var in category_vars if var in X_imputed_core.columns]\n",
        "  if not valid_category_vars:\n",
        "    print(f'Skipping category {category_name}, no valid variables')\n",
        "    continue\n",
        "\n",
        "  all_grouped_vars_found.update(valid_category_vars)\n",
        "  category_data = X_imputed_core[valid_category_vars]\n",
        "\n",
        "  # Stores numerical state for category\n",
        "  improvement_state_values = pd.DataFrame(index=category_data.index, dtype=float)\n",
        "\n",
        "  for col_name in valid_category_vars:\n",
        "    series = category_data[col_name]\n",
        "    threshold = small_change_thresholds.get(col_name, 0)\n",
        "    state_col = pd.Series(index=series.index, dtype=float)\n",
        "\n",
        "    if col_name in level_log_positive_impact:\n",
        "      diff_series = series.diff(1)\n",
        "      state_col[diff_series > threshold] = 1.0 # Strong increase = good\n",
        "      state_col[(diff_series > -threshold) & (diff_series <= threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[diff_series <= -threshold] = 0.0 # Decrease = Bad\n",
        "    elif col_name in level_log_negative_impact:\n",
        "      diff_series = series.diff(1)\n",
        "      state_col[diff_series < -threshold] = 1.0 # Strong Decrease = Good\n",
        "      state_col[(diff_series >= -threshold) & (diff_series < threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[diff_series >= threshold] = 0.0 # Increase = Bad\n",
        "    elif col_name in counter_cyclical_vars:\n",
        "      state_col[series < -threshold] = 1.0 # Strong Decrease = Good\n",
        "      state_col[(series >= -threshold) & (series < threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[series >= threshold] = 0.0 # Increase = Bad\n",
        "    else:\n",
        "      state_col[series > threshold] = 1.0 # Strong Increase = Good\n",
        "      state_col[(series > -threshold) & (series <= threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[series <= -threshold] = 0.0 # Decrease = Bad\n",
        "\n",
        "    improvement_state_values[col_name] = state_col\n",
        "  # Average state calculation\n",
        "  di_series = improvement_state_values.mean(axis=1, skipna=True)\n",
        "  diffusion_indices[category_name + '__DI'] = di_series\n",
        "  print(f\"Calculated diffusion index for {category_name} ({len(valid_category_vars)} variables)\")\n",
        "\n",
        "X_cbdi_raw = pd.DataFrame(diffusion_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caoyzVbIo8Sh",
        "outputId": "7f1c4256-0f07-4c50-cb81-22d966342b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated diffusion index for Output_Income (16 variables)\n",
            "Calculated diffusion index for Labor_Market (31 variables)\n",
            "Calculated diffusion index for Housing (10 variables)\n",
            "Calculated diffusion index for Consumption_Orders_Inventories (7 variables)\n",
            "Calculated diffusion index for Money_Credit (13 variables)\n",
            "Calculated diffusion index for Interest_Rates_Spreads (17 variables)\n",
            "Calculated diffusion index for FX_Rates (4 variables)\n",
            "Calculated diffusion index for Prices (19 variables)\n",
            "Calculated diffusion index for Stock_Market (4 variables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding overall DI\n",
        "overall_data = X_imputed_core[list(all_grouped_vars_found)]\n",
        "overall_improvement_state_values = pd.DataFrame(index=overall_data.index, dtype=float)\n",
        "\n",
        "for col_name in overall_data.columns:\n",
        "    # Apply same logic as above to ALL variables used in groups\n",
        "    series = overall_data[col_name]\n",
        "    threshold = small_change_thresholds.get(col_name, 0)\n",
        "    state_col = pd.Series(index=series.index, dtype=float)\n",
        "    if col_name in level_log_positive_impact:\n",
        "        diff_series = series.diff(1)\n",
        "        state_col[diff_series > threshold] = 1.0\n",
        "        state_col[(diff_series > -threshold) & (diff_series <= threshold)] = 0.5\n",
        "        state_col[diff_series <= -threshold] = 0.0\n",
        "    elif col_name in level_log_negative_impact:\n",
        "        diff_series = series.diff(1);\n",
        "        state_col[diff_series < -threshold] = 1.0\n",
        "        state_col[(diff_series >= -threshold) & (diff_series < threshold)] = 0.5\n",
        "        state_col[diff_series >= threshold] = 0.0\n",
        "    elif col_name in counter_cyclical_vars:\n",
        "        state_col[series < -threshold] = 1.0\n",
        "        state_col[(series >= -threshold) & (series < threshold)] = 0.5\n",
        "        state_col[series >= threshold] = 0.0\n",
        "    else:\n",
        "        state_col[series > threshold] = 1.0\n",
        "        state_col[(series > -threshold) & (series <= threshold)] = 0.5\n",
        "        state_col[series <= -threshold] = 0.0\n",
        "    overall_improvement_state_values[col_name] = state_col\n",
        "\n",
        "X_cbdi_raw['Overall_DI'] = overall_improvement_state_values.mean(axis=1, skipna=True)\n",
        "print(X_cbdi_raw.head())\n",
        "print(f\"Total NaNs: {X_cbdi_raw.isna().sum().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds8GRDBPseAu",
        "outputId": "8e1282bd-22a3-4855-eb9f-8231bb1daeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Output_Income__DI  Labor_Market__DI  Housing__DI  \\\n",
            "Date                                                           \n",
            "1961-01-01            0.68750          0.362069          NaN   \n",
            "1961-02-01            0.46875          0.241935         0.60   \n",
            "1961-03-01            0.71875          0.612903         0.75   \n",
            "1961-04-01            0.96875          0.419355         0.25   \n",
            "1961-05-01            0.96875          0.612903         0.75   \n",
            "\n",
            "            Consumption_Orders_Inventories__DI  Money_Credit__DI  \\\n",
            "Date                                                               \n",
            "1961-01-01                            0.214286          0.423077   \n",
            "1961-02-01                            0.714286          0.423077   \n",
            "1961-03-01                            0.642857          0.615385   \n",
            "1961-04-01                            0.428571          0.576923   \n",
            "1961-05-01                            1.000000          0.653846   \n",
            "\n",
            "            Interest_Rates_Spreads__DI  FX_Rates__DI  Prices__DI  \\\n",
            "Date                                                               \n",
            "1961-01-01                    0.277778         0.625    0.342105   \n",
            "1961-02-01                    0.735294         0.375    0.710526   \n",
            "1961-03-01                    0.117647         0.375    0.236842   \n",
            "1961-04-01                    0.264706         0.750    0.447368   \n",
            "1961-05-01                    0.617647         0.500    0.631579   \n",
            "\n",
            "            Stock_Market__DI  Overall_DI  \n",
            "Date                                      \n",
            "1961-01-01          0.666667    0.420000  \n",
            "1961-02-01          0.500000    0.504132  \n",
            "1961-03-01          0.750000    0.508264  \n",
            "1961-04-01          0.500000    0.491736  \n",
            "1961-05-01          0.625000    0.698347  \n",
            "Total NaNs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if X_cbdi_raw.index[1:].equals(X_imputed_core.index[1:]):\n",
        "     print(\"Index alignment verified (ignoring first row potentially affected by diff()).\")\n",
        "else:\n",
        "     print(\"Index mismatch suspected\")\n",
        "\n",
        "X_cbdi_raw.to_pickle(\"X_cbdi_raw_3state.pkl\")\n",
        "print(\"3-State Category Diffusion Index DataFrame saved as X_cbdi_raw_3state.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPAhFDJOth91",
        "outputId": "4fec3331-ea1f-44a4-ee35-8569a9fe3020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index alignment verified (ignoring first row potentially affected by diff()).\n",
            "3-State Category Diffusion Index DataFrame saved as X_cbdi_raw_3state.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Factor-Based Diffusion Index"
      ],
      "metadata": {
        "id": "ZA1rKMXko70a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Calculating Factor-Based Diffusion Indices (Method 1: Sign-Based Contribution) ---\")\n",
        "\n",
        "if isinstance(sm_pca_results.loadings, pd.DataFrame):\n",
        "  loadings_df = sm_pca_results.loadings\n",
        "  print(\"Loadings appear to be a DataFrame.\")\n",
        "elif isinstance(sm_pca_results.loadings, np.ndarray):\n",
        "  print(\"Loadings are a NumPy array. Converting to DataFrame...\")\n",
        "  try:\n",
        "      factor_columns_generated = [f'Factor_{i+1}' for i in range(sm_pca_results.loadings.shape[1])]\n",
        "      variable_index = X_imputed_core.columns\n",
        "      loadings_df = pd.DataFrame(sm_pca_results.loadings,\n",
        "                                  index=variable_index,\n",
        "                                  columns=factor_columns_generated)\n",
        "      optimized_factors = X_factors_raw_final.columns\n",
        "      loadings_df = loadings_df[optimized_factors]\n",
        "      print(\"Conversion successful.\")\n",
        "  except Exception as e:\n",
        "    print(f\"ERROR converting loadings NumPy array to DataFrame: {e}\")\n",
        "    loadings_df = None # Indicate failure\n",
        "else:\n",
        "  print(\"ERROR: sm_pca_results.loadings is an unexpected type. Cannot proceed.\")\n",
        "  loadings_df = None\n",
        "\n",
        "if loadings_df is None:\n",
        "  print(\"Stopping FBDI calculation due to loading issues.\")\n",
        "  X_fbdi_raw_m1 = pd.DataFrame()\n",
        "  nan_check = pd.Series()\n",
        "else:\n",
        "  available_factors = list(X_factors_raw_final.columns)\n",
        "  factors_to_include = [f for f in ['Factor_1', 'Factor_2', 'Factor_3', 'Factor_4'] if f in available_factors]\n",
        "  print(f\" Factors used for FBDI calculation: {factors_to_include}\")\n",
        "\n",
        "  if not factors_to_include:\n",
        "    print(\"ERROR: None of the specified factors found. Skipping FBDI.\")\n",
        "    X_fbdi_raw_m1 = pd.DataFrame()\n",
        "    nan_check = pd.Series()\n",
        "  else:\n",
        "    fbdi_results = {} # Dictionary to store each factor's DI Series\n",
        "\n",
        "for factor_to_analyze in factors_to_include:\n",
        "  print(f\"\\n-- Calculating FBDI for: {factor_to_analyze} --\")\n",
        "\n",
        "  # Get the specific factor from factor dataframe\n",
        "  target_factor_series = X_factors_raw_final[factor_to_analyze]\n",
        "  print(f\"  NaNs check in input {factor_to_analyze}: {target_factor_series.isna().sum()}\")\n",
        "  if target_factor_series.isna().any():\n",
        "    print(f\"  ERROR: Input factor series {factor_to_analyze} contains NaNs!\")\n",
        "    continue\n",
        "\n",
        "  # Get the loadings\n",
        "  if factor_to_analyze not in loadings_df.columns:\n",
        "    print(f\"  ERROR: Loadings column for {factor_to_analyze} not found. Skipping.\")\n",
        "    continue\n",
        "  target_factor_loadings = loadings_df[factor_to_analyze] # This is a pandas Series (Var -> Loading)\n",
        "  if target_factor_loadings.isna().any():\n",
        "    print(f\"  ERROR: Loadings for {factor_to_analyze} contain NaNs!\")\n",
        "    continue\n",
        "\n",
        "  # Calculate Factor Difference\n",
        "  factor_diff = target_factor_series.diff(1)\n",
        "  print(f\"  NaNs check in factor_diff (expect <= 1): {factor_diff.isna().sum()}\")\n",
        "  if factor_diff.iloc[1:].isna().any(): # Check if unexpected NaNs exist beyond the first one\n",
        "    print(f\"  WARN: Unexpected NaNs found in factor_diff beyond the first row!\")\n",
        "\n",
        "  # Calculate Absolute Loadings and Total for normalization\n",
        "  absolute_loadings = target_factor_loadings.abs()\n",
        "\n",
        "  variables_in_analysis = X_imputed_core.columns\n",
        "  total_abs_loading = absolute_loadings.loc[variables_in_analysis].sum()\n",
        "  print(f\"  Total absolute loading for {factor_to_analyze} (across {len(variables_in_analysis)} vars): {total_abs_loading:.4f}\")\n",
        "\n",
        "  if pd.isna(total_abs_loading) or total_abs_loading < 1e-9:\n",
        "    print(f\"  ERROR: Total absolute loading is zero/NaN for {factor_to_analyze}. Skipping FBDI calculation.\")\n",
        "    fbdi_results[f'FBDI_Weighted_{factor_to_analyze}'] = pd.Series(np.nan, index=X_imputed_core.index)\n",
        "    continue\n",
        "\n",
        "  # Loop Through Variables and Accumulate Weighted States\n",
        "  fbdi_contrib_weighted = pd.Series(0.0, index=factor_diff.index)\n",
        "\n",
        "  for var_name in variables_in_analysis:\n",
        "    loading = target_factor_loadings.get(var_name) # Get scalar loading\n",
        "    abs_loading_val = absolute_loadings.get(var_name, 0) # Get scalar absolute loading\n",
        "\n",
        "    if loading is None or pd.isna(loading) or abs_loading_val == 0:\n",
        "      continue\n",
        "\n",
        "    # Calculate approximate change contribution\n",
        "    contribution_diff = loading * factor_diff\n",
        "\n",
        "    # Get the threshold specific to this variable\n",
        "    threshold = small_change_thresholds.get(var_name, 0)\n",
        "\n",
        "    # Determine state (0, 0.5, 1) based on the factor's push\n",
        "    state_col = pd.Series(0.5, index=contribution_diff.index, dtype=float) # Default neutral\n",
        "    state_col[contribution_diff > threshold] = 1.0  # Strong Positive Push\n",
        "    state_col[contribution_diff < -threshold] = 0.0 # Strong Negative Push\n",
        "    # Fill initial NaN in diff with neutral state\n",
        "    # (This should affect only the first row if factor_diff has only 1 NaN)\n",
        "    state_col = state_col.fillna(0.5)\n",
        "\n",
        "    # Accumulate state weighted by the absolute loading of the variable on this factor\n",
        "    fbdi_contrib_weighted += state_col * abs_loading_val\n",
        "\n",
        "  # Normalize\n",
        "  fbdi_series_method1 = fbdi_contrib_weighted / total_abs_loading\n",
        "  fbdi_results[f'FBDI_Weighted_{factor_to_analyze}'] = fbdi_series_method1\n",
        "  print(f\"  Finished calculating FBDI for {factor_to_analyze}.\")\n",
        "\n",
        "X_fbdi_raw_method1 = pd.DataFrame(fbdi_results)\n",
        "\n",
        "print(f\"\\nFactor-Based Diffusion Index DataFrame (Method 1 - Factors {factors_to_include}) head(15):\")\n",
        "print(X_fbdi_raw_method1.head(15))\n",
        "nan_check = X_fbdi_raw_method1.isna().sum()\n",
        "print(f\"NaN Check per column (expect <= 1 each):\\n{nan_check}\")\n",
        "total_nans = nan_check.sum()\n",
        "print(f\"Total NaNs: {total_nans}\")\n",
        "\n",
        "if (nan_check <= 1).all():\n",
        "  save_path = \"X_fbdi_raw_method1.pkl\" # Save locally in Colab session first\n",
        "  try:\n",
        "      X_fbdi_raw_method1.to_pickle(save_path)\n",
        "      print(f\"\\nSaved: {save_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"\\nERROR saving FBDI file: {e}\")\n",
        "else:\n",
        "  print(\"\\nERROR: Excessive NaNs (>1 per column) remain in FBDI Method 1. Not saved. Please debug.\")"
      ],
      "metadata": {
        "id": "W6sHrvXsqFmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7fdc4a-fec3-4dd9-d874-0b0c1c8e189a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Calculating Factor-Based Diffusion Indices (Method 1: Sign-Based Contribution) ---\n",
            "Loadings are a NumPy array. Converting to DataFrame...\n",
            "Conversion successful.\n",
            " Factors used for FBDI calculation: ['Factor_1', 'Factor_2', 'Factor_3', 'Factor_4']\n",
            "\n",
            "-- Calculating FBDI for: Factor_1 --\n",
            "  NaNs check in input Factor_1: 0\n",
            "  NaNs check in factor_diff (expect <= 1): 1\n",
            "  Total absolute loading for Factor_1 (across 121 vars): 8.2735\n",
            "  Finished calculating FBDI for Factor_1.\n",
            "\n",
            "-- Calculating FBDI for: Factor_2 --\n",
            "  NaNs check in input Factor_2: 0\n",
            "  NaNs check in factor_diff (expect <= 1): 1\n",
            "  Total absolute loading for Factor_2 (across 121 vars): 8.1727\n",
            "  Finished calculating FBDI for Factor_2.\n",
            "\n",
            "-- Calculating FBDI for: Factor_3 --\n",
            "  NaNs check in input Factor_3: 0\n",
            "  NaNs check in factor_diff (expect <= 1): 1\n",
            "  Total absolute loading for Factor_3 (across 121 vars): 8.2543\n",
            "  Finished calculating FBDI for Factor_3.\n",
            "\n",
            "-- Calculating FBDI for: Factor_4 --\n",
            "  NaNs check in input Factor_4: 0\n",
            "  NaNs check in factor_diff (expect <= 1): 1\n",
            "  Total absolute loading for Factor_4 (across 121 vars): 7.1796\n",
            "  Finished calculating FBDI for Factor_4.\n",
            "\n",
            "Factor-Based Diffusion Index DataFrame (Method 1 - Factors ['Factor_1', 'Factor_2', 'Factor_3', 'Factor_4']) head(15):\n",
            "            FBDI_Weighted_Factor_1  FBDI_Weighted_Factor_2  \\\n",
            "Date                                                         \n",
            "1961-01-01                0.500000                0.500000   \n",
            "1961-02-01                0.330285                0.500000   \n",
            "1961-03-01                0.780211                0.368977   \n",
            "1961-04-01                0.507770                0.590859   \n",
            "1961-05-01                0.754595                0.626968   \n",
            "1961-06-01                0.500000                0.392555   \n",
            "1961-07-01                0.237150                0.616363   \n",
            "1961-08-01                0.762850                0.381123   \n",
            "1961-09-01                0.209621                0.635441   \n",
            "1961-10-01                0.793104                0.487168   \n",
            "1961-11-01                0.545399                0.625606   \n",
            "1961-12-01                0.226528                0.434880   \n",
            "1962-01-01                0.224517                0.638276   \n",
            "1962-02-01                0.787792                0.590859   \n",
            "1962-03-01                0.224517                0.393307   \n",
            "\n",
            "            FBDI_Weighted_Factor_3  FBDI_Weighted_Factor_4  \n",
            "Date                                                        \n",
            "1961-01-01                0.500000                0.500000  \n",
            "1961-02-01                0.591349                0.505210  \n",
            "1961-03-01                0.406217                0.506898  \n",
            "1961-04-01                0.366302                0.494680  \n",
            "1961-05-01                0.598803                0.510316  \n",
            "1961-06-01                0.370487                0.485435  \n",
            "1961-07-01                0.584645                0.500000  \n",
            "1961-08-01                0.431122                0.506898  \n",
            "1961-09-01                0.612672                0.503983  \n",
            "1961-10-01                0.398504                0.506898  \n",
            "1961-11-01                0.637431                0.503983  \n",
            "1961-12-01                0.629513                0.486143  \n",
            "1962-01-01                0.637431                0.503983  \n",
            "1962-02-01                0.370905                0.509536  \n",
            "1962-03-01                0.488961                0.513891  \n",
            "NaN Check per column (expect <= 1 each):\n",
            "FBDI_Weighted_Factor_1    0\n",
            "FBDI_Weighted_Factor_2    0\n",
            "FBDI_Weighted_Factor_3    0\n",
            "FBDI_Weighted_Factor_4    0\n",
            "dtype: int64\n",
            "Total NaNs: 0\n",
            "\n",
            "Saved: X_fbdi_raw_method1.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_factor_loadings(loadings_df, factor_name, top_n=15):\n",
        "    \"\"\"Prints variables with highest positive/negative absolute loadings for a factor.\"\"\"\n",
        "    if factor_name not in loadings_df.columns:\n",
        "        print(f\"Factor '{factor_name}' not found in loadings DataFrame.\")\n",
        "        return\n",
        "    print(f\"\\\\n--- Analyzing Loadings for: {factor_name} ---\")\n",
        "\n",
        "    # Get loadings for this factor\n",
        "    factor_loadings = loadings_df[factor_name].copy()\n",
        "\n",
        "    # Calculate absolute loadings and sort\n",
        "    abs_loadings = factor_loadings.abs().sort_values(ascending=False)\n",
        "\n",
        "    # Get top N variables by absolute loading\n",
        "    top_vars = abs_loadings.head(top_n).index\n",
        "\n",
        "    # Show actual loadings\n",
        "    print(f\"Top {top_n} variables by Absolute Loading on {factor_name}:\")\n",
        "    print(loadings_df.loc[top_vars, [factor_name]].sort_values(by=factor_name, ascending=False)) # Sort by signed loading\n",
        "\n",
        "# Example: Analyze first 4 factors\n",
        "if not loadings_df.empty:\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_1')\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_2')\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_3')\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_4')\n",
        "else:\n",
        "     print(\"Loadings DataFrame is empty, cannot analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpuuGlWFIvBr",
        "outputId": "47808af9-013d-449d-d8a5-2068f6821336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n--- Analyzing Loadings for: Factor_1 ---\n",
            "Top 15 variables by Absolute Loading on Factor_1:\n",
            "           Factor_1\n",
            "UNRATE     0.173419\n",
            "DMANEMP   -0.171813\n",
            "IPBUSEQ   -0.174120\n",
            "CE16OV    -0.174648\n",
            "USTRADE   -0.174734\n",
            "SRVPRD    -0.176802\n",
            "IPFINAL   -0.176941\n",
            "CUMFNS    -0.178865\n",
            "USTPU     -0.179607\n",
            "MANEMP    -0.180079\n",
            "INDPRO    -0.182801\n",
            "IPFPNSS   -0.183592\n",
            "USGOOD    -0.185163\n",
            "PAYEMS    -0.185948\n",
            "IPMANSICS -0.187523\n",
            "\\n--- Analyzing Loadings for: Factor_2 ---\n",
            "Top 15 variables by Absolute Loading on Factor_2:\n",
            "                 Factor_2\n",
            "CUSR0000SAC      0.224511\n",
            "CUSR0000SA0L2    0.221779\n",
            "CPIAUCSL         0.216639\n",
            "CPITRNSL         0.215967\n",
            "DNDGRG3M086SBEA  0.215130\n",
            "CUSR0000SA0L5    0.212544\n",
            "PCEPI            0.209745\n",
            "CPIULFSL         0.203705\n",
            "WPSFD49502       0.193451\n",
            "WPSFD49207       0.188323\n",
            "WPSID61          0.186182\n",
            "PERMITW         -0.153338\n",
            "PERMIT          -0.156998\n",
            "HOUSTS          -0.158679\n",
            "HOUST           -0.173678\n",
            "\\n--- Analyzing Loadings for: Factor_3 ---\n",
            "Top 15 variables by Absolute Loading on Factor_3:\n",
            "                 Factor_3\n",
            "BAAFFM           0.192541\n",
            "AAAFFM           0.189945\n",
            "T10YFFM          0.179705\n",
            "PERMITW         -0.169773\n",
            "HOUSTW          -0.170307\n",
            "CPITRNSL        -0.172890\n",
            "PERMIT          -0.173291\n",
            "CPIULFSL        -0.177813\n",
            "PCEPI           -0.182231\n",
            "HOUST           -0.183399\n",
            "CUSR0000SA0L5   -0.190166\n",
            "CUSR0000SA0L2   -0.194451\n",
            "CPIAUCSL        -0.194883\n",
            "DNDGRG3M086SBEA -0.196602\n",
            "CUSR0000SAC     -0.197530\n",
            "\\n--- Analyzing Loadings for: Factor_4 ---\n",
            "Top 15 variables by Absolute Loading on Factor_4:\n",
            "           Factor_4\n",
            "T10YFFM   -0.161017\n",
            "T5YFFM    -0.165926\n",
            "FEDFUNDS  -0.173296\n",
            "COMPAPFFx -0.185354\n",
            "BAA       -0.200068\n",
            "TB3SMFFM  -0.204930\n",
            "T1YFFM    -0.206115\n",
            "TB6SMFFM  -0.208967\n",
            "AAA       -0.236329\n",
            "CP3Mx     -0.249030\n",
            "GS10      -0.259529\n",
            "TB3MS     -0.261793\n",
            "GS5       -0.277886\n",
            "TB6MS     -0.283023\n",
            "GS1       -0.294219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\n--- Calculating Recursive FBDI (NumPy Accumulation) ---\")\n",
        "\n",
        "RECURSION_START_DATE = '1961-01-01'\n",
        "N_FACTORS_FIXED_REC = 8 # Keep reasonable number fixed\n",
        "ALIGN_FACTOR = 'Factor_1'\n",
        "\n",
        "X_for_recursion = X_imputed_core.loc[X_imputed_core.index.min():last_usable_date].copy()\n",
        "dates_to_estimate = X_for_recursion.loc[RECURSION_START_DATE:].index\n",
        "num_steps = len(dates_to_estimate)\n",
        "first_window_sign_f1 = None\n",
        "\n",
        "latest_factor_estimates_array = np.full((num_steps, N_FACTORS_FIXED_REC), np.nan)\n",
        "\n",
        "scaler_rec = StandardScaler()\n",
        "pca_rec = PCA(n_components=N_FACTORS_FIXED_REC, random_state=42)\n",
        "\n",
        "start_time_rec_loop = time.time()\n",
        "print(f\"Starting recursive PCA loop from {RECURSION_START_DATE}...\")\n",
        "\n",
        "# Recursive Loop\n",
        "for i, t in enumerate(dates_to_estimate): # Use enumerate to get index 'i' for array\n",
        "  loop_step_start_rec = time.time()\n",
        "  print(f\" Processing t = {t.strftime('%Y-%m-%d')} ({i+1}/{num_steps})...\", end=\"\")\n",
        "\n",
        "  X_upto_t = X_for_recursion.loc[:t]\n",
        "\n",
        "  if len(X_upto_t) < N_FACTORS_FIXED_REC + 10:\n",
        "    print(\" Skipping, window too small.\")\n",
        "\n",
        "    continue\n",
        "\n",
        "  try:\n",
        "    X_scaled_upto_t = scaler_rec.fit_transform(X_upto_t)\n",
        "    pca_rec.fit(X_scaled_upto_t)\n",
        "    factors_upto_t = pca_rec.transform(X_scaled_upto_t)\n",
        "    current_latest_factors = factors_upto_t[-1, :]\n",
        "\n",
        "    # Sign Alignment\n",
        "    if first_window_sign_f1 is None:\n",
        "      first_window_sign_f1 = np.sign(current_latest_factors[0])\n",
        "      if first_window_sign_f1 == 0: first_window_sign_f1 = 1\n",
        "    if np.sign(current_latest_factors[0]) != first_window_sign_f1:\n",
        "      current_latest_factors = -current_latest_factors\n",
        "\n",
        "    latest_factor_estimates_array[i, :] = current_latest_factors\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\" ERROR PCA at {t}: {e}. Storing NaNs.\")\n",
        "\n",
        "\n",
        "  print(f\" Step Time: {(time.time() - loop_step_start_rec):.2f}s\")\n",
        "\n",
        "print(f\"--- Recursive Loop Finished --- Total time: {(time.time() - start_time_rec_loop)/60:.2f} minutes ---\")\n",
        "\n",
        "\n",
        "print(\" Constructing Cumulative Recursive Factor Indices from NumPy array...\")\n",
        "# Convert NumPy array to DataFrame\n",
        "latest_factors_df = pd.DataFrame(\n",
        "  latest_factor_estimates_array,\n",
        "  index=dates_to_estimate,\n",
        "  columns=[f'Factor_{j+1}_Latest' for j in range(N_FACTORS_FIXED_REC)]\n",
        ")\n",
        "\n",
        "\n",
        "if latest_factors_df.empty:\n",
        "  print(\"ERROR: No valid factor estimates generated.\")\n",
        "\n",
        "else:\n",
        "  # Calculate cumulative sum\n",
        "  X_fbdi_raw_recursive = latest_factors_df.cumsum(axis=0)\n",
        "  X_fbdi_raw_recursive.columns = [f'RFDI_{i+1}' for i in range(X_fbdi_raw_recursive.shape[1])]\n",
        "\n",
        "\n",
        "  print(\"\\nRecursive Factor Diffusion Index (RFDI) DataFrame head(15):\")\n",
        "  print(X_fbdi_raw_recursive.head(15))\n",
        "  nan_check = X_fbdi_raw_recursive.isna().sum()\n",
        "  print(f\"NaN Check:\\n{nan_check}\")\n",
        "\n",
        "  save_path = \"X_fbdi_raw_recursive.pkl\"\n",
        "  try:\n",
        "    X_fbdi_raw_recursive.to_pickle(save_path)\n",
        "    print(f\"\\nSaved: {save_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"\\nERROR saving RFDI file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AwKb9WPo32j",
        "outputId": "a60bed5f-71d1-4a22-c645-09e1f5f354fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n--- Calculating Recursive FBDI (NumPy Accumulation) ---\n",
            "Starting recursive PCA loop from 1961-01-01...\n",
            " Processing t = 1961-01-01 (1/765)... Skipping, window too small.\n",
            " Processing t = 1961-02-01 (2/765)... Skipping, window too small.\n",
            " Processing t = 1961-03-01 (3/765)... Skipping, window too small.\n",
            " Processing t = 1961-04-01 (4/765)... Skipping, window too small.\n",
            " Processing t = 1961-05-01 (5/765)... Skipping, window too small.\n",
            " Processing t = 1961-06-01 (6/765)... Skipping, window too small.\n",
            " Processing t = 1961-07-01 (7/765)... Skipping, window too small.\n",
            " Processing t = 1961-08-01 (8/765)... Skipping, window too small.\n",
            " Processing t = 1961-09-01 (9/765)... Skipping, window too small.\n",
            " Processing t = 1961-10-01 (10/765)... Skipping, window too small.\n",
            " Processing t = 1961-11-01 (11/765)... Skipping, window too small.\n",
            " Processing t = 1961-12-01 (12/765)... Skipping, window too small.\n",
            " Processing t = 1962-01-01 (13/765)... Skipping, window too small.\n",
            " Processing t = 1962-02-01 (14/765)... Skipping, window too small.\n",
            " Processing t = 1962-03-01 (15/765)... Skipping, window too small.\n",
            " Processing t = 1962-04-01 (16/765)... Skipping, window too small.\n",
            " Processing t = 1962-05-01 (17/765)... Skipping, window too small.\n",
            " Processing t = 1962-06-01 (18/765)... Step Time: 0.02s\n",
            " Processing t = 1962-07-01 (19/765)... Step Time: 0.01s\n",
            " Processing t = 1962-08-01 (20/765)... Step Time: 0.01s\n",
            " Processing t = 1962-09-01 (21/765)... Step Time: 0.02s\n",
            " Processing t = 1962-10-01 (22/765)... Step Time: 0.04s\n",
            " Processing t = 1962-11-01 (23/765)... Step Time: 0.03s\n",
            " Processing t = 1962-12-01 (24/765)... Step Time: 0.03s\n",
            " Processing t = 1963-01-01 (25/765)... Step Time: 0.01s\n",
            " Processing t = 1963-02-01 (26/765)... Step Time: 0.01s\n",
            " Processing t = 1963-03-01 (27/765)... Step Time: 0.01s\n",
            " Processing t = 1963-04-01 (28/765)... Step Time: 0.01s\n",
            " Processing t = 1963-05-01 (29/765)... Step Time: 0.01s\n",
            " Processing t = 1963-06-01 (30/765)... Step Time: 0.02s\n",
            " Processing t = 1963-07-01 (31/765)... Step Time: 0.01s\n",
            " Processing t = 1963-08-01 (32/765)... Step Time: 0.02s\n",
            " Processing t = 1963-09-01 (33/765)... Step Time: 0.01s\n",
            " Processing t = 1963-10-01 (34/765)... Step Time: 0.01s\n",
            " Processing t = 1963-11-01 (35/765)... Step Time: 0.01s\n",
            " Processing t = 1963-12-01 (36/765)... Step Time: 0.01s\n",
            " Processing t = 1964-01-01 (37/765)... Step Time: 0.01s\n",
            " Processing t = 1964-02-01 (38/765)... Step Time: 0.01s\n",
            " Processing t = 1964-03-01 (39/765)... Step Time: 0.01s\n",
            " Processing t = 1964-04-01 (40/765)... Step Time: 0.05s\n",
            " Processing t = 1964-05-01 (41/765)... Step Time: 0.02s\n",
            " Processing t = 1964-06-01 (42/765)... Step Time: 0.03s\n",
            " Processing t = 1964-07-01 (43/765)... Step Time: 0.22s\n",
            " Processing t = 1964-08-01 (44/765)... Step Time: 0.05s\n",
            " Processing t = 1964-09-01 (45/765)... Step Time: 0.01s\n",
            " Processing t = 1964-10-01 (46/765)... Step Time: 0.01s\n",
            " Processing t = 1964-11-01 (47/765)... Step Time: 0.03s\n",
            " Processing t = 1964-12-01 (48/765)... Step Time: 0.06s\n",
            " Processing t = 1965-01-01 (49/765)... Step Time: 0.03s\n",
            " Processing t = 1965-02-01 (50/765)... Step Time: 0.06s\n",
            " Processing t = 1965-03-01 (51/765)... Step Time: 0.04s\n",
            " Processing t = 1965-04-01 (52/765)... Step Time: 0.02s\n",
            " Processing t = 1965-05-01 (53/765)... Step Time: 0.01s\n",
            " Processing t = 1965-06-01 (54/765)... Step Time: 0.07s\n",
            " Processing t = 1965-07-01 (55/765)... Step Time: 0.02s\n",
            " Processing t = 1965-08-01 (56/765)... Step Time: 0.31s\n",
            " Processing t = 1965-09-01 (57/765)... Step Time: 0.05s\n",
            " Processing t = 1965-10-01 (58/765)... Step Time: 0.02s\n",
            " Processing t = 1965-11-01 (59/765)... Step Time: 0.02s\n",
            " Processing t = 1965-12-01 (60/765)... Step Time: 0.03s\n",
            " Processing t = 1966-01-01 (61/765)... Step Time: 0.02s\n",
            " Processing t = 1966-02-01 (62/765)... Step Time: 0.02s\n",
            " Processing t = 1966-03-01 (63/765)... Step Time: 0.06s\n",
            " Processing t = 1966-04-01 (64/765)... Step Time: 0.02s\n",
            " Processing t = 1966-05-01 (65/765)... Step Time: 0.35s\n",
            " Processing t = 1966-06-01 (66/765)... Step Time: 0.16s\n",
            " Processing t = 1966-07-01 (67/765)... Step Time: 0.02s\n",
            " Processing t = 1966-08-01 (68/765)... Step Time: 0.24s\n",
            " Processing t = 1966-09-01 (69/765)... Step Time: 0.40s\n",
            " Processing t = 1966-10-01 (70/765)... Step Time: 0.27s\n",
            " Processing t = 1966-11-01 (71/765)... Step Time: 0.03s\n",
            " Processing t = 1966-12-01 (72/765)... Step Time: 0.04s\n",
            " Processing t = 1967-01-01 (73/765)... Step Time: 0.03s\n",
            " Processing t = 1967-02-01 (74/765)... Step Time: 0.03s\n",
            " Processing t = 1967-03-01 (75/765)... Step Time: 0.02s\n",
            " Processing t = 1967-04-01 (76/765)... Step Time: 0.02s\n",
            " Processing t = 1967-05-01 (77/765)... Step Time: 0.04s\n",
            " Processing t = 1967-06-01 (78/765)... Step Time: 0.02s\n",
            " Processing t = 1967-07-01 (79/765)... Step Time: 0.02s\n",
            " Processing t = 1967-08-01 (80/765)... Step Time: 0.02s\n",
            " Processing t = 1967-09-01 (81/765)... Step Time: 0.02s\n",
            " Processing t = 1967-10-01 (82/765)... Step Time: 0.02s\n",
            " Processing t = 1967-11-01 (83/765)... Step Time: 0.03s\n",
            " Processing t = 1967-12-01 (84/765)... Step Time: 0.02s\n",
            " Processing t = 1968-01-01 (85/765)... Step Time: 0.01s\n",
            " Processing t = 1968-02-01 (86/765)... Step Time: 0.03s\n",
            " Processing t = 1968-03-01 (87/765)... Step Time: 0.02s\n",
            " Processing t = 1968-04-01 (88/765)... Step Time: 0.01s\n",
            " Processing t = 1968-05-01 (89/765)... Step Time: 0.01s\n",
            " Processing t = 1968-06-01 (90/765)... Step Time: 0.01s\n",
            " Processing t = 1968-07-01 (91/765)... Step Time: 0.01s\n",
            " Processing t = 1968-08-01 (92/765)... Step Time: 0.02s\n",
            " Processing t = 1968-09-01 (93/765)... Step Time: 0.01s\n",
            " Processing t = 1968-10-01 (94/765)... Step Time: 0.01s\n",
            " Processing t = 1968-11-01 (95/765)... Step Time: 0.01s\n",
            " Processing t = 1968-12-01 (96/765)... Step Time: 0.01s\n",
            " Processing t = 1969-01-01 (97/765)... Step Time: 0.10s\n",
            " Processing t = 1969-02-01 (98/765)... Step Time: 0.06s\n",
            " Processing t = 1969-03-01 (99/765)... Step Time: 0.03s\n",
            " Processing t = 1969-04-01 (100/765)... Step Time: 0.02s\n",
            " Processing t = 1969-05-01 (101/765)... Step Time: 0.02s\n",
            " Processing t = 1969-06-01 (102/765)... Step Time: 0.03s\n",
            " Processing t = 1969-07-01 (103/765)... Step Time: 0.03s\n",
            " Processing t = 1969-08-01 (104/765)... Step Time: 0.01s\n",
            " Processing t = 1969-09-01 (105/765)... Step Time: 0.04s\n",
            " Processing t = 1969-10-01 (106/765)... Step Time: 0.03s\n",
            " Processing t = 1969-11-01 (107/765)... Step Time: 0.03s\n",
            " Processing t = 1969-12-01 (108/765)... Step Time: 0.02s\n",
            " Processing t = 1970-01-01 (109/765)... Step Time: 0.09s\n",
            " Processing t = 1970-02-01 (110/765)... Step Time: 0.02s\n",
            " Processing t = 1970-03-01 (111/765)... Step Time: 0.02s\n",
            " Processing t = 1970-04-01 (112/765)... Step Time: 0.03s\n",
            " Processing t = 1970-05-01 (113/765)... Step Time: 0.66s\n",
            " Processing t = 1970-06-01 (114/765)... Step Time: 0.03s\n",
            " Processing t = 1970-07-01 (115/765)... Step Time: 0.02s\n",
            " Processing t = 1970-08-01 (116/765)... Step Time: 0.01s\n",
            " Processing t = 1970-09-01 (117/765)... Step Time: 0.41s\n",
            " Processing t = 1970-10-01 (118/765)... Step Time: 0.07s\n",
            " Processing t = 1970-11-01 (119/765)... Step Time: 0.04s\n",
            " Processing t = 1970-12-01 (120/765)... Step Time: 0.02s\n",
            " Processing t = 1971-01-01 (121/765)... Step Time: 0.11s\n",
            " Processing t = 1971-02-01 (122/765)... Step Time: 0.03s\n",
            " Processing t = 1971-03-01 (123/765)... Step Time: 0.04s\n",
            " Processing t = 1971-04-01 (124/765)... Step Time: 0.05s\n",
            " Processing t = 1971-05-01 (125/765)... Step Time: 0.03s\n",
            " Processing t = 1971-06-01 (126/765)... Step Time: 0.04s\n",
            " Processing t = 1971-07-01 (127/765)... Step Time: 0.08s\n",
            " Processing t = 1971-08-01 (128/765)... Step Time: 0.03s\n",
            " Processing t = 1971-09-01 (129/765)... Step Time: 0.03s\n",
            " Processing t = 1971-10-01 (130/765)... Step Time: 0.02s\n",
            " Processing t = 1971-11-01 (131/765)... Step Time: 0.02s\n",
            " Processing t = 1971-12-01 (132/765)... Step Time: 0.02s\n",
            " Processing t = 1972-01-01 (133/765)... Step Time: 0.04s\n",
            " Processing t = 1972-02-01 (134/765)... Step Time: 0.03s\n",
            " Processing t = 1972-03-01 (135/765)... Step Time: 0.02s\n",
            " Processing t = 1972-04-01 (136/765)... Step Time: 0.03s\n",
            " Processing t = 1972-05-01 (137/765)... Step Time: 0.02s\n",
            " Processing t = 1972-06-01 (138/765)... Step Time: 0.02s\n",
            " Processing t = 1972-07-01 (139/765)... Step Time: 0.04s\n",
            " Processing t = 1972-08-01 (140/765)... Step Time: 0.10s\n",
            " Processing t = 1972-09-01 (141/765)... Step Time: 0.03s\n",
            " Processing t = 1972-10-01 (142/765)... Step Time: 0.05s\n",
            " Processing t = 1972-11-01 (143/765)... Step Time: 0.04s\n",
            " Processing t = 1972-12-01 (144/765)... Step Time: 0.06s\n",
            " Processing t = 1973-01-01 (145/765)... Step Time: 0.03s\n",
            " Processing t = 1973-02-01 (146/765)... Step Time: 0.04s\n",
            " Processing t = 1973-03-01 (147/765)... Step Time: 0.01s\n",
            " Processing t = 1973-04-01 (148/765)... Step Time: 0.03s\n",
            " Processing t = 1973-05-01 (149/765)... Step Time: 0.03s\n",
            " Processing t = 1973-06-01 (150/765)... Step Time: 0.03s\n",
            " Processing t = 1973-07-01 (151/765)... Step Time: 0.02s\n",
            " Processing t = 1973-08-01 (152/765)... Step Time: 0.02s\n",
            " Processing t = 1973-09-01 (153/765)... Step Time: 0.01s\n",
            " Processing t = 1973-10-01 (154/765)... Step Time: 0.02s\n",
            " Processing t = 1973-11-01 (155/765)... Step Time: 0.01s\n",
            " Processing t = 1973-12-01 (156/765)... Step Time: 0.02s\n",
            " Processing t = 1974-01-01 (157/765)... Step Time: 0.02s\n",
            " Processing t = 1974-02-01 (158/765)... Step Time: 0.03s\n",
            " Processing t = 1974-03-01 (159/765)... Step Time: 0.04s\n",
            " Processing t = 1974-04-01 (160/765)... Step Time: 0.04s\n",
            " Processing t = 1974-05-01 (161/765)... Step Time: 0.03s\n",
            " Processing t = 1974-06-01 (162/765)... Step Time: 0.03s\n",
            " Processing t = 1974-07-01 (163/765)... Step Time: 0.08s\n",
            " Processing t = 1974-08-01 (164/765)... Step Time: 0.03s\n",
            " Processing t = 1974-09-01 (165/765)... Step Time: 0.55s\n",
            " Processing t = 1974-10-01 (166/765)... Step Time: 0.02s\n",
            " Processing t = 1974-11-01 (167/765)... Step Time: 0.01s\n",
            " Processing t = 1974-12-01 (168/765)... Step Time: 0.02s\n",
            " Processing t = 1975-01-01 (169/765)... Step Time: 0.02s\n",
            " Processing t = 1975-02-01 (170/765)... Step Time: 0.04s\n",
            " Processing t = 1975-03-01 (171/765)... Step Time: 0.03s\n",
            " Processing t = 1975-04-01 (172/765)... Step Time: 0.04s\n",
            " Processing t = 1975-05-01 (173/765)... Step Time: 0.10s\n",
            " Processing t = 1975-06-01 (174/765)... Step Time: 0.03s\n",
            " Processing t = 1975-07-01 (175/765)... Step Time: 0.04s\n",
            " Processing t = 1975-08-01 (176/765)... Step Time: 0.04s\n",
            " Processing t = 1975-09-01 (177/765)... Step Time: 0.05s\n",
            " Processing t = 1975-10-01 (178/765)... Step Time: 0.09s\n",
            " Processing t = 1975-11-01 (179/765)... Step Time: 0.04s\n",
            " Processing t = 1975-12-01 (180/765)... Step Time: 0.04s\n",
            " Processing t = 1976-01-01 (181/765)... Step Time: 0.03s\n",
            " Processing t = 1976-02-01 (182/765)... Step Time: 0.02s\n",
            " Processing t = 1976-03-01 (183/765)... Step Time: 0.02s\n",
            " Processing t = 1976-04-01 (184/765)... Step Time: 0.03s\n",
            " Processing t = 1976-05-01 (185/765)... Step Time: 0.05s\n",
            " Processing t = 1976-06-01 (186/765)... Step Time: 0.02s\n",
            " Processing t = 1976-07-01 (187/765)... Step Time: 0.11s\n",
            " Processing t = 1976-08-01 (188/765)... Step Time: 0.58s\n",
            " Processing t = 1976-09-01 (189/765)... Step Time: 0.03s\n",
            " Processing t = 1976-10-01 (190/765)... Step Time: 0.06s\n",
            " Processing t = 1976-11-01 (191/765)... Step Time: 0.01s\n",
            " Processing t = 1976-12-01 (192/765)... Step Time: 0.01s\n",
            " Processing t = 1977-01-01 (193/765)... Step Time: 0.02s\n",
            " Processing t = 1977-02-01 (194/765)... Step Time: 0.07s\n",
            " Processing t = 1977-03-01 (195/765)... Step Time: 0.02s\n",
            " Processing t = 1977-04-01 (196/765)... Step Time: 0.03s\n",
            " Processing t = 1977-05-01 (197/765)... Step Time: 0.03s\n",
            " Processing t = 1977-06-01 (198/765)... Step Time: 0.04s\n",
            " Processing t = 1977-07-01 (199/765)... Step Time: 0.03s\n",
            " Processing t = 1977-08-01 (200/765)... Step Time: 0.03s\n",
            " Processing t = 1977-09-01 (201/765)... Step Time: 0.04s\n",
            " Processing t = 1977-10-01 (202/765)... Step Time: 0.06s\n",
            " Processing t = 1977-11-01 (203/765)... Step Time: 0.02s\n",
            " Processing t = 1977-12-01 (204/765)... Step Time: 0.05s\n",
            " Processing t = 1978-01-01 (205/765)... Step Time: 0.03s\n",
            " Processing t = 1978-02-01 (206/765)... Step Time: 0.36s\n",
            " Processing t = 1978-03-01 (207/765)... Step Time: 0.03s\n",
            " Processing t = 1978-04-01 (208/765)... Step Time: 0.01s\n",
            " Processing t = 1978-05-01 (209/765)... Step Time: 0.02s\n",
            " Processing t = 1978-06-01 (210/765)... Step Time: 0.02s\n",
            " Processing t = 1978-07-01 (211/765)... Step Time: 0.03s\n",
            " Processing t = 1978-08-01 (212/765)... Step Time: 0.06s\n",
            " Processing t = 1978-09-01 (213/765)... Step Time: 0.52s\n",
            " Processing t = 1978-10-01 (214/765)... Step Time: 0.59s\n",
            " Processing t = 1978-11-01 (215/765)... Step Time: 0.48s\n",
            " Processing t = 1978-12-01 (216/765)... Step Time: 1.60s\n",
            " Processing t = 1979-01-01 (217/765)... Step Time: 0.90s\n",
            " Processing t = 1979-02-01 (218/765)... Step Time: 0.20s\n",
            " Processing t = 1979-03-01 (219/765)... Step Time: 0.23s\n",
            " Processing t = 1979-04-01 (220/765)... Step Time: 0.38s\n",
            " Processing t = 1979-05-01 (221/765)... Step Time: 0.22s\n",
            " Processing t = 1979-06-01 (222/765)... Step Time: 0.24s\n",
            " Processing t = 1979-07-01 (223/765)... Step Time: 0.11s\n",
            " Processing t = 1979-08-01 (224/765)... Step Time: 0.10s\n",
            " Processing t = 1979-09-01 (225/765)... Step Time: 0.12s\n",
            " Processing t = 1979-10-01 (226/765)... Step Time: 0.08s\n",
            " Processing t = 1979-11-01 (227/765)... Step Time: 0.09s\n",
            " Processing t = 1979-12-01 (228/765)... Step Time: 0.07s\n",
            " Processing t = 1980-01-01 (229/765)... Step Time: 0.08s\n",
            " Processing t = 1980-02-01 (230/765)... Step Time: 0.14s\n",
            " Processing t = 1980-03-01 (231/765)... Step Time: 0.07s\n",
            " Processing t = 1980-04-01 (232/765)... Step Time: 0.50s\n",
            " Processing t = 1980-05-01 (233/765)... Step Time: 0.06s\n",
            " Processing t = 1980-06-01 (234/765)... Step Time: 0.36s\n",
            " Processing t = 1980-07-01 (235/765)... Step Time: 0.03s\n",
            " Processing t = 1980-08-01 (236/765)... Step Time: 0.02s\n",
            " Processing t = 1980-09-01 (237/765)... Step Time: 0.03s\n",
            " Processing t = 1980-10-01 (238/765)... Step Time: 0.02s\n",
            " Processing t = 1980-11-01 (239/765)... Step Time: 0.04s\n",
            " Processing t = 1980-12-01 (240/765)... Step Time: 0.04s\n",
            " Processing t = 1981-01-01 (241/765)... Step Time: 0.05s\n",
            " Processing t = 1981-02-01 (242/765)... Step Time: 0.04s\n",
            " Processing t = 1981-03-01 (243/765)... Step Time: 0.03s\n",
            " Processing t = 1981-04-01 (244/765)... Step Time: 0.02s\n",
            " Processing t = 1981-05-01 (245/765)... Step Time: 0.06s\n",
            " Processing t = 1981-06-01 (246/765)... Step Time: 0.28s\n",
            " Processing t = 1981-07-01 (247/765)... Step Time: 0.05s\n",
            " Processing t = 1981-08-01 (248/765)... Step Time: 0.03s\n",
            " Processing t = 1981-09-01 (249/765)... Step Time: 0.05s\n",
            " Processing t = 1981-10-01 (250/765)... Step Time: 0.11s\n",
            " Processing t = 1981-11-01 (251/765)... Step Time: 0.05s\n",
            " Processing t = 1981-12-01 (252/765)... Step Time: 0.03s\n",
            " Processing t = 1982-01-01 (253/765)... Step Time: 0.06s\n",
            " Processing t = 1982-02-01 (254/765)... Step Time: 0.05s\n",
            " Processing t = 1982-03-01 (255/765)... Step Time: 0.06s\n",
            " Processing t = 1982-04-01 (256/765)... Step Time: 0.04s\n",
            " Processing t = 1982-05-01 (257/765)... Step Time: 0.30s\n",
            " Processing t = 1982-06-01 (258/765)... Step Time: 0.04s\n",
            " Processing t = 1982-07-01 (259/765)... Step Time: 0.02s\n",
            " Processing t = 1982-08-01 (260/765)... Step Time: 0.02s\n",
            " Processing t = 1982-09-01 (261/765)... Step Time: 0.04s\n",
            " Processing t = 1982-10-01 (262/765)... Step Time: 0.04s\n",
            " Processing t = 1982-11-01 (263/765)... Step Time: 0.04s\n",
            " Processing t = 1982-12-01 (264/765)... Step Time: 0.04s\n",
            " Processing t = 1983-01-01 (265/765)... Step Time: 0.03s\n",
            " Processing t = 1983-02-01 (266/765)... Step Time: 0.07s\n",
            " Processing t = 1983-03-01 (267/765)... Step Time: 0.09s\n",
            " Processing t = 1983-04-01 (268/765)... Step Time: 0.03s\n",
            " Processing t = 1983-05-01 (269/765)... Step Time: 0.03s\n",
            " Processing t = 1983-06-01 (270/765)... Step Time: 0.70s\n",
            " Processing t = 1983-07-01 (271/765)... Step Time: 0.05s\n",
            " Processing t = 1983-08-01 (272/765)... Step Time: 0.04s\n",
            " Processing t = 1983-09-01 (273/765)... Step Time: 0.06s\n",
            " Processing t = 1983-10-01 (274/765)... Step Time: 0.14s\n",
            " Processing t = 1983-11-01 (275/765)... Step Time: 0.10s\n",
            " Processing t = 1983-12-01 (276/765)... Step Time: 0.03s\n",
            " Processing t = 1984-01-01 (277/765)... Step Time: 0.04s\n",
            " Processing t = 1984-02-01 (278/765)... Step Time: 0.05s\n",
            " Processing t = 1984-03-01 (279/765)... Step Time: 0.05s\n",
            " Processing t = 1984-04-01 (280/765)... Step Time: 0.05s\n",
            " Processing t = 1984-05-01 (281/765)... Step Time: 0.05s\n",
            " Processing t = 1984-06-01 (282/765)... Step Time: 0.03s\n",
            " Processing t = 1984-07-01 (283/765)... Step Time: 0.04s\n",
            " Processing t = 1984-08-01 (284/765)... Step Time: 0.03s\n",
            " Processing t = 1984-09-01 (285/765)... Step Time: 0.07s\n",
            " Processing t = 1984-10-01 (286/765)... Step Time: 0.07s\n",
            " Processing t = 1984-11-01 (287/765)... Step Time: 0.06s\n",
            " Processing t = 1984-12-01 (288/765)... Step Time: 0.04s\n",
            " Processing t = 1985-01-01 (289/765)... Step Time: 0.05s\n",
            " Processing t = 1985-02-01 (290/765)... Step Time: 0.08s\n",
            " Processing t = 1985-03-01 (291/765)... Step Time: 0.03s\n",
            " Processing t = 1985-04-01 (292/765)... Step Time: 0.04s\n",
            " Processing t = 1985-05-01 (293/765)... Step Time: 0.12s\n",
            " Processing t = 1985-06-01 (294/765)... Step Time: 0.04s\n",
            " Processing t = 1985-07-01 (295/765)... Step Time: 0.05s\n",
            " Processing t = 1985-08-01 (296/765)... Step Time: 0.05s\n",
            " Processing t = 1985-09-01 (297/765)... Step Time: 0.04s\n",
            " Processing t = 1985-10-01 (298/765)... Step Time: 0.26s\n",
            " Processing t = 1985-11-01 (299/765)... Step Time: 0.05s\n",
            " Processing t = 1985-12-01 (300/765)... Step Time: 0.03s\n",
            " Processing t = 1986-01-01 (301/765)... Step Time: 0.02s\n",
            " Processing t = 1986-02-01 (302/765)... Step Time: 0.04s\n",
            " Processing t = 1986-03-01 (303/765)... Step Time: 0.04s\n",
            " Processing t = 1986-04-01 (304/765)... Step Time: 0.04s\n",
            " Processing t = 1986-05-01 (305/765)... Step Time: 0.05s\n",
            " Processing t = 1986-06-01 (306/765)... Step Time: 0.13s\n",
            " Processing t = 1986-07-01 (307/765)... Step Time: 0.73s\n",
            " Processing t = 1986-08-01 (308/765)... Step Time: 0.21s\n",
            " Processing t = 1986-09-01 (309/765)... Step Time: 0.07s\n",
            " Processing t = 1986-10-01 (310/765)... Step Time: 0.05s\n",
            " Processing t = 1986-11-01 (311/765)... Step Time: 0.10s\n",
            " Processing t = 1986-12-01 (312/765)... Step Time: 0.06s\n",
            " Processing t = 1987-01-01 (313/765)... Step Time: 0.05s\n",
            " Processing t = 1987-02-01 (314/765)... Step Time: 0.07s\n",
            " Processing t = 1987-03-01 (315/765)... Step Time: 0.03s\n",
            " Processing t = 1987-04-01 (316/765)... Step Time: 0.04s\n",
            " Processing t = 1987-05-01 (317/765)... Step Time: 0.04s\n",
            " Processing t = 1987-06-01 (318/765)... Step Time: 0.31s\n",
            " Processing t = 1987-07-01 (319/765)... Step Time: 0.27s\n",
            " Processing t = 1987-08-01 (320/765)... Step Time: 0.05s\n",
            " Processing t = 1987-09-01 (321/765)... Step Time: 0.08s\n",
            " Processing t = 1987-10-01 (322/765)... Step Time: 0.04s\n",
            " Processing t = 1987-11-01 (323/765)... Step Time: 0.03s\n",
            " Processing t = 1987-12-01 (324/765)... Step Time: 0.07s\n",
            " Processing t = 1988-01-01 (325/765)... Step Time: 0.04s\n",
            " Processing t = 1988-02-01 (326/765)... Step Time: 0.06s\n",
            " Processing t = 1988-03-01 (327/765)... Step Time: 0.06s\n",
            " Processing t = 1988-04-01 (328/765)... Step Time: 0.06s\n",
            " Processing t = 1988-05-01 (329/765)... Step Time: 0.10s\n",
            " Processing t = 1988-06-01 (330/765)... Step Time: 0.05s\n",
            " Processing t = 1988-07-01 (331/765)... Step Time: 0.03s\n",
            " Processing t = 1988-08-01 (332/765)... Step Time: 0.14s\n",
            " Processing t = 1988-09-01 (333/765)... Step Time: 0.10s\n",
            " Processing t = 1988-10-01 (334/765)... Step Time: 0.08s\n",
            " Processing t = 1988-11-01 (335/765)... Step Time: 0.12s\n",
            " Processing t = 1988-12-01 (336/765)... Step Time: 0.06s\n",
            " Processing t = 1989-01-01 (337/765)... Step Time: 0.06s\n",
            " Processing t = 1989-02-01 (338/765)... Step Time: 0.03s\n",
            " Processing t = 1989-03-01 (339/765)... Step Time: 0.48s\n",
            " Processing t = 1989-04-01 (340/765)... Step Time: 0.13s\n",
            " Processing t = 1989-05-01 (341/765)... Step Time: 0.09s\n",
            " Processing t = 1989-06-01 (342/765)... Step Time: 0.05s\n",
            " Processing t = 1989-07-01 (343/765)... Step Time: 0.06s\n",
            " Processing t = 1989-08-01 (344/765)... Step Time: 0.05s\n",
            " Processing t = 1989-09-01 (345/765)... Step Time: 0.06s\n",
            " Processing t = 1989-10-01 (346/765)... Step Time: 0.05s\n",
            " Processing t = 1989-11-01 (347/765)... Step Time: 0.39s\n",
            " Processing t = 1989-12-01 (348/765)... Step Time: 0.56s\n",
            " Processing t = 1990-01-01 (349/765)... Step Time: 0.06s\n",
            " Processing t = 1990-02-01 (350/765)... Step Time: 0.05s\n",
            " Processing t = 1990-03-01 (351/765)... Step Time: 0.09s\n",
            " Processing t = 1990-04-01 (352/765)... Step Time: 0.16s\n",
            " Processing t = 1990-05-01 (353/765)... Step Time: 0.18s\n",
            " Processing t = 1990-06-01 (354/765)... Step Time: 0.18s\n",
            " Processing t = 1990-07-01 (355/765)... Step Time: 0.12s\n",
            " Processing t = 1990-08-01 (356/765)... Step Time: 0.17s\n",
            " Processing t = 1990-09-01 (357/765)... Step Time: 0.61s\n",
            " Processing t = 1990-10-01 (358/765)... Step Time: 0.77s\n",
            " Processing t = 1990-11-01 (359/765)... Step Time: 0.11s\n",
            " Processing t = 1990-12-01 (360/765)... Step Time: 0.11s\n",
            " Processing t = 1991-01-01 (361/765)... Step Time: 0.07s\n",
            " Processing t = 1991-02-01 (362/765)... Step Time: 0.35s\n",
            " Processing t = 1991-03-01 (363/765)... Step Time: 0.05s\n",
            " Processing t = 1991-04-01 (364/765)... Step Time: 0.60s\n",
            " Processing t = 1991-05-01 (365/765)... Step Time: 0.02s\n",
            " Processing t = 1991-06-01 (366/765)... Step Time: 0.06s\n",
            " Processing t = 1991-07-01 (367/765)... Step Time: 0.08s\n",
            " Processing t = 1991-08-01 (368/765)... Step Time: 0.13s\n",
            " Processing t = 1991-09-01 (369/765)... Step Time: 0.06s\n",
            " Processing t = 1991-10-01 (370/765)... Step Time: 0.05s\n",
            " Processing t = 1991-11-01 (371/765)... Step Time: 0.04s\n",
            " Processing t = 1991-12-01 (372/765)... Step Time: 0.04s\n",
            " Processing t = 1992-01-01 (373/765)... Step Time: 0.03s\n",
            " Processing t = 1992-02-01 (374/765)... Step Time: 0.15s\n",
            " Processing t = 1992-03-01 (375/765)... Step Time: 0.06s\n",
            " Processing t = 1992-04-01 (376/765)... Step Time: 0.04s\n",
            " Processing t = 1992-05-01 (377/765)... Step Time: 0.06s\n",
            " Processing t = 1992-06-01 (378/765)... Step Time: 0.03s\n",
            " Processing t = 1992-07-01 (379/765)... Step Time: 0.18s\n",
            " Processing t = 1992-08-01 (380/765)... Step Time: 0.03s\n",
            " Processing t = 1992-09-01 (381/765)... Step Time: 0.04s\n",
            " Processing t = 1992-10-01 (382/765)... Step Time: 0.02s\n",
            " Processing t = 1992-11-01 (383/765)... Step Time: 0.06s\n",
            " Processing t = 1992-12-01 (384/765)... Step Time: 0.03s\n",
            " Processing t = 1993-01-01 (385/765)... Step Time: 0.08s\n",
            " Processing t = 1993-02-01 (386/765)... Step Time: 0.09s\n",
            " Processing t = 1993-03-01 (387/765)... Step Time: 0.03s\n",
            " Processing t = 1993-04-01 (388/765)... Step Time: 0.04s\n",
            " Processing t = 1993-05-01 (389/765)... Step Time: 0.03s\n",
            " Processing t = 1993-06-01 (390/765)... Step Time: 0.03s\n",
            " Processing t = 1993-07-01 (391/765)... Step Time: 0.02s\n",
            " Processing t = 1993-08-01 (392/765)... Step Time: 0.03s\n",
            " Processing t = 1993-09-01 (393/765)... Step Time: 0.04s\n",
            " Processing t = 1993-10-01 (394/765)... Step Time: 0.03s\n",
            " Processing t = 1993-11-01 (395/765)... Step Time: 0.03s\n",
            " Processing t = 1993-12-01 (396/765)... Step Time: 0.23s\n",
            " Processing t = 1994-01-01 (397/765)... Step Time: 0.04s\n",
            " Processing t = 1994-02-01 (398/765)... Step Time: 0.03s\n",
            " Processing t = 1994-03-01 (399/765)... Step Time: 0.03s\n",
            " Processing t = 1994-04-01 (400/765)... Step Time: 0.07s\n",
            " Processing t = 1994-05-01 (401/765)... Step Time: 0.04s\n",
            " Processing t = 1994-06-01 (402/765)... Step Time: 0.04s\n",
            " Processing t = 1994-07-01 (403/765)... Step Time: 0.04s\n",
            " Processing t = 1994-08-01 (404/765)... Step Time: 0.04s\n",
            " Processing t = 1994-09-01 (405/765)... Step Time: 0.02s\n",
            " Processing t = 1994-10-01 (406/765)... Step Time: 0.04s\n",
            " Processing t = 1994-11-01 (407/765)... Step Time: 0.11s\n",
            " Processing t = 1994-12-01 (408/765)... Step Time: 0.04s\n",
            " Processing t = 1995-01-01 (409/765)... Step Time: 0.03s\n",
            " Processing t = 1995-02-01 (410/765)... Step Time: 0.05s\n",
            " Processing t = 1995-03-01 (411/765)... Step Time: 0.03s\n",
            " Processing t = 1995-04-01 (412/765)... Step Time: 0.02s\n",
            " Processing t = 1995-05-01 (413/765)... Step Time: 0.08s\n",
            " Processing t = 1995-06-01 (414/765)... Step Time: 0.05s\n",
            " Processing t = 1995-07-01 (415/765)... Step Time: 0.06s\n",
            " Processing t = 1995-08-01 (416/765)... Step Time: 0.04s\n",
            " Processing t = 1995-09-01 (417/765)... Step Time: 0.03s\n",
            " Processing t = 1995-10-01 (418/765)... Step Time: 0.03s\n",
            " Processing t = 1995-11-01 (419/765)... Step Time: 0.02s\n",
            " Processing t = 1995-12-01 (420/765)... Step Time: 0.40s\n",
            " Processing t = 1996-01-01 (421/765)... Step Time: 0.05s\n",
            " Processing t = 1996-02-01 (422/765)... Step Time: 0.03s\n",
            " Processing t = 1996-03-01 (423/765)... Step Time: 0.04s\n",
            " Processing t = 1996-04-01 (424/765)... Step Time: 0.03s\n",
            " Processing t = 1996-05-01 (425/765)... Step Time: 0.17s\n",
            " Processing t = 1996-06-01 (426/765)... Step Time: 0.05s\n",
            " Processing t = 1996-07-01 (427/765)... Step Time: 0.04s\n",
            " Processing t = 1996-08-01 (428/765)... Step Time: 0.06s\n",
            " Processing t = 1996-09-01 (429/765)... Step Time: 0.04s\n",
            " Processing t = 1996-10-01 (430/765)... Step Time: 0.40s\n",
            " Processing t = 1996-11-01 (431/765)... Step Time: 0.07s\n",
            " Processing t = 1996-12-01 (432/765)... Step Time: 0.04s\n",
            " Processing t = 1997-01-01 (433/765)... Step Time: 0.04s\n",
            " Processing t = 1997-02-01 (434/765)... Step Time: 0.21s\n",
            " Processing t = 1997-03-01 (435/765)... Step Time: 0.33s\n",
            " Processing t = 1997-04-01 (436/765)... Step Time: 0.02s\n",
            " Processing t = 1997-05-01 (437/765)... Step Time: 0.04s\n",
            " Processing t = 1997-06-01 (438/765)... Step Time: 0.04s\n",
            " Processing t = 1997-07-01 (439/765)... Step Time: 0.04s\n",
            " Processing t = 1997-08-01 (440/765)... Step Time: 0.04s\n",
            " Processing t = 1997-09-01 (441/765)... Step Time: 0.28s\n",
            " Processing t = 1997-10-01 (442/765)... Step Time: 0.07s\n",
            " Processing t = 1997-11-01 (443/765)... Step Time: 0.04s\n",
            " Processing t = 1997-12-01 (444/765)... Step Time: 0.07s\n",
            " Processing t = 1998-01-01 (445/765)... Step Time: 0.04s\n",
            " Processing t = 1998-02-01 (446/765)... Step Time: 0.07s\n",
            " Processing t = 1998-03-01 (447/765)... Step Time: 0.06s\n",
            " Processing t = 1998-04-01 (448/765)... Step Time: 0.05s\n",
            " Processing t = 1998-05-01 (449/765)... Step Time: 0.04s\n",
            " Processing t = 1998-06-01 (450/765)... Step Time: 0.02s\n",
            " Processing t = 1998-07-01 (451/765)... Step Time: 0.07s\n",
            " Processing t = 1998-08-01 (452/765)... Step Time: 0.04s\n",
            " Processing t = 1998-09-01 (453/765)... Step Time: 0.04s\n",
            " Processing t = 1998-10-01 (454/765)... Step Time: 0.06s\n",
            " Processing t = 1998-11-01 (455/765)... Step Time: 0.08s\n",
            " Processing t = 1998-12-01 (456/765)... Step Time: 0.06s\n",
            " Processing t = 1999-01-01 (457/765)... Step Time: 0.17s\n",
            " Processing t = 1999-02-01 (458/765)... Step Time: 0.04s\n",
            " Processing t = 1999-03-01 (459/765)... Step Time: 0.05s\n",
            " Processing t = 1999-04-01 (460/765)... Step Time: 0.03s\n",
            " Processing t = 1999-05-01 (461/765)... Step Time: 0.03s\n",
            " Processing t = 1999-06-01 (462/765)... Step Time: 0.03s\n",
            " Processing t = 1999-07-01 (463/765)... Step Time: 0.03s\n",
            " Processing t = 1999-08-01 (464/765)... Step Time: 0.03s\n",
            " Processing t = 1999-09-01 (465/765)... Step Time: 0.02s\n",
            " Processing t = 1999-10-01 (466/765)... Step Time: 0.03s\n",
            " Processing t = 1999-11-01 (467/765)... Step Time: 0.41s\n",
            " Processing t = 1999-12-01 (468/765)... Step Time: 0.04s\n",
            " Processing t = 2000-01-01 (469/765)... Step Time: 0.04s\n",
            " Processing t = 2000-02-01 (470/765)... Step Time: 0.04s\n",
            " Processing t = 2000-03-01 (471/765)... Step Time: 0.03s\n",
            " Processing t = 2000-04-01 (472/765)... Step Time: 0.04s\n",
            " Processing t = 2000-05-01 (473/765)... Step Time: 0.22s\n",
            " Processing t = 2000-06-01 (474/765)... Step Time: 0.06s\n",
            " Processing t = 2000-07-01 (475/765)... Step Time: 0.04s\n",
            " Processing t = 2000-08-01 (476/765)... Step Time: 0.10s\n",
            " Processing t = 2000-09-01 (477/765)... Step Time: 0.04s\n",
            " Processing t = 2000-10-01 (478/765)... Step Time: 0.07s\n",
            " Processing t = 2000-11-01 (479/765)... Step Time: 0.03s\n",
            " Processing t = 2000-12-01 (480/765)... Step Time: 0.05s\n",
            " Processing t = 2001-01-01 (481/765)... Step Time: 0.03s\n",
            " Processing t = 2001-02-01 (482/765)... Step Time: 0.03s\n",
            " Processing t = 2001-03-01 (483/765)... Step Time: 0.12s\n",
            " Processing t = 2001-04-01 (484/765)... Step Time: 0.07s\n",
            " Processing t = 2001-05-01 (485/765)... Step Time: 0.16s\n",
            " Processing t = 2001-06-01 (486/765)... Step Time: 0.05s\n",
            " Processing t = 2001-07-01 (487/765)... Step Time: 0.04s\n",
            " Processing t = 2001-08-01 (488/765)... Step Time: 0.07s\n",
            " Processing t = 2001-09-01 (489/765)... Step Time: 0.03s\n",
            " Processing t = 2001-10-01 (490/765)... Step Time: 0.05s\n",
            " Processing t = 2001-11-01 (491/765)... Step Time: 0.04s\n",
            " Processing t = 2001-12-01 (492/765)... Step Time: 0.07s\n",
            " Processing t = 2002-01-01 (493/765)... Step Time: 0.04s\n",
            " Processing t = 2002-02-01 (494/765)... Step Time: 0.02s\n",
            " Processing t = 2002-03-01 (495/765)... Step Time: 0.03s\n",
            " Processing t = 2002-04-01 (496/765)... Step Time: 0.05s\n",
            " Processing t = 2002-05-01 (497/765)... Step Time: 0.04s\n",
            " Processing t = 2002-06-01 (498/765)... Step Time: 0.04s\n",
            " Processing t = 2002-07-01 (499/765)... Step Time: 0.04s\n",
            " Processing t = 2002-08-01 (500/765)... Step Time: 0.03s\n",
            " Processing t = 2002-09-01 (501/765)... Step Time: 0.03s\n",
            " Processing t = 2002-10-01 (502/765)... Step Time: 0.07s\n",
            " Processing t = 2002-11-01 (503/765)... Step Time: 0.11s\n",
            " Processing t = 2002-12-01 (504/765)... Step Time: 0.10s\n",
            " Processing t = 2003-01-01 (505/765)... Step Time: 0.05s\n",
            " Processing t = 2003-02-01 (506/765)... Step Time: 0.07s\n",
            " Processing t = 2003-03-01 (507/765)... Step Time: 0.13s\n",
            " Processing t = 2003-04-01 (508/765)... Step Time: 0.04s\n",
            " Processing t = 2003-05-01 (509/765)... Step Time: 0.05s\n",
            " Processing t = 2003-06-01 (510/765)... Step Time: 0.05s\n",
            " Processing t = 2003-07-01 (511/765)... Step Time: 0.13s\n",
            " Processing t = 2003-08-01 (512/765)... Step Time: 0.12s\n",
            " Processing t = 2003-09-01 (513/765)... Step Time: 0.06s\n",
            " Processing t = 2003-10-01 (514/765)... Step Time: 0.08s\n",
            " Processing t = 2003-11-01 (515/765)... Step Time: 0.05s\n",
            " Processing t = 2003-12-01 (516/765)... Step Time: 0.04s\n",
            " Processing t = 2004-01-01 (517/765)... Step Time: 0.02s\n",
            " Processing t = 2004-02-01 (518/765)... Step Time: 0.03s\n",
            " Processing t = 2004-03-01 (519/765)... Step Time: 0.09s\n",
            " Processing t = 2004-04-01 (520/765)... Step Time: 0.09s\n",
            " Processing t = 2004-05-01 (521/765)... Step Time: 0.10s\n",
            " Processing t = 2004-06-01 (522/765)... Step Time: 0.14s\n",
            " Processing t = 2004-07-01 (523/765)... Step Time: 0.11s\n",
            " Processing t = 2004-08-01 (524/765)... Step Time: 0.53s\n",
            " Processing t = 2004-09-01 (525/765)... Step Time: 0.35s\n",
            " Processing t = 2004-10-01 (526/765)... Step Time: 0.17s\n",
            " Processing t = 2004-11-01 (527/765)... Step Time: 0.12s\n",
            " Processing t = 2004-12-01 (528/765)... Step Time: 0.10s\n",
            " Processing t = 2005-01-01 (529/765)... Step Time: 0.18s\n",
            " Processing t = 2005-02-01 (530/765)... Step Time: 0.13s\n",
            " Processing t = 2005-03-01 (531/765)... Step Time: 0.12s\n",
            " Processing t = 2005-04-01 (532/765)... Step Time: 0.07s\n",
            " Processing t = 2005-05-01 (533/765)... Step Time: 0.06s\n",
            " Processing t = 2005-06-01 (534/765)... Step Time: 0.19s\n",
            " Processing t = 2005-07-01 (535/765)... Step Time: 0.19s\n",
            " Processing t = 2005-08-01 (536/765)... Step Time: 0.55s\n",
            " Processing t = 2005-09-01 (537/765)... Step Time: 0.13s\n",
            " Processing t = 2005-10-01 (538/765)... Step Time: 0.17s\n",
            " Processing t = 2005-11-01 (539/765)... Step Time: 0.15s\n",
            " Processing t = 2005-12-01 (540/765)... Step Time: 0.09s\n",
            " Processing t = 2006-01-01 (541/765)... Step Time: 0.29s\n",
            " Processing t = 2006-02-01 (542/765)... Step Time: 0.08s\n",
            " Processing t = 2006-03-01 (543/765)... Step Time: 0.21s\n",
            " Processing t = 2006-04-01 (544/765)... Step Time: 0.12s\n",
            " Processing t = 2006-05-01 (545/765)... Step Time: 0.12s\n",
            " Processing t = 2006-06-01 (546/765)... Step Time: 0.09s\n",
            " Processing t = 2006-07-01 (547/765)... Step Time: 0.06s\n",
            " Processing t = 2006-08-01 (548/765)... Step Time: 0.09s\n",
            " Processing t = 2006-09-01 (549/765)... Step Time: 0.09s\n",
            " Processing t = 2006-10-01 (550/765)... Step Time: 0.11s\n",
            " Processing t = 2006-11-01 (551/765)... Step Time: 0.12s\n",
            " Processing t = 2006-12-01 (552/765)... Step Time: 0.10s\n",
            " Processing t = 2007-01-01 (553/765)... Step Time: 0.11s\n",
            " Processing t = 2007-02-01 (554/765)... Step Time: 0.18s\n",
            " Processing t = 2007-03-01 (555/765)... Step Time: 0.13s\n",
            " Processing t = 2007-04-01 (556/765)... Step Time: 0.06s\n",
            " Processing t = 2007-05-01 (557/765)... Step Time: 0.03s\n",
            " Processing t = 2007-06-01 (558/765)... Step Time: 0.02s\n",
            " Processing t = 2007-07-01 (559/765)... Step Time: 0.03s\n",
            " Processing t = 2007-08-01 (560/765)... Step Time: 0.13s\n",
            " Processing t = 2007-09-01 (561/765)... Step Time: 0.03s\n",
            " Processing t = 2007-10-01 (562/765)... Step Time: 0.03s\n",
            " Processing t = 2007-11-01 (563/765)... Step Time: 0.10s\n",
            " Processing t = 2007-12-01 (564/765)... Step Time: 0.10s\n",
            " Processing t = 2008-01-01 (565/765)... Step Time: 0.04s\n",
            " Processing t = 2008-02-01 (566/765)... Step Time: 0.03s\n",
            " Processing t = 2008-03-01 (567/765)... Step Time: 0.11s\n",
            " Processing t = 2008-04-01 (568/765)... Step Time: 0.13s\n",
            " Processing t = 2008-05-01 (569/765)... Step Time: 0.12s\n",
            " Processing t = 2008-06-01 (570/765)... Step Time: 0.12s\n",
            " Processing t = 2008-07-01 (571/765)... Step Time: 0.14s\n",
            " Processing t = 2008-08-01 (572/765)... Step Time: 0.13s\n",
            " Processing t = 2008-09-01 (573/765)... Step Time: 0.06s\n",
            " Processing t = 2008-10-01 (574/765)... Step Time: 0.03s\n",
            " Processing t = 2008-11-01 (575/765)... Step Time: 0.03s\n",
            " Processing t = 2008-12-01 (576/765)... Step Time: 0.03s\n",
            " Processing t = 2009-01-01 (577/765)... Step Time: 0.03s\n",
            " Processing t = 2009-02-01 (578/765)... Step Time: 0.03s\n",
            " Processing t = 2009-03-01 (579/765)... Step Time: 0.13s\n",
            " Processing t = 2009-04-01 (580/765)... Step Time: 0.03s\n",
            " Processing t = 2009-05-01 (581/765)... Step Time: 0.09s\n",
            " Processing t = 2009-06-01 (582/765)... Step Time: 0.11s\n",
            " Processing t = 2009-07-01 (583/765)... Step Time: 0.09s\n",
            " Processing t = 2009-08-01 (584/765)... Step Time: 0.03s\n",
            " Processing t = 2009-09-01 (585/765)... Step Time: 0.13s\n",
            " Processing t = 2009-10-01 (586/765)... Step Time: 0.07s\n",
            " Processing t = 2009-11-01 (587/765)... Step Time: 0.15s\n",
            " Processing t = 2009-12-01 (588/765)... Step Time: 0.04s\n",
            " Processing t = 2010-01-01 (589/765)... Step Time: 0.03s\n",
            " Processing t = 2010-02-01 (590/765)... Step Time: 0.04s\n",
            " Processing t = 2010-03-01 (591/765)... Step Time: 0.04s\n",
            " Processing t = 2010-04-01 (592/765)... Step Time: 0.12s\n",
            " Processing t = 2010-05-01 (593/765)... Step Time: 0.04s\n",
            " Processing t = 2010-06-01 (594/765)... Step Time: 0.02s\n",
            " Processing t = 2010-07-01 (595/765)... Step Time: 0.03s\n",
            " Processing t = 2010-08-01 (596/765)... Step Time: 0.04s\n",
            " Processing t = 2010-09-01 (597/765)... Step Time: 0.04s\n",
            " Processing t = 2010-10-01 (598/765)... Step Time: 0.07s\n",
            " Processing t = 2010-11-01 (599/765)... Step Time: 0.09s\n",
            " Processing t = 2010-12-01 (600/765)... Step Time: 0.04s\n",
            " Processing t = 2011-01-01 (601/765)... Step Time: 0.04s\n",
            " Processing t = 2011-02-01 (602/765)... Step Time: 0.23s\n",
            " Processing t = 2011-03-01 (603/765)... Step Time: 0.18s\n",
            " Processing t = 2011-04-01 (604/765)... Step Time: 0.04s\n",
            " Processing t = 2011-05-01 (605/765)... Step Time: 0.21s\n",
            " Processing t = 2011-06-01 (606/765)... Step Time: 0.05s\n",
            " Processing t = 2011-07-01 (607/765)... Step Time: 0.03s\n",
            " Processing t = 2011-08-01 (608/765)... Step Time: 0.03s\n",
            " Processing t = 2011-09-01 (609/765)... Step Time: 0.03s\n",
            " Processing t = 2011-10-01 (610/765)... Step Time: 0.04s\n",
            " Processing t = 2011-11-01 (611/765)... Step Time: 0.03s\n",
            " Processing t = 2011-12-01 (612/765)... Step Time: 0.14s\n",
            " Processing t = 2012-01-01 (613/765)... Step Time: 0.14s\n",
            " Processing t = 2012-02-01 (614/765)... Step Time: 0.13s\n",
            " Processing t = 2012-03-01 (615/765)... Step Time: 0.13s\n",
            " Processing t = 2012-04-01 (616/765)... Step Time: 0.05s\n",
            " Processing t = 2012-05-01 (617/765)... Step Time: 0.04s\n",
            " Processing t = 2012-06-01 (618/765)... Step Time: 0.09s\n",
            " Processing t = 2012-07-01 (619/765)... Step Time: 0.05s\n",
            " Processing t = 2012-08-01 (620/765)... Step Time: 0.03s\n",
            " Processing t = 2012-09-01 (621/765)... Step Time: 0.16s\n",
            " Processing t = 2012-10-01 (622/765)... Step Time: 0.04s\n",
            " Processing t = 2012-11-01 (623/765)... Step Time: 0.12s\n",
            " Processing t = 2012-12-01 (624/765)... Step Time: 0.11s\n",
            " Processing t = 2013-01-01 (625/765)... Step Time: 0.06s\n",
            " Processing t = 2013-02-01 (626/765)... Step Time: 0.16s\n",
            " Processing t = 2013-03-01 (627/765)... Step Time: 0.17s\n",
            " Processing t = 2013-04-01 (628/765)... Step Time: 0.05s\n",
            " Processing t = 2013-05-01 (629/765)... Step Time: 0.03s\n",
            " Processing t = 2013-06-01 (630/765)... Step Time: 0.12s\n",
            " Processing t = 2013-07-01 (631/765)... Step Time: 0.03s\n",
            " Processing t = 2013-08-01 (632/765)... Step Time: 0.04s\n",
            " Processing t = 2013-09-01 (633/765)... Step Time: 0.05s\n",
            " Processing t = 2013-10-01 (634/765)... Step Time: 0.14s\n",
            " Processing t = 2013-11-01 (635/765)... Step Time: 0.04s\n",
            " Processing t = 2013-12-01 (636/765)... Step Time: 0.16s\n",
            " Processing t = 2014-01-01 (637/765)... Step Time: 0.05s\n",
            " Processing t = 2014-02-01 (638/765)... Step Time: 0.03s\n",
            " Processing t = 2014-03-01 (639/765)... Step Time: 0.15s\n",
            " Processing t = 2014-04-01 (640/765)... Step Time: 0.14s\n",
            " Processing t = 2014-05-01 (641/765)... Step Time: 0.19s\n",
            " Processing t = 2014-06-01 (642/765)... Step Time: 0.14s\n",
            " Processing t = 2014-07-01 (643/765)... Step Time: 0.06s\n",
            " Processing t = 2014-08-01 (644/765)... Step Time: 0.09s\n",
            " Processing t = 2014-09-01 (645/765)... Step Time: 0.03s\n",
            " Processing t = 2014-10-01 (646/765)... Step Time: 0.04s\n",
            " Processing t = 2014-11-01 (647/765)... Step Time: 0.14s\n",
            " Processing t = 2014-12-01 (648/765)... Step Time: 0.02s\n",
            " Processing t = 2015-01-01 (649/765)... Step Time: 0.03s\n",
            " Processing t = 2015-02-01 (650/765)... Step Time: 0.21s\n",
            " Processing t = 2015-03-01 (651/765)... Step Time: 0.04s\n",
            " Processing t = 2015-04-01 (652/765)... Step Time: 0.03s\n",
            " Processing t = 2015-05-01 (653/765)... Step Time: 0.04s\n",
            " Processing t = 2015-06-01 (654/765)... Step Time: 0.03s\n",
            " Processing t = 2015-07-01 (655/765)... Step Time: 0.12s\n",
            " Processing t = 2015-08-01 (656/765)... Step Time: 0.06s\n",
            " Processing t = 2015-09-01 (657/765)... Step Time: 0.04s\n",
            " Processing t = 2015-10-01 (658/765)... Step Time: 0.05s\n",
            " Processing t = 2015-11-01 (659/765)... Step Time: 0.03s\n",
            " Processing t = 2015-12-01 (660/765)... Step Time: 0.12s\n",
            " Processing t = 2016-01-01 (661/765)... Step Time: 0.13s\n",
            " Processing t = 2016-02-01 (662/765)... Step Time: 0.10s\n",
            " Processing t = 2016-03-01 (663/765)... Step Time: 0.24s\n",
            " Processing t = 2016-04-01 (664/765)... Step Time: 0.16s\n",
            " Processing t = 2016-05-01 (665/765)... Step Time: 0.06s\n",
            " Processing t = 2016-06-01 (666/765)... Step Time: 0.12s\n",
            " Processing t = 2016-07-01 (667/765)... Step Time: 0.08s\n",
            " Processing t = 2016-08-01 (668/765)... Step Time: 0.04s\n",
            " Processing t = 2016-09-01 (669/765)... Step Time: 0.03s\n",
            " Processing t = 2016-10-01 (670/765)... Step Time: 0.04s\n",
            " Processing t = 2016-11-01 (671/765)... Step Time: 0.05s\n",
            " Processing t = 2016-12-01 (672/765)... Step Time: 0.03s\n",
            " Processing t = 2017-01-01 (673/765)... Step Time: 0.03s\n",
            " Processing t = 2017-02-01 (674/765)... Step Time: 0.09s\n",
            " Processing t = 2017-03-01 (675/765)... Step Time: 0.06s\n",
            " Processing t = 2017-04-01 (676/765)... Step Time: 0.05s\n",
            " Processing t = 2017-05-01 (677/765)... Step Time: 0.04s\n",
            " Processing t = 2017-06-01 (678/765)... Step Time: 0.23s\n",
            " Processing t = 2017-07-01 (679/765)... Step Time: 0.18s\n",
            " Processing t = 2017-08-01 (680/765)... Step Time: 0.14s\n",
            " Processing t = 2017-09-01 (681/765)... Step Time: 0.13s\n",
            " Processing t = 2017-10-01 (682/765)... Step Time: 0.07s\n",
            " Processing t = 2017-11-01 (683/765)... Step Time: 0.13s\n",
            " Processing t = 2017-12-01 (684/765)... Step Time: 0.44s\n",
            " Processing t = 2018-01-01 (685/765)... Step Time: 0.07s\n",
            " Processing t = 2018-02-01 (686/765)... Step Time: 0.46s\n",
            " Processing t = 2018-03-01 (687/765)... Step Time: 0.27s\n",
            " Processing t = 2018-04-01 (688/765)... Step Time: 0.23s\n",
            " Processing t = 2018-05-01 (689/765)... Step Time: 0.27s\n",
            " Processing t = 2018-06-01 (690/765)... Step Time: 0.10s\n",
            " Processing t = 2018-07-01 (691/765)... Step Time: 0.09s\n",
            " Processing t = 2018-08-01 (692/765)... Step Time: 0.11s\n",
            " Processing t = 2018-09-01 (693/765)... Step Time: 0.25s\n",
            " Processing t = 2018-10-01 (694/765)... Step Time: 0.06s\n",
            " Processing t = 2018-11-01 (695/765)... Step Time: 0.11s\n",
            " Processing t = 2018-12-01 (696/765)... Step Time: 0.32s\n",
            " Processing t = 2019-01-01 (697/765)... Step Time: 0.19s\n",
            " Processing t = 2019-02-01 (698/765)... Step Time: 0.37s\n",
            " Processing t = 2019-03-01 (699/765)... Step Time: 0.36s\n",
            " Processing t = 2019-04-01 (700/765)... Step Time: 0.21s\n",
            " Processing t = 2019-05-01 (701/765)... Step Time: 0.27s\n",
            " Processing t = 2019-06-01 (702/765)... Step Time: 0.16s\n",
            " Processing t = 2019-07-01 (703/765)... Step Time: 0.17s\n",
            " Processing t = 2019-08-01 (704/765)... Step Time: 0.12s\n",
            " Processing t = 2019-09-01 (705/765)... Step Time: 0.07s\n",
            " Processing t = 2019-10-01 (706/765)... Step Time: 0.29s\n",
            " Processing t = 2019-11-01 (707/765)... Step Time: 0.04s\n",
            " Processing t = 2019-12-01 (708/765)... Step Time: 0.03s\n",
            " Processing t = 2020-01-01 (709/765)... Step Time: 0.04s\n",
            " Processing t = 2020-02-01 (710/765)... Step Time: 0.03s\n",
            " Processing t = 2020-03-01 (711/765)... Step Time: 0.13s\n",
            " Processing t = 2020-04-01 (712/765)... Step Time: 0.07s\n",
            " Processing t = 2020-05-01 (713/765)... Step Time: 0.03s\n",
            " Processing t = 2020-06-01 (714/765)... Step Time: 0.04s\n",
            " Processing t = 2020-07-01 (715/765)... Step Time: 0.05s\n",
            " Processing t = 2020-08-01 (716/765)... Step Time: 0.05s\n",
            " Processing t = 2020-09-01 (717/765)... Step Time: 0.05s\n",
            " Processing t = 2020-10-01 (718/765)... Step Time: 0.05s\n",
            " Processing t = 2020-11-01 (719/765)... Step Time: 0.04s\n",
            " Processing t = 2020-12-01 (720/765)... Step Time: 0.08s\n",
            " Processing t = 2021-01-01 (721/765)... Step Time: 0.04s\n",
            " Processing t = 2021-02-01 (722/765)... Step Time: 0.14s\n",
            " Processing t = 2021-03-01 (723/765)... Step Time: 0.05s\n",
            " Processing t = 2021-04-01 (724/765)... Step Time: 0.03s\n",
            " Processing t = 2021-05-01 (725/765)... Step Time: 0.10s\n",
            " Processing t = 2021-06-01 (726/765)... Step Time: 0.04s\n",
            " Processing t = 2021-07-01 (727/765)... Step Time: 0.05s\n",
            " Processing t = 2021-08-01 (728/765)... Step Time: 0.03s\n",
            " Processing t = 2021-09-01 (729/765)... Step Time: 0.16s\n",
            " Processing t = 2021-10-01 (730/765)... Step Time: 0.08s\n",
            " Processing t = 2021-11-01 (731/765)... Step Time: 0.04s\n",
            " Processing t = 2021-12-01 (732/765)... Step Time: 0.04s\n",
            " Processing t = 2022-01-01 (733/765)... Step Time: 0.04s\n",
            " Processing t = 2022-02-01 (734/765)... Step Time: 0.16s\n",
            " Processing t = 2022-03-01 (735/765)... Step Time: 0.17s\n",
            " Processing t = 2022-04-01 (736/765)... Step Time: 0.05s\n",
            " Processing t = 2022-05-01 (737/765)... Step Time: 0.03s\n",
            " Processing t = 2022-06-01 (738/765)... Step Time: 0.06s\n",
            " Processing t = 2022-07-01 (739/765)... Step Time: 0.04s\n",
            " Processing t = 2022-08-01 (740/765)... Step Time: 0.04s\n",
            " Processing t = 2022-09-01 (741/765)... Step Time: 0.07s\n",
            " Processing t = 2022-10-01 (742/765)... Step Time: 0.04s\n",
            " Processing t = 2022-11-01 (743/765)... Step Time: 0.14s\n",
            " Processing t = 2022-12-01 (744/765)... Step Time: 0.05s\n",
            " Processing t = 2023-01-01 (745/765)... Step Time: 0.07s\n",
            " Processing t = 2023-02-01 (746/765)... Step Time: 0.04s\n",
            " Processing t = 2023-03-01 (747/765)... Step Time: 0.05s\n",
            " Processing t = 2023-04-01 (748/765)... Step Time: 0.06s\n",
            " Processing t = 2023-05-01 (749/765)... Step Time: 0.04s\n",
            " Processing t = 2023-06-01 (750/765)... Step Time: 0.04s\n",
            " Processing t = 2023-07-01 (751/765)... Step Time: 0.23s\n",
            " Processing t = 2023-08-01 (752/765)... Step Time: 0.07s\n",
            " Processing t = 2023-09-01 (753/765)... Step Time: 0.05s\n",
            " Processing t = 2023-10-01 (754/765)... Step Time: 0.04s\n",
            " Processing t = 2023-11-01 (755/765)... Step Time: 0.07s\n",
            " Processing t = 2023-12-01 (756/765)... Step Time: 0.04s\n",
            " Processing t = 2024-01-01 (757/765)... Step Time: 0.03s\n",
            " Processing t = 2024-02-01 (758/765)... Step Time: 0.17s\n",
            " Processing t = 2024-03-01 (759/765)... Step Time: 0.04s\n",
            " Processing t = 2024-04-01 (760/765)... Step Time: 0.05s\n",
            " Processing t = 2024-05-01 (761/765)... Step Time: 0.04s\n",
            " Processing t = 2024-06-01 (762/765)... Step Time: 0.04s\n",
            " Processing t = 2024-07-01 (763/765)... Step Time: 0.10s\n",
            " Processing t = 2024-08-01 (764/765)... Step Time: 0.15s\n",
            " Processing t = 2024-09-01 (765/765)... Step Time: 0.13s\n",
            "--- Recursive Loop Finished --- Total time: 1.11 minutes ---\n",
            " Constructing Cumulative Recursive Factor Indices from NumPy array...\n",
            "\n",
            "Recursive Factor Diffusion Index (RFDI) DataFrame head(15):\n",
            "            RFDI_1  RFDI_2  RFDI_3  RFDI_4  RFDI_5  RFDI_6  RFDI_7  RFDI_8\n",
            "Date                                                                      \n",
            "1961-01-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-02-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-03-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-04-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-05-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-06-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-07-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-08-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-09-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-10-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-11-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1961-12-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1962-01-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1962-02-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "1962-03-01     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
            "NaN Check:\n",
            "RFDI_1    17\n",
            "RFDI_2    17\n",
            "RFDI_3    17\n",
            "RFDI_4    17\n",
            "RFDI_5    17\n",
            "RFDI_6    17\n",
            "RFDI_7    17\n",
            "RFDI_8    17\n",
            "dtype: int64\n",
            "\n",
            "Saved: X_fbdi_raw_recursive.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\n--- Calculating Residual Distribution Shape Index (RDSI) ---\")\n",
        "# MAIN FACTOR-BASED DIFFUSION INDEX\n",
        "ROLLING_WINDOW_DIST = 11 # Short window for smoothing skew/kurtosis\n",
        "FINAL_SMOOTH_RDSI = 4   # Dinal smoothing on indices\n",
        "\n",
        "print(\" Calculating residuals...\")\n",
        "Predicted_Values = X_factors_raw_final @ loadings_df.T\n",
        "Predicted_Values.columns = X_imputed_core.columns\n",
        "Residuals_df = X_imputed_core - Predicted_Values\n",
        "\n",
        "print(f\" Calculating rolling ({ROLLING_WINDOW_DIST}m window) cross-sectional skew/kurtosis:\")\n",
        "\n",
        "\n",
        "Skew_t = Residuals_df.skew(axis=1, skipna=True)\n",
        "Kurt_t = Residuals_df.kurt(axis=1, skipna=True) # Fisher's kurtosis\n",
        "\n",
        "# Apply rolling window smoothing\n",
        "Rolling_Skew = Skew_t.rolling(window=ROLLING_WINDOW_DIST, min_periods=ROLLING_WINDOW_DIST // 2).mean()\n",
        "Rolling_Kurt = Kurt_t.rolling(window=ROLLING_WINDOW_DIST, min_periods=ROLLING_WINDOW_DIST // 2).mean()\n",
        "\n",
        "\n",
        "X_fbdi_raw_rdsi = pd.DataFrame({\n",
        "    f'FBDI_ResidSkew_Roll{ROLLING_WINDOW_DIST}': Rolling_Skew,\n",
        "    f'FBDI_ResidKurt_Roll{ROLLING_WINDOW_DIST}': Rolling_Kurt\n",
        "})\n",
        "\n",
        "\n",
        "if FINAL_SMOOTH_RDSI > 1:\n",
        "    print(f\" Applying final smoothing (window={FINAL_SMOOTH_RDSI})...\")\n",
        "    cols_to_smooth = X_fbdi_raw_rdsi.columns\n",
        "    for col in cols_to_smooth:\n",
        "        X_fbdi_raw_rdsi[f'{col}_Smooth{FINAL_SMOOTH_RDSI}'] = X_fbdi_raw_rdsi[col].rolling(window=FINAL_SMOOTH_RDSI, min_periods=1).mean()\n",
        "\n",
        "    final_cols = [f'{col}_Smooth{FINAL_SMOOTH_RDSI}' for col in cols_to_smooth]\n",
        "    X_fbdi_final_to_save = X_fbdi_raw_rdsi[final_cols]\n",
        "else:\n",
        "    X_fbdi_final_to_save = X_fbdi_raw_rdsi\n",
        "\n",
        "\n",
        "print(f\"\\nResidual Distribution Shape Index (RDSI) head:\")\n",
        "\n",
        "print(X_fbdi_final_to_save.head(ROLLING_WINDOW_DIST + FINAL_SMOOTH_RDSI + 5))\n",
        "nan_check = X_fbdi_final_to_save.isna().sum()\n",
        "print(f\"NaN Check (expect NaNs at start from rolling({ROLLING_WINDOW_DIST})):\\n{nan_check}\")\n",
        "\n",
        "save_path = \"X_fbdi_raw_rdsi.pkl\"\n",
        "try:\n",
        "     X_fbdi_final_to_save.to_pickle(save_path)\n",
        "     print(f\"\\nSaved (NaNs dropped): {save_path}\")\n",
        "except Exception as e:\n",
        "      print(f\"\\nERROR saving RDSI file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX2KBf505qJd",
        "outputId": "26fb0cc9-8fdc-4fc0-e687-2ee87f4ddf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n--- Calculating Residual Distribution Shape Index (RDSI) ---\n",
            " Calculating residuals...\n",
            " Calculating rolling (11m window) cross-sectional skew/kurtosis...\n",
            " Applying final smoothing (window=4)...\n",
            "\n",
            "Residual Distribution Shape Index (RDSI) head:\n",
            "            FBDI_ResidSkew_Roll11_Smooth4  FBDI_ResidKurt_Roll11_Smooth4\n",
            "Date                                                                    \n",
            "1961-01-01                            NaN                            NaN\n",
            "1961-02-01                            NaN                            NaN\n",
            "1961-03-01                            NaN                            NaN\n",
            "1961-04-01                            NaN                            NaN\n",
            "1961-05-01                       5.498055                      36.002267\n",
            "1961-06-01                       5.489989                      35.652009\n",
            "1961-07-01                       5.475265                      35.198531\n",
            "1961-08-01                       5.478959                      35.035936\n",
            "1961-09-01                       5.471311                      34.537281\n",
            "1961-10-01                       5.511606                      34.835902\n",
            "1961-11-01                       5.565515                      35.382286\n",
            "1961-12-01                       5.579944                      35.725350\n",
            "1962-01-01                       5.670187                      36.804144\n",
            "1962-02-01                       5.666094                      37.243626\n",
            "1962-03-01                       5.662040                      37.742622\n",
            "1962-04-01                       5.686381                      38.373154\n",
            "1962-05-01                       5.656708                      38.613152\n",
            "1962-06-01                       5.513437                      39.156378\n",
            "1962-07-01                       5.366933                      39.672306\n",
            "1962-08-01                       5.176360                      40.214775\n",
            "NaN Check (expect NaNs at start from rolling(11)):\n",
            "FBDI_ResidSkew_Roll11_Smooth4    4\n",
            "FBDI_ResidKurt_Roll11_Smooth4    4\n",
            "dtype: int64\n",
            "\n",
            "Saved (NaNs dropped): X_fbdi_raw_rdsi.pkl\n",
            "\n",
            "--- End of RDSI Generation ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc. Prep"
      ],
      "metadata": {
        "id": "6eGS_nVT9bjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lagging Variables"
      ],
      "metadata": {
        "id": "4ero2Hgh9e34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_cbdi_raw_3state = pd.read_pickle(\"X_cbdi_raw_3state.pkl\")\n",
        "X_fbdi_raw_method1 = pd.read_pickle('X_fbdi_raw_method1.pkl')\n",
        "X_fbdi_raw_recursive = pd.read_pickle('X_fbdi_raw_recursive.pkl')\n",
        "X_fbdi_raw_rdsi = pd.read_pickle('X_fbdi_raw_rdsi.pkl')\n",
        "\n",
        "lags_to_add = [1, 2, 6, 12]\n",
        "# Function for lagging\n",
        "def add_lags(df, lags):\n",
        "  df_lagged_list = [df]\n",
        "  for lag in lags:\n",
        "    df_shifted = df.shift(lag).add_suffix(f'_lag{lag}')\n",
        "    df_lagged_list.append(df_shifted)\n",
        "  return pd.concat(df_lagged_list, axis=1)\n",
        "\n",
        "# Lagging Factor Set\n",
        "X_factors_lagged = add_lags(X_factors_raw_final, lags_to_add)\n",
        "\n",
        "# Lagging CBDI Set\n",
        "X_cbdi_lagged = add_lags(X_cbdi_raw_3state, lags_to_add)\n",
        "\n",
        "# Lagging FBDI Set\n",
        "X_fbdi_lagged = add_lags(X_fbdi_raw_rdsi, lags_to_add)\n",
        "\n",
        "# Lagging FBDI Recursive\n",
        "X_fbdi_recursive_lagged = add_lags(X_fbdi_raw_recursive, lags_to_add)\n",
        "\n",
        "# Lagging Full Set\n",
        "X_full_lagged = add_lags(X_imputed_core, lags_to_add)\n",
        "\n",
        "# Lagging yield\n",
        "X_yield_lagged = add_lags(X_raw_spread, lags_to_add)"
      ],
      "metadata": {
        "id": "16tdVPBV9IY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Data"
      ],
      "metadata": {
        "id": "frSnAfrRBYrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_size = 0.4\n",
        "X_train_factors, X_test_factors, y_train, y_test = skm.train_test_split(X_factors_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_cbdi, X_test_cbdi, _, _ = skm.train_test_split(X_cbdi_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_full, X_test_full, _, _ = skm.train_test_split(X_full_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_fbdi, X_test_fbdi, _, _ = skm.train_test_split(X_fbdi_lagged, y_final, test_size = test_set_size, shuffle=False)\n",
        "X_train_fbdi_recursive, X_test_fbdi_recursive, _, _ = skm.train_test_split(X_fbdi_recursive_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_yield, X_test_yield, _, _ = skm.train_test_split(X_yield_lagged, y_final, test_size = test_set_size, shuffle = False)"
      ],
      "metadata": {
        "id": "frlgvAt6_MzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.to_pickle(X_train_factors, \"X_train_factors.pkl\")\n",
        "pd.to_pickle(X_test_factors, \"X_test_factors.pkl\")\n",
        "pd.to_pickle(X_train_cbdi, \"X_train_cbdi.pkl\")\n",
        "pd.to_pickle(X_test_cbdi, \"X_test_cbdi.pkl\")\n",
        "pd.to_pickle(X_train_full, \"X_train_full.pkl\")\n",
        "pd.to_pickle(X_test_full, \"X_test_full.pkl\")\n",
        "pd.to_pickle(X_train_fbdi, 'X_train_fbdi.pkl')\n",
        "pd.to_pickle(X_test_fbdi, 'X_test_fbdi.pkl')\n",
        "pd.to_pickle(X_train_fbdi, 'X_train_fbdi_recursive.pkl')\n",
        "pd.to_pickle(X_test_fbdi, 'X_test_fbdi_recursive.pkl')\n",
        "pd.to_pickle(y_train, \"y_train.pkl\")\n",
        "pd.to_pickle(y_test, \"y_test.pkl\")"
      ],
      "metadata": {
        "id": "23Hf3tW2B7lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Model Processing"
      ],
      "metadata": {
        "id": "kd-DwsBWCcDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute factors\n",
        "imputer_factors = KNNImputer(n_neighbors=5)\n",
        "imputer_factors.fit(X_train_factors)\n",
        "X_train_factors_imp = imputer_factors.transform(X_train_factors)\n",
        "X_test_factors_imp = imputer_factors.transform(X_test_factors)\n",
        "\n",
        "# Scale factors\n",
        "scaler_factors = StandardScaler()\n",
        "scaler_factors.fit(X_train_factors_imp)\n",
        "X_train_factors_scaled = scaler_factors.transform(X_train_factors_imp)\n",
        "X_test_factors_scaled = scaler_factors.transform(X_test_factors_imp)\n",
        "\n",
        "# Repeat for CBDI\n",
        "imputer_cbdi = KNNImputer(n_neighbors=5)\n",
        "imputer_cbdi.fit(X_train_cbdi)\n",
        "X_train_cbdi_imp = imputer_cbdi.transform(X_train_cbdi)\n",
        "X_test_cbdi_imp = imputer_cbdi.transform(X_test_cbdi)\n",
        "\n",
        "scaler_cbdi = StandardScaler()\n",
        "scaler_cbdi.fit(X_train_cbdi_imp)\n",
        "X_train_cbdi_scaled = scaler_cbdi.transform(X_train_cbdi_imp)\n",
        "X_test_cbdi_scaled = scaler_cbdi.transform(X_test_cbdi_imp)\n",
        "\n",
        "# Full set\n",
        "imputer_full = KNNImputer(n_neighbors=5)\n",
        "imputer_full.fit(X_train_full)\n",
        "X_train_full_imp = imputer_full.transform(X_train_full)\n",
        "X_test_full_imp = imputer_full.transform(X_test_full)\n",
        "\n",
        "scaler_full = StandardScaler()\n",
        "scaler_full.fit(X_train_full_imp)\n",
        "X_train_full_scaled = scaler_full.transform(X_train_full_imp)\n",
        "X_test_full_scaled = scaler_full.transform(X_test_full_imp)\n",
        "\n",
        "# FBDI\n",
        "imputer_fbdi = KNNImputer(n_neighbors=5)\n",
        "imputer_fbdi.fit(X_train_fbdi)\n",
        "X_train_fbdi_imp = imputer_fbdi.transform(X_train_fbdi)\n",
        "X_test_fbdi_imp = imputer_fbdi.transform(X_test_fbdi)\n",
        "\n",
        "scaler_fbdi = StandardScaler()\n",
        "scaler_fbdi.fit(X_train_fbdi_imp)\n",
        "X_train_fbdi_scaled = scaler_fbdi.transform(X_train_fbdi_imp)\n",
        "X_test_fbdi_scaled = scaler_fbdi.transform(X_test_fbdi_imp)\n",
        "\n",
        "# FBDI Recursive\n",
        "imputer_fbdi_recursive = KNNImputer(n_neighbors=5)\n",
        "imputer_fbdi_recursive.fit(X_train_fbdi_recursive)\n",
        "X_train_fbdi_recursive_imp = imputer_fbdi_recursive.transform(X_train_fbdi_recursive)\n",
        "X_test_fbdi_recursive_imp = imputer_fbdi_recursive.transform(X_test_fbdi_recursive)\n",
        "\n",
        "scaler_fbdi_recursive = StandardScaler()\n",
        "scaler_fbdi_recursive.fit(X_train_fbdi_recursive_imp)\n",
        "X_train_fbdi_recursive_scaled = scaler_fbdi_recursive.transform(X_train_fbdi_recursive_imp)\n",
        "X_test_fbdi_recursive_scaled = scaler_fbdi_recursive.transform(X_test_fbdi_recursive_imp)\n",
        "\n",
        "# Yield\n",
        "imputer_yield = KNNImputer(n_neighbors=5)\n",
        "imputer_yield.fit(X_train_yield)\n",
        "X_train_yield_imp = imputer_yield.transform(X_train_yield)\n",
        "X_test_yield_imp = imputer_yield.transform(X_test_yield)\n",
        "\n",
        "scaler_yield = StandardScaler()\n",
        "scaler_yield.fit(X_train_yield_imp)\n",
        "X_train_yield_scaled = scaler_yield.transform(X_train_yield_imp)\n",
        "X_test_yield_scaled = scaler_yield.transform(X_test_yield_imp)\n",
        "\n",
        "# Finalizing sets\n",
        "X_train_factors_final = pd.DataFrame(X_train_factors_scaled, index=X_train_factors.index, columns=X_train_factors.columns)\n",
        "X_test_factors_final = pd.DataFrame(X_test_factors_scaled, index=X_test_factors.index, columns=X_test_factors.columns)\n",
        "\n",
        "X_train_cbdi_final = pd.DataFrame(X_train_cbdi_scaled, index=X_train_cbdi.index, columns=X_train_cbdi.columns)\n",
        "X_test_cbdi_final = pd.DataFrame(X_test_cbdi_scaled, index=X_test_cbdi.index, columns=X_test_cbdi.columns)\n",
        "\n",
        "X_train_full_final = pd.DataFrame(X_train_full_scaled, index=X_train_full.index, columns=X_train_full.columns)\n",
        "X_test_full_final = pd.DataFrame(X_test_full_scaled, index=X_test_full.index, columns=X_test_full.columns)\n",
        "\n",
        "X_train_fbdi_final = pd.DataFrame(X_train_fbdi_scaled, index=X_train_fbdi.index, columns=X_train_fbdi.columns)\n",
        "X_test_fbdi_final = pd.DataFrame(X_test_fbdi_scaled, index=X_test_fbdi.index, columns=X_test_fbdi.columns)\n",
        "\n",
        "X_train_fbdi_recursive_final = pd.DataFrame(X_train_fbdi_recursive_scaled, index=X_train_fbdi_recursive.index, columns=X_train_fbdi_recursive.columns)\n",
        "X_test_fbdi_recursive_final = pd.DataFrame(X_test_fbdi_recursive_scaled, index=X_test_fbdi_recursive.index, columns=X_test_fbdi_recursive.columns)\n",
        "\n",
        "X_train_yield_final = pd.DataFrame(X_train_yield_scaled, index=X_train_yield.index, columns=X_train_yield.columns)\n",
        "X_test_yield_final = pd.DataFrame(X_test_yield_scaled, index=X_test_yield.index, columns=X_test_yield.columns)"
      ],
      "metadata": {
        "id": "oJ4x1WFSCQJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "8Qmg5UaED8p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sets = {\n",
        "    'Factors': X_train_factors_final,\n",
        "    'CBDI': X_train_cbdi_final,\n",
        "    'Full': X_train_full_final,\n",
        "    'FBDI': X_train_fbdi_final,\n",
        "    'FBDI_Recursive': X_train_fbdi_recursive_final,\n",
        "    'Yield': X_train_yield_final\n",
        "}\n",
        "\n",
        "test_sets = {\n",
        "    'Factors': X_test_factors_final,\n",
        "    'CBDI': X_test_cbdi_final,\n",
        "    'Full': X_test_full_final,\n",
        "    'FBDI': X_test_fbdi_final,\n",
        "    'FBDI_Recursive': X_test_fbdi_recursive_final,\n",
        "    'Yield': X_test_yield_final\n",
        "}"
      ],
      "metadata": {
        "id": "MDrTyZ2LDvFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = skm.cross_val_score(xgb.XGBClassifier(objective='binary:logistic', eval_metric='aucpr', use_label_encoder=False, random_state=42), X_train_fbdi_final, y_train, cv=skm.TimeSeriesSplit(n_splits=3), scoring='average_precision')\n",
        "print(f\"Index: [Name of your FBDI]\")\n",
        "print(f\"  Time Series CV PR AUC Scores: {scores}\")\n",
        "print(f\"  Mean PR AUC: {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEOlXUgcSZZS",
        "outputId": "870beba4-acb8-4338-ae8c-8f482093b186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: [Name of your FBDI]\n",
            "  Time Series CV PR AUC Scores: [0.30437392 0.21608214 0.91820988]\n",
            "  Mean PR AUC: 0.4796 +/- 0.3123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_run_defs = {\n",
        "    \"Logit\": lambda: LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000),\n",
        "    \"Logit_L2\": lambda: LogisticRegression(penalty='l2', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000),\n",
        "    \"RandomForest\": lambda: RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    \"XGBoost\": lambda: xgb.XGBClassifier(objective='binary:logistic', eval_metric='aucpr', use_label_encoder=False, random_state=42),\n",
        "    'HGBoost': lambda: HistGradientBoostingClassifier(loss='log_loss', random_state=42, class_weight='balanced')\n",
        "}"
      ],
      "metadata": {
        "id": "UPolDOCeFh-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "mCnwoZ-6pgKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RF Param Grid\n",
        "rf_param_grid = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None] + list(randint(5, 20).rvs(5)),\n",
        "    'min_samples_split': randint(5, 50),\n",
        "    'min_samples_leaf': randint(3, 30),\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': ['balanced', 'balanced_subsample'] + [{0: 1, 1: w} for w in [10, 12, 18, 21]],\n",
        "}\n",
        "\n",
        "# XGB Param Grid\n",
        "scale_pos_weight_calc = sum(y_train==0) / sum(y_train==1)\n",
        "xgb_param_grid = {\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'max_depth': randint(3, 7),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'min_child_weight': randint(7, 25),\n",
        "    'gamma': uniform(0.1, 0.5),\n",
        "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
        "    'reg_lambda': [0.1, 1, 5],\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'scale_pos_weight': [scale_pos_weight_calc]\n",
        "}\n",
        "\n",
        "# HGB Param Grid\n",
        "hgb_param_grid = {\n",
        "    'learning_rate': uniform(0.01, 0.15),\n",
        "    'max_iter': randint(100, 500),\n",
        "    'max_leaf_nodes': [None] + list(randint(15, 41).rvs(4)),\n",
        "    'max_depth': [None] + list(randint(4, 10).rvs(3)),\n",
        "    'min_samples_leaf': randint(10, 50),\n",
        "    'l2_regularization': uniform(0, 1.0),\n",
        "}"
      ],
      "metadata": {
        "id": "JsYRy5F2GtlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_param_grid_set = {\n",
        "    'learning_rate': [0.3],\n",
        "    'max_depth': [6],\n",
        "    'subsample': [1],\n",
        "    'colsample_bytree': [1],\n",
        "    'min_child_weight': [1],\n",
        "    'gamma': [0],\n",
        "    'reg_alpha': [0],\n",
        "    'reg_lambda': [1],\n",
        "    'n_estimators': [100],\n",
        "    # 'scale_pos_weight': [scale_pos_weight_calc] # Set calculated value\n",
        "}"
      ],
      "metadata": {
        "id": "ispXYGyz0KiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_tune_ratio = 0.6\n",
        "tune_end_index = int(len(y_final) * initial_tune_ratio)\n",
        "y_train_tune = y_final.iloc[:tune_end_index]\n",
        "\n",
        "RUN_RECURSIVE_LOOP = True\n",
        "\n",
        "best_params_found = {}\n",
        "models_to_tune = ['RandomForest', 'XGBoost', 'HGBoost']\n",
        "if RUN_RECURSIVE_LOOP:\n",
        "  for input_name in train_sets:\n",
        "    print(f\"\\n == Tuning for Input: {input_name} == \")\n",
        "    if input_name == \"Factors\":\n",
        "      X_train_tune_full = X_factors_lagged.iloc[:tune_end_index]\n",
        "    elif input_name == \"CBDI\":\n",
        "      X_train_tune_full = X_cbdi_lagged.iloc[:tune_end_index]\n",
        "    elif input_name == 'FBDI':\n",
        "      X_train_tune_full = X_fbdi_lagged.iloc[:tune_end_index]\n",
        "    elif input_name == 'FBDI_Recursive':\n",
        "      X_train_tune_full = X_fbdi_recursive_lagged.iloc[:tune_end_index]\n",
        "    else:\n",
        "      X_train_tune_full = X_full_lagged.iloc[:tune_end_index]\n",
        "\n",
        "    imputer_tune = KNNImputer(n_neighbors=5)\n",
        "    X_train_tune_imputed = imputer_tune.fit_transform(X_train_tune_full)\n",
        "    scaler_tune = StandardScaler()\n",
        "    X_train_tune_final = scaler_tune.fit_transform(X_train_tune_imputed)\n",
        "\n",
        "    best_params_found[input_name] = {}\n",
        "    for model_name in models_to_tune:\n",
        "      model_instance = models_to_run_defs[model_name]()\n",
        "      param_grid = rf_param_grid if model_name == 'RandomForest' else xgb_param_grid\n",
        "      if model_name == 'RandomForest':\n",
        "        param_grid = rf_param_grid\n",
        "      elif model_name == 'XGBoost':\n",
        "        if input_name == 'FBDI':\n",
        "          param_grid = xgb_param_grid_set\n",
        "        else:\n",
        "          param_grid = xgb_param_grid\n",
        "      else:\n",
        "        param_grid = hgb_param_grid\n",
        "      print(f\"Tuning {model_name} on {input_name}\")\n",
        "      if model_name == 'RandomForest' or model_name == 'HGBoost' or model_name == 'XGBoost':\n",
        "        random_search_tune = skm.RandomizedSearchCV(\n",
        "            estimator=model_instance,\n",
        "            param_distributions=param_grid,\n",
        "            n_iter=70,\n",
        "            cv=skm.TimeSeriesSplit(n_splits=3),\n",
        "            scoring='average_precision',\n",
        "            refit=False,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "      # else:\n",
        "      #   random_search_tune = skm.RandomizedSearchCV(\n",
        "      #       estimator=model_instance,\n",
        "      #       param_distributions=param_grid,\n",
        "      #       n_iter=70,\n",
        "      #       cv=skm.TimeSeriesSplit(n_splits=3),\n",
        "      #       scoring='average_precision',\n",
        "      #       refit=False,\n",
        "      #       random_state=42,\n",
        "      #       n_jobs=1\n",
        "      #   )\n",
        "      random_search_tune.fit(X_train_tune_final, y_train_tune)\n",
        "      best_params_found[input_name][model_name] = random_search_tune.best_params_\n",
        "      print(f\"    Best Params for {model_name} ({input_name}): {random_search_tune.best_params_}\")\n",
        "      print(f\"    Best CV Score: {random_search_tune.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "-RVeU2mHpkkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161fa68c-bb16-4b02-a973-ba9748da971e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " == Tuning for Input: CBDI == \n",
            "Tuning RandomForest on CBDI\n",
            "    Best Params for RandomForest (CBDI): {'class_weight': {0: 1, 1: 12}, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 11, 'n_estimators': 120}\n",
            "    Best CV Score: 0.4701\n",
            "Tuning XGBoost on CBDI\n",
            "    Best Params for XGBoost (CBDI): {'colsample_bytree': np.float64(0.8428136990746738), 'gamma': np.float64(0.2379995910112717), 'learning_rate': np.float64(0.06925470114081649), 'max_depth': 3, 'min_child_weight': 7, 'n_estimators': 444, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'scale_pos_weight': 6.403225806451613, 'subsample': np.float64(0.908897907718663)}\n",
            "    Best CV Score: 0.4875\n",
            "Tuning HGBoost on CBDI\n",
            "    Best Params for HGBoost (CBDI): {'l2_regularization': np.float64(0.6711435168240506), 'learning_rate': np.float64(0.06379701719442459), 'max_depth': np.int64(8), 'max_iter': 254, 'max_leaf_nodes': np.int64(21), 'min_samples_leaf': 11}\n",
            "    Best CV Score: 0.5215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recursive Forecasting Loop"
      ],
      "metadata": {
        "id": "y7tr27PHuVs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits_recursive = int(len(y_final) * 0.4)\n",
        "evaluation_start_date = y_final.index[-n_splits_recursive]\n",
        "print(f\"Recursive evaluation period starting from: {evaluation_start_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"Using PRE-TUNED hyperparameters found on initial ~{(1-test_set_size)*100:.0f}% of data.\")\n",
        "\n",
        "predictor_sets = {\n",
        "    'Factors': X_factors_raw_final,\n",
        "    'CBDI': X_cbdi_raw_3state,\n",
        "    'Full': X_transformed_core,\n",
        "    'FBDI': X_fbdi_raw_rdsi,\n",
        "    'FBDI_Recursive': X_fbdi_raw_recursive,\n",
        "    'Yield': X_raw_spread\n",
        "}\n",
        "save_dir = \"/content/drive/MyDrive/Diffusion Indices/Final_Models_Joblib/\" # Separate folder maybe\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "arrays_path = os.path.join(save_dir, 'cached_outputs')  # For saving key arrays\n",
        "os.makedirs(arrays_path, exist_ok=True)\n",
        "\n",
        "\n",
        "oos_predictions = {input_name: {model_name: [] for model_name in models_to_run_defs} for input_name in predictor_sets}\n",
        "oos_probabilities = {input_name: {model_name: [] for model_name in models_to_run_defs} for input_name in predictor_sets}\n",
        "oos_target_indices = []\n",
        "final_model_importances = {}\n",
        "\n",
        "# if RUN_RECURSIVE_LOOP:\n",
        "#   oos_predictions = joblib.load(os.path.join(arrays_path, f'oos_predictions_{prediction_horizon}mo.joblib'))\n",
        "#   oos_probabilities = joblib.load(os.path.join(arrays_path, f'oos_probabilities_{prediction_horizon}mo.joblib'))\n",
        "#   final_model_importances = joblib.load(os.path.join(arrays_path, f'oos_final_model_importances_{prediction_horizon}mo.joblib'))\n",
        "#   oos_predictions['Yield'] = {model_name: [] for model_name in models_to_run_defs}\n",
        "#   oos_probabilities['Yield'] = {model_name: [] for model_name in models_to_run_defs}\n",
        "\n",
        "\n",
        "# Loop Start\n",
        "start_time_loop = time.time()\n",
        "forecast_points = y_final.loc[evaluation_start_date:].index\n",
        "if RUN_RECURSIVE_LOOP:\n",
        "  for i, current_forecast_date in enumerate(forecast_points):\n",
        "    is_last_iteration = (i == len(forecast_points)-1)\n",
        "    loop_step_start = time.time()\n",
        "    print(f\" Step {i+1}/{len(forecast_points)}: Forecasting for target date {current_forecast_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    current_date_iloc = y_final.index.get_loc(current_forecast_date)\n",
        "    train_end_iloc = current_date_iloc - 1\n",
        "    if train_end_iloc < 0: continue\n",
        "    train_end_date = y_final.index[train_end_iloc]\n",
        "\n",
        "    print(f\"  Training window ends: {train_end_date.strftime('%Y-%m-%d')}\")\n",
        "    y_train_current = y_final.loc[:train_end_date]\n",
        "\n",
        "    # Process input reps\n",
        "    for input_name, base_data_raw in predictor_sets.items():\n",
        "      print(f\"Processing Input: {input_name}\")\n",
        "\n",
        "      X_train_base_current = base_data_raw.loc[:train_end_date]\n",
        "      X_train_lagged_current = add_lags(X_train_base_current, lags_to_add)\n",
        "\n",
        "      # Preparing single row for prediction\n",
        "      X_predict_now = X_train_lagged_current.iloc[-1:]\n",
        "\n",
        "      # Preprocess specific training window\n",
        "      max_current_lag = max(lags_to_add) if lags_to_add else 0\n",
        "      longest_lag_col = f'{base_data_raw.columns[0]}_lag{max_current_lag}'\n",
        "      if longest_lag_col in X_train_lagged_current.columns:\n",
        "        first_valid_lag_idx = X_train_lagged_current[longest_lag_col].first_valid_index()\n",
        "      else:\n",
        "        if len(X_train_lagged_current) > max_current_lag:\n",
        "          first_valid_lag_idx = X_train_lagged_current.index[max_current_lag]\n",
        "        else:\n",
        "          first_valid_lag_idx = None\n",
        "\n",
        "      if first_valid_lag_idx is None:\n",
        "        print(f\"    Skipping {input_name} - training window too short for max lag ({len(X_train_lagged_current)} < {max_current_lag})\")\n",
        "        for model_name in models_to_run_defs:\n",
        "            oos_predictions[input_name][model_name].append(np.nan)\n",
        "            oos_probabilities[input_name][model_name].append(np.nan)\n",
        "        continue\n",
        "\n",
        "      X_train_current_valid_lags = X_train_lagged_current.loc[first_valid_lag_idx:]\n",
        "      y_train_current_aligned = y_train_current.loc[first_valid_lag_idx:]\n",
        "\n",
        "      if len(X_train_current_valid_lags) < 50: # Check minimum samples AFTER lag drop\n",
        "        print(f\"    Skipping {input_name} - insufficient data after lag drop ({len(X_train_current_valid_lags)})\")\n",
        "        for model_name in models_to_run_defs:\n",
        "            oos_predictions[input_name][model_name].append(np.nan)\n",
        "            oos_probabilities[input_name][model_name].append(np.nan)\n",
        "        continue\n",
        "\n",
        "      # Impute and scale\n",
        "      print(f\"     Window samples before imputation: {len(X_train_current_valid_lags)}, NaNs: {X_train_current_valid_lags.isna().sum().sum()}\")\n",
        "      current_imputer = KNNImputer(n_neighbors=5)\n",
        "      current_imputer.fit(X_train_current_valid_lags)\n",
        "      X_train_imp = current_imputer.transform(X_train_current_valid_lags)\n",
        "      X_predict_imp = current_imputer.transform(X_predict_now[X_train_current_valid_lags.columns])\n",
        "\n",
        "      current_scaler = StandardScaler()\n",
        "      X_train_scaled = current_scaler.fit_transform(X_train_imp)\n",
        "      X_predict_scaled = current_scaler.transform(X_predict_imp)\n",
        "      current_feature_names = X_train_current_valid_lags.columns\n",
        "\n",
        "      X_train_scaled_df = pd.DataFrame(X_train_scaled, index=y_train_current_aligned.index, columns=X_train_current_valid_lags.columns)\n",
        "\n",
        "      for model_name, model_constructor in models_to_run_defs.items():\n",
        "        current_best_params = best_params_found.get(input_name, {}).get(model_name, None)\n",
        "        if current_best_params is None and model_name in models_to_tune:\n",
        "          print(f\"     Skipping {model_name} on {input_name}: No best parameters found.\")\n",
        "          oos_predictions[input_name][model_name].append(np.nan)\n",
        "          oos_probabilities[input_name][model_name].append(np.nan)\n",
        "          continue\n",
        "\n",
        "        print(f\"Training {model_name}...\")\n",
        "        if model_name in models_to_tune:\n",
        "          model_instance = model_constructor().set_params(**current_best_params)\n",
        "        else:\n",
        "          model_instance = model_constructor()\n",
        "        model_instance.fit(X_train_scaled_df, y_train_current_aligned)\n",
        "\n",
        "        # Make prediction\n",
        "        pred_proba = model_instance.predict_proba(X_predict_scaled)[:, 1][0]\n",
        "        pred_label = model_instance.predict(X_predict_scaled)[0]\n",
        "\n",
        "        # Store\n",
        "        oos_predictions[input_name][model_name].append(pred_label)\n",
        "        oos_probabilities[input_name][model_name].append(pred_proba)\n",
        "\n",
        "        if is_last_iteration:\n",
        "          print(f\"    Storing importance/coeffs for FINAL model ({input_name}/{model_name})...\")\n",
        "          if isinstance(model_instance, LogisticRegression):\n",
        "            if hasattr(model_instance, 'coef_'):\n",
        "              coefs = model_instance.coef_[0]\n",
        "              if len(current_feature_names) == len(coefs):\n",
        "                final_model_importances[(input_name, model_name)] = pd.Series(coefs, index=current_feature_names)\n",
        "              else: print(f\"      WARN: Coef/Feature length mismatch for {model_name}\")\n",
        "            else: print(f\"      WARN: Could not get coef_ for {model_name}\")\n",
        "          elif hasattr(model_instance, 'feature_importances_'):\n",
        "            imps = model_instance.feature_importances_\n",
        "            if len(current_feature_names) == len(imps):\n",
        "              final_model_importances[(input_name, model_name)] = pd.Series(imps, index=current_feature_names)\n",
        "            else: print(f\"      WARN: Importance/Feature length mismatch for {model_name}\")\n",
        "          else:\n",
        "            print(f\"      WARN: Could not get feature_importances_ for {model_name}\")\n",
        "\n",
        "          model_filename = f\"{save_dir}model_{input_name}_{model_name}_{prediction_horizon}mo_final.joblib\"\n",
        "          joblib.dump(model_instance, model_filename)\n",
        "          print(f\"    Saved final model to {model_filename}\")\n",
        "          # joblib.dump(oos_predictions, os.path.join(arrays_path, f'oos_predictions_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # joblib.dump(oos_probabilities, os.path.join(arrays_path, f'oos_probabilities_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # joblib.dump(oos_target_indices, os.path.join(arrays_path, f'oos_target_indices_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # joblib.dump(final_model_importances, os.path.join(arrays_path, f'oos_final_model_importances_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # print(\"Saved prediction arrays.\")\n",
        "\n",
        "\n",
        "\n",
        "    oos_target_indices.append(current_forecast_date)\n",
        "    print(f\"   Step {i+1} finished. Time: {(time.time() - loop_step_start):.2f}s\")\n",
        "    print(f\"\\n--- Recursive Loop Finished --- Total time: {(time.time() - start_time_loop)/60:.2f} minutes ---\")\n",
        "  joblib.dump(oos_predictions, os.path.join(arrays_path, f'oos_predictions_yield_{prediction_horizon}mo.joblib'))\n",
        "  joblib.dump(oos_probabilities, os.path.join(arrays_path, f'oos_probabilities_yield_{prediction_horizon}mo.joblib'))\n",
        "  joblib.dump(oos_target_indices, os.path.join(arrays_path, f'oos_target_indices_yield_{prediction_horizon}mo.joblib'))\n",
        "  joblib.dump(final_model_importances, os.path.join(arrays_path, f'oos_final_model_importances_yield_{prediction_horizon}mo.joblib'))\n",
        "  print(\"Saved prediction arrays.\")\n",
        "else:\n",
        "  print(\"Skipping recursive loop. Loading saved prediction arrays...\")\n",
        "  oos_predictions = joblib.load(os.path.join(arrays_path, f'oos_predictions_yield_{prediction_horizon}mo.joblib'))\n",
        "  oos_probabilities = joblib.load(os.path.join(arrays_path, f'oos_probabilities_yield_{prediction_horizon}mo.joblib'))\n",
        "  oos_target_indices = joblib.load(os.path.join(arrays_path, f'oos_target_indices_yield_{prediction_horizon}mo.joblib'))\n",
        "  final_model_importances = joblib.load(os.path.join(arrays_path, f'oos_final_model_importances_yield_{prediction_horizon}mo.joblib'))\n",
        "  print(\"Loaded prediction arrays.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBWcjsHYtecs",
        "outputId": "563f7b69-b93a-4ffd-d7a1-d2bfe4c36cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recursive evaluation period starting from: 1999-04-01\n",
            "Using PRE-TUNED hyperparameters found on initial ~60% of data.\n",
            " Step 1/306: Forecasting for target date 1999-04-01\n",
            "  Training window ends: 1999-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 447, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 1 finished. Time: 1.52s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.03 minutes ---\n",
            " Step 2/306: Forecasting for target date 1999-05-01\n",
            "  Training window ends: 1999-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 448, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 2 finished. Time: 1.43s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.05 minutes ---\n",
            " Step 3/306: Forecasting for target date 1999-06-01\n",
            "  Training window ends: 1999-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 449, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 3 finished. Time: 1.44s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.07 minutes ---\n",
            " Step 4/306: Forecasting for target date 1999-07-01\n",
            "  Training window ends: 1999-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 450, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 4 finished. Time: 1.47s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.10 minutes ---\n",
            " Step 5/306: Forecasting for target date 1999-08-01\n",
            "  Training window ends: 1999-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 451, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 5 finished. Time: 1.48s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.12 minutes ---\n",
            " Step 6/306: Forecasting for target date 1999-09-01\n",
            "  Training window ends: 1999-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 452, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 6 finished. Time: 1.47s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.15 minutes ---\n",
            " Step 7/306: Forecasting for target date 1999-10-01\n",
            "  Training window ends: 1999-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 453, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 7 finished. Time: 2.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.19 minutes ---\n",
            " Step 8/306: Forecasting for target date 1999-11-01\n",
            "  Training window ends: 1999-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 454, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 8 finished. Time: 2.49s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.23 minutes ---\n",
            " Step 9/306: Forecasting for target date 1999-12-01\n",
            "  Training window ends: 1999-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 455, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 9 finished. Time: 1.40s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.25 minutes ---\n",
            " Step 10/306: Forecasting for target date 2000-01-01\n",
            "  Training window ends: 1999-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 456, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 10 finished. Time: 1.42s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.28 minutes ---\n",
            " Step 11/306: Forecasting for target date 2000-02-01\n",
            "  Training window ends: 2000-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 457, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 11 finished. Time: 1.43s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.30 minutes ---\n",
            " Step 12/306: Forecasting for target date 2000-03-01\n",
            "  Training window ends: 2000-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 458, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 12 finished. Time: 1.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.33 minutes ---\n",
            " Step 13/306: Forecasting for target date 2000-04-01\n",
            "  Training window ends: 2000-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 459, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 13 finished. Time: 1.48s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.35 minutes ---\n",
            " Step 14/306: Forecasting for target date 2000-05-01\n",
            "  Training window ends: 2000-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 460, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 14 finished. Time: 1.48s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.37 minutes ---\n",
            " Step 15/306: Forecasting for target date 2000-06-01\n",
            "  Training window ends: 2000-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 461, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 15 finished. Time: 1.69s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.40 minutes ---\n",
            " Step 16/306: Forecasting for target date 2000-07-01\n",
            "  Training window ends: 2000-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 462, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 16 finished. Time: 3.52s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.46 minutes ---\n",
            " Step 17/306: Forecasting for target date 2000-08-01\n",
            "  Training window ends: 2000-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 463, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 17 finished. Time: 1.54s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.49 minutes ---\n",
            " Step 18/306: Forecasting for target date 2000-09-01\n",
            "  Training window ends: 2000-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 464, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 18 finished. Time: 1.45s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.51 minutes ---\n",
            " Step 19/306: Forecasting for target date 2000-10-01\n",
            "  Training window ends: 2000-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 465, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 19 finished. Time: 1.46s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.54 minutes ---\n",
            " Step 20/306: Forecasting for target date 2000-11-01\n",
            "  Training window ends: 2000-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 466, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 20 finished. Time: 1.44s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.56 minutes ---\n",
            " Step 21/306: Forecasting for target date 2000-12-01\n",
            "  Training window ends: 2000-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 467, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 21 finished. Time: 1.39s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.58 minutes ---\n",
            " Step 22/306: Forecasting for target date 2001-01-01\n",
            "  Training window ends: 2000-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 468, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 22 finished. Time: 1.43s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.61 minutes ---\n",
            " Step 23/306: Forecasting for target date 2001-02-01\n",
            "  Training window ends: 2001-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 469, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 23 finished. Time: 1.49s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.63 minutes ---\n",
            " Step 24/306: Forecasting for target date 2001-03-01\n",
            "  Training window ends: 2001-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 470, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 24 finished. Time: 2.72s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.68 minutes ---\n",
            " Step 25/306: Forecasting for target date 2001-04-01\n",
            "  Training window ends: 2001-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 471, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 25 finished. Time: 2.11s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.71 minutes ---\n",
            " Step 26/306: Forecasting for target date 2001-05-01\n",
            "  Training window ends: 2001-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 472, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 26 finished. Time: 1.45s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.74 minutes ---\n",
            " Step 27/306: Forecasting for target date 2001-06-01\n",
            "  Training window ends: 2001-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 473, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 27 finished. Time: 1.46s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.76 minutes ---\n",
            " Step 28/306: Forecasting for target date 2001-07-01\n",
            "  Training window ends: 2001-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 474, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 28 finished. Time: 1.49s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.79 minutes ---\n",
            " Step 29/306: Forecasting for target date 2001-08-01\n",
            "  Training window ends: 2001-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 475, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 29 finished. Time: 1.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.81 minutes ---\n",
            " Step 30/306: Forecasting for target date 2001-09-01\n",
            "  Training window ends: 2001-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 476, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 30 finished. Time: 1.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.84 minutes ---\n",
            " Step 31/306: Forecasting for target date 2001-10-01\n",
            "  Training window ends: 2001-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 477, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 31 finished. Time: 1.55s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.86 minutes ---\n",
            " Step 32/306: Forecasting for target date 2001-11-01\n",
            "  Training window ends: 2001-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 478, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 32 finished. Time: 2.80s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.91 minutes ---\n",
            " Step 33/306: Forecasting for target date 2001-12-01\n",
            "  Training window ends: 2001-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 479, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 33 finished. Time: 2.44s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.95 minutes ---\n",
            " Step 34/306: Forecasting for target date 2002-01-01\n",
            "  Training window ends: 2001-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 480, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 34 finished. Time: 1.56s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 0.98 minutes ---\n",
            " Step 35/306: Forecasting for target date 2002-02-01\n",
            "  Training window ends: 2002-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 481, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 35 finished. Time: 1.49s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.00 minutes ---\n",
            " Step 36/306: Forecasting for target date 2002-03-01\n",
            "  Training window ends: 2002-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 482, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 36 finished. Time: 1.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.03 minutes ---\n",
            " Step 37/306: Forecasting for target date 2002-04-01\n",
            "  Training window ends: 2002-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 483, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 37 finished. Time: 1.47s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.05 minutes ---\n",
            " Step 38/306: Forecasting for target date 2002-05-01\n",
            "  Training window ends: 2002-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 484, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 38 finished. Time: 1.48s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.07 minutes ---\n",
            " Step 39/306: Forecasting for target date 2002-06-01\n",
            "  Training window ends: 2002-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 485, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 39 finished. Time: 1.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.10 minutes ---\n",
            " Step 40/306: Forecasting for target date 2002-07-01\n",
            "  Training window ends: 2002-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 486, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 40 finished. Time: 2.70s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.14 minutes ---\n",
            " Step 41/306: Forecasting for target date 2002-08-01\n",
            "  Training window ends: 2002-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 487, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 41 finished. Time: 2.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.19 minutes ---\n",
            " Step 42/306: Forecasting for target date 2002-09-01\n",
            "  Training window ends: 2002-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 488, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 42 finished. Time: 1.52s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.21 minutes ---\n",
            " Step 43/306: Forecasting for target date 2002-10-01\n",
            "  Training window ends: 2002-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 489, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 43 finished. Time: 1.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.24 minutes ---\n",
            " Step 44/306: Forecasting for target date 2002-11-01\n",
            "  Training window ends: 2002-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 490, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 44 finished. Time: 1.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.26 minutes ---\n",
            " Step 45/306: Forecasting for target date 2002-12-01\n",
            "  Training window ends: 2002-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 491, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 45 finished. Time: 1.51s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.29 minutes ---\n",
            " Step 46/306: Forecasting for target date 2003-01-01\n",
            "  Training window ends: 2002-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 492, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 46 finished. Time: 1.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.31 minutes ---\n",
            " Step 47/306: Forecasting for target date 2003-02-01\n",
            "  Training window ends: 2003-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 493, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 47 finished. Time: 1.52s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.34 minutes ---\n",
            " Step 48/306: Forecasting for target date 2003-03-01\n",
            "  Training window ends: 2003-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 494, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 48 finished. Time: 2.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.39 minutes ---\n",
            " Step 49/306: Forecasting for target date 2003-04-01\n",
            "  Training window ends: 2003-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 495, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 49 finished. Time: 2.39s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.43 minutes ---\n",
            " Step 50/306: Forecasting for target date 2003-05-01\n",
            "  Training window ends: 2003-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 496, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 50 finished. Time: 1.54s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.45 minutes ---\n",
            " Step 51/306: Forecasting for target date 2003-06-01\n",
            "  Training window ends: 2003-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 497, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 51 finished. Time: 1.61s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.48 minutes ---\n",
            " Step 52/306: Forecasting for target date 2003-07-01\n",
            "  Training window ends: 2003-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 498, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 52 finished. Time: 1.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.50 minutes ---\n",
            " Step 53/306: Forecasting for target date 2003-08-01\n",
            "  Training window ends: 2003-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 499, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 53 finished. Time: 1.52s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.53 minutes ---\n",
            " Step 54/306: Forecasting for target date 2003-09-01\n",
            "  Training window ends: 2003-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 500, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 54 finished. Time: 1.55s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.56 minutes ---\n",
            " Step 55/306: Forecasting for target date 2003-10-01\n",
            "  Training window ends: 2003-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 501, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 55 finished. Time: 1.61s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.58 minutes ---\n",
            " Step 56/306: Forecasting for target date 2003-11-01\n",
            "  Training window ends: 2003-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 502, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 56 finished. Time: 2.72s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.63 minutes ---\n",
            " Step 57/306: Forecasting for target date 2003-12-01\n",
            "  Training window ends: 2003-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 503, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 57 finished. Time: 2.25s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.67 minutes ---\n",
            " Step 58/306: Forecasting for target date 2004-01-01\n",
            "  Training window ends: 2003-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 504, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 58 finished. Time: 1.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.69 minutes ---\n",
            " Step 59/306: Forecasting for target date 2004-02-01\n",
            "  Training window ends: 2004-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 505, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 59 finished. Time: 1.55s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.72 minutes ---\n",
            " Step 60/306: Forecasting for target date 2004-03-01\n",
            "  Training window ends: 2004-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 506, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 60 finished. Time: 1.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.74 minutes ---\n",
            " Step 61/306: Forecasting for target date 2004-04-01\n",
            "  Training window ends: 2004-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 507, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 61 finished. Time: 1.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.77 minutes ---\n",
            " Step 62/306: Forecasting for target date 2004-05-01\n",
            "  Training window ends: 2004-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 508, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 62 finished. Time: 1.60s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.80 minutes ---\n",
            " Step 63/306: Forecasting for target date 2004-06-01\n",
            "  Training window ends: 2004-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 509, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 63 finished. Time: 1.77s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.83 minutes ---\n",
            " Step 64/306: Forecasting for target date 2004-07-01\n",
            "  Training window ends: 2004-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 510, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 64 finished. Time: 3.07s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.88 minutes ---\n",
            " Step 65/306: Forecasting for target date 2004-08-01\n",
            "  Training window ends: 2004-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 511, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 65 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.91 minutes ---\n",
            " Step 66/306: Forecasting for target date 2004-09-01\n",
            "  Training window ends: 2004-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 512, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 66 finished. Time: 1.59s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.94 minutes ---\n",
            " Step 67/306: Forecasting for target date 2004-10-01\n",
            "  Training window ends: 2004-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 513, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 67 finished. Time: 1.59s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.96 minutes ---\n",
            " Step 68/306: Forecasting for target date 2004-11-01\n",
            "  Training window ends: 2004-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 514, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 68 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 1.99 minutes ---\n",
            " Step 69/306: Forecasting for target date 2004-12-01\n",
            "  Training window ends: 2004-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 515, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 69 finished. Time: 1.63s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.02 minutes ---\n",
            " Step 70/306: Forecasting for target date 2005-01-01\n",
            "  Training window ends: 2004-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 516, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 70 finished. Time: 1.64s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.04 minutes ---\n",
            " Step 71/306: Forecasting for target date 2005-02-01\n",
            "  Training window ends: 2005-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 517, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 71 finished. Time: 2.27s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.08 minutes ---\n",
            " Step 72/306: Forecasting for target date 2005-03-01\n",
            "  Training window ends: 2005-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 518, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 72 finished. Time: 3.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.13 minutes ---\n",
            " Step 73/306: Forecasting for target date 2005-04-01\n",
            "  Training window ends: 2005-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 519, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 73 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.16 minutes ---\n",
            " Step 74/306: Forecasting for target date 2005-05-01\n",
            "  Training window ends: 2005-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 520, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 74 finished. Time: 1.70s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.19 minutes ---\n",
            " Step 75/306: Forecasting for target date 2005-06-01\n",
            "  Training window ends: 2005-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 521, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 75 finished. Time: 1.56s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.21 minutes ---\n",
            " Step 76/306: Forecasting for target date 2005-07-01\n",
            "  Training window ends: 2005-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 522, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 76 finished. Time: 1.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.24 minutes ---\n",
            " Step 77/306: Forecasting for target date 2005-08-01\n",
            "  Training window ends: 2005-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 523, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 77 finished. Time: 1.57s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.27 minutes ---\n",
            " Step 78/306: Forecasting for target date 2005-09-01\n",
            "  Training window ends: 2005-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 524, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 78 finished. Time: 1.63s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.29 minutes ---\n",
            " Step 79/306: Forecasting for target date 2005-10-01\n",
            "  Training window ends: 2005-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 525, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 79 finished. Time: 2.73s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.34 minutes ---\n",
            " Step 80/306: Forecasting for target date 2005-11-01\n",
            "  Training window ends: 2005-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 526, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 80 finished. Time: 2.28s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.38 minutes ---\n",
            " Step 81/306: Forecasting for target date 2005-12-01\n",
            "  Training window ends: 2005-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 527, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 81 finished. Time: 1.61s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.40 minutes ---\n",
            " Step 82/306: Forecasting for target date 2006-01-01\n",
            "  Training window ends: 2005-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 528, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 82 finished. Time: 1.60s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.43 minutes ---\n",
            " Step 83/306: Forecasting for target date 2006-02-01\n",
            "  Training window ends: 2006-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 529, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 83 finished. Time: 1.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.46 minutes ---\n",
            " Step 84/306: Forecasting for target date 2006-03-01\n",
            "  Training window ends: 2006-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 530, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 84 finished. Time: 1.67s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.49 minutes ---\n",
            " Step 85/306: Forecasting for target date 2006-04-01\n",
            "  Training window ends: 2006-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 531, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 85 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.51 minutes ---\n",
            " Step 86/306: Forecasting for target date 2006-05-01\n",
            "  Training window ends: 2006-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 532, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 86 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.54 minutes ---\n",
            " Step 87/306: Forecasting for target date 2006-06-01\n",
            "  Training window ends: 2006-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 533, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 87 finished. Time: 3.40s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.60 minutes ---\n",
            " Step 88/306: Forecasting for target date 2006-07-01\n",
            "  Training window ends: 2006-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 534, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 88 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.63 minutes ---\n",
            " Step 89/306: Forecasting for target date 2006-08-01\n",
            "  Training window ends: 2006-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 535, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 89 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.66 minutes ---\n",
            " Step 90/306: Forecasting for target date 2006-09-01\n",
            "  Training window ends: 2006-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 536, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 90 finished. Time: 1.63s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.68 minutes ---\n",
            " Step 91/306: Forecasting for target date 2006-10-01\n",
            "  Training window ends: 2006-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 537, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 91 finished. Time: 1.61s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.71 minutes ---\n",
            " Step 92/306: Forecasting for target date 2006-11-01\n",
            "  Training window ends: 2006-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 538, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 92 finished. Time: 1.63s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.74 minutes ---\n",
            " Step 93/306: Forecasting for target date 2006-12-01\n",
            "  Training window ends: 2006-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 539, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 93 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.76 minutes ---\n",
            " Step 94/306: Forecasting for target date 2007-01-01\n",
            "  Training window ends: 2006-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 540, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 94 finished. Time: 2.82s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.81 minutes ---\n",
            " Step 95/306: Forecasting for target date 2007-02-01\n",
            "  Training window ends: 2007-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 541, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 95 finished. Time: 2.44s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.85 minutes ---\n",
            " Step 96/306: Forecasting for target date 2007-03-01\n",
            "  Training window ends: 2007-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 542, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 96 finished. Time: 1.74s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.88 minutes ---\n",
            " Step 97/306: Forecasting for target date 2007-04-01\n",
            "  Training window ends: 2007-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 543, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 97 finished. Time: 1.66s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.91 minutes ---\n",
            " Step 98/306: Forecasting for target date 2007-05-01\n",
            "  Training window ends: 2007-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 544, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 98 finished. Time: 2.04s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.94 minutes ---\n",
            " Step 99/306: Forecasting for target date 2007-06-01\n",
            "  Training window ends: 2007-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 545, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 99 finished. Time: 1.69s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 2.97 minutes ---\n",
            " Step 100/306: Forecasting for target date 2007-07-01\n",
            "  Training window ends: 2007-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 546, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 100 finished. Time: 1.72s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.00 minutes ---\n",
            " Step 101/306: Forecasting for target date 2007-08-01\n",
            "  Training window ends: 2007-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 547, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 101 finished. Time: 2.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.05 minutes ---\n",
            " Step 102/306: Forecasting for target date 2007-09-01\n",
            "  Training window ends: 2007-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 548, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 102 finished. Time: 2.46s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.09 minutes ---\n",
            " Step 103/306: Forecasting for target date 2007-10-01\n",
            "  Training window ends: 2007-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 549, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 103 finished. Time: 1.60s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.12 minutes ---\n",
            " Step 104/306: Forecasting for target date 2007-11-01\n",
            "  Training window ends: 2007-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 550, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 104 finished. Time: 1.73s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.14 minutes ---\n",
            " Step 105/306: Forecasting for target date 2007-12-01\n",
            "  Training window ends: 2007-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 551, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 105 finished. Time: 1.73s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.17 minutes ---\n",
            " Step 106/306: Forecasting for target date 2008-01-01\n",
            "  Training window ends: 2007-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 552, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 106 finished. Time: 1.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.20 minutes ---\n",
            " Step 107/306: Forecasting for target date 2008-02-01\n",
            "  Training window ends: 2008-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 553, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 107 finished. Time: 1.77s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.23 minutes ---\n",
            " Step 108/306: Forecasting for target date 2008-03-01\n",
            "  Training window ends: 2008-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 554, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 108 finished. Time: 2.70s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.28 minutes ---\n",
            " Step 109/306: Forecasting for target date 2008-04-01\n",
            "  Training window ends: 2008-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 555, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 109 finished. Time: 2.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.32 minutes ---\n",
            " Step 110/306: Forecasting for target date 2008-05-01\n",
            "  Training window ends: 2008-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 556, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 110 finished. Time: 1.68s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.35 minutes ---\n",
            " Step 111/306: Forecasting for target date 2008-06-01\n",
            "  Training window ends: 2008-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 557, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 111 finished. Time: 1.67s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.38 minutes ---\n",
            " Step 112/306: Forecasting for target date 2008-07-01\n",
            "  Training window ends: 2008-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 558, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 112 finished. Time: 1.75s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.41 minutes ---\n",
            " Step 113/306: Forecasting for target date 2008-08-01\n",
            "  Training window ends: 2008-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 559, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 113 finished. Time: 1.69s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.44 minutes ---\n",
            " Step 114/306: Forecasting for target date 2008-09-01\n",
            "  Training window ends: 2008-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 560, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 114 finished. Time: 1.71s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.47 minutes ---\n",
            " Step 115/306: Forecasting for target date 2008-10-01\n",
            "  Training window ends: 2008-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 561, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 115 finished. Time: 2.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.51 minutes ---\n",
            " Step 116/306: Forecasting for target date 2008-11-01\n",
            "  Training window ends: 2008-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 562, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 116 finished. Time: 4.79s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.59 minutes ---\n",
            " Step 117/306: Forecasting for target date 2008-12-01\n",
            "  Training window ends: 2008-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 563, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 117 finished. Time: 2.35s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.63 minutes ---\n",
            " Step 118/306: Forecasting for target date 2009-01-01\n",
            "  Training window ends: 2008-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 564, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 118 finished. Time: 2.32s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.67 minutes ---\n",
            " Step 119/306: Forecasting for target date 2009-02-01\n",
            "  Training window ends: 2009-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 565, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 119 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.70 minutes ---\n",
            " Step 120/306: Forecasting for target date 2009-03-01\n",
            "  Training window ends: 2009-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 566, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 120 finished. Time: 1.71s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.72 minutes ---\n",
            " Step 121/306: Forecasting for target date 2009-04-01\n",
            "  Training window ends: 2009-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 567, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 121 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.75 minutes ---\n",
            " Step 122/306: Forecasting for target date 2009-05-01\n",
            "  Training window ends: 2009-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 568, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 122 finished. Time: 3.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.80 minutes ---\n",
            " Step 123/306: Forecasting for target date 2009-06-01\n",
            "  Training window ends: 2009-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 569, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 123 finished. Time: 2.30s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.84 minutes ---\n",
            " Step 124/306: Forecasting for target date 2009-07-01\n",
            "  Training window ends: 2009-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 570, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 124 finished. Time: 1.90s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.87 minutes ---\n",
            " Step 125/306: Forecasting for target date 2009-08-01\n",
            "  Training window ends: 2009-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 571, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 125 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.91 minutes ---\n",
            " Step 126/306: Forecasting for target date 2009-09-01\n",
            "  Training window ends: 2009-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 572, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 126 finished. Time: 1.77s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.94 minutes ---\n",
            " Step 127/306: Forecasting for target date 2009-10-01\n",
            "  Training window ends: 2009-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 573, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 127 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 3.97 minutes ---\n",
            " Step 128/306: Forecasting for target date 2009-11-01\n",
            "  Training window ends: 2009-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 574, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 128 finished. Time: 2.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.00 minutes ---\n",
            " Step 129/306: Forecasting for target date 2009-12-01\n",
            "  Training window ends: 2009-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 575, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 129 finished. Time: 3.79s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.06 minutes ---\n",
            " Step 130/306: Forecasting for target date 2010-01-01\n",
            "  Training window ends: 2009-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 576, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 130 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.09 minutes ---\n",
            " Step 131/306: Forecasting for target date 2010-02-01\n",
            "  Training window ends: 2010-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 577, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 131 finished. Time: 1.79s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.12 minutes ---\n",
            " Step 132/306: Forecasting for target date 2010-03-01\n",
            "  Training window ends: 2010-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 578, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 132 finished. Time: 1.82s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.15 minutes ---\n",
            " Step 133/306: Forecasting for target date 2010-04-01\n",
            "  Training window ends: 2010-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 579, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 133 finished. Time: 1.94s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.19 minutes ---\n",
            " Step 134/306: Forecasting for target date 2010-05-01\n",
            "  Training window ends: 2010-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 580, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 134 finished. Time: 1.77s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.22 minutes ---\n",
            " Step 135/306: Forecasting for target date 2010-06-01\n",
            "  Training window ends: 2010-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 581, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 135 finished. Time: 2.67s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.26 minutes ---\n",
            " Step 136/306: Forecasting for target date 2010-07-01\n",
            "  Training window ends: 2010-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 582, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 136 finished. Time: 3.03s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.31 minutes ---\n",
            " Step 137/306: Forecasting for target date 2010-08-01\n",
            "  Training window ends: 2010-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 583, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 137 finished. Time: 1.82s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.34 minutes ---\n",
            " Step 138/306: Forecasting for target date 2010-09-01\n",
            "  Training window ends: 2010-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 584, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 138 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.37 minutes ---\n",
            " Step 139/306: Forecasting for target date 2010-10-01\n",
            "  Training window ends: 2010-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 585, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 139 finished. Time: 1.75s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.40 minutes ---\n",
            " Step 140/306: Forecasting for target date 2010-11-01\n",
            "  Training window ends: 2010-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 586, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 140 finished. Time: 1.73s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.43 minutes ---\n",
            " Step 141/306: Forecasting for target date 2010-12-01\n",
            "  Training window ends: 2010-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 587, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 141 finished. Time: 1.76s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.46 minutes ---\n",
            " Step 142/306: Forecasting for target date 2011-01-01\n",
            "  Training window ends: 2010-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 588, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 142 finished. Time: 3.24s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.51 minutes ---\n",
            " Step 143/306: Forecasting for target date 2011-02-01\n",
            "  Training window ends: 2011-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 589, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 143 finished. Time: 2.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.55 minutes ---\n",
            " Step 144/306: Forecasting for target date 2011-03-01\n",
            "  Training window ends: 2011-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 590, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 144 finished. Time: 1.77s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.58 minutes ---\n",
            " Step 145/306: Forecasting for target date 2011-04-01\n",
            "  Training window ends: 2011-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 591, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 145 finished. Time: 1.73s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.61 minutes ---\n",
            " Step 146/306: Forecasting for target date 2011-05-01\n",
            "  Training window ends: 2011-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 592, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 146 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.64 minutes ---\n",
            " Step 147/306: Forecasting for target date 2011-06-01\n",
            "  Training window ends: 2011-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 593, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 147 finished. Time: 1.84s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.67 minutes ---\n",
            " Step 148/306: Forecasting for target date 2011-07-01\n",
            "  Training window ends: 2011-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 594, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 148 finished. Time: 1.92s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.71 minutes ---\n",
            " Step 149/306: Forecasting for target date 2011-08-01\n",
            "  Training window ends: 2011-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 595, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 149 finished. Time: 2.96s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.76 minutes ---\n",
            " Step 150/306: Forecasting for target date 2011-09-01\n",
            "  Training window ends: 2011-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 596, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 150 finished. Time: 2.54s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.80 minutes ---\n",
            " Step 151/306: Forecasting for target date 2011-10-01\n",
            "  Training window ends: 2011-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 597, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 151 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.83 minutes ---\n",
            " Step 152/306: Forecasting for target date 2011-11-01\n",
            "  Training window ends: 2011-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 598, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 152 finished. Time: 1.80s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.86 minutes ---\n",
            " Step 153/306: Forecasting for target date 2011-12-01\n",
            "  Training window ends: 2011-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 599, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 153 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.89 minutes ---\n",
            " Step 154/306: Forecasting for target date 2012-01-01\n",
            "  Training window ends: 2011-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 600, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 154 finished. Time: 1.76s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.92 minutes ---\n",
            " Step 155/306: Forecasting for target date 2012-02-01\n",
            "  Training window ends: 2012-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 601, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 155 finished. Time: 1.84s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 4.95 minutes ---\n",
            " Step 156/306: Forecasting for target date 2012-03-01\n",
            "  Training window ends: 2012-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 602, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 156 finished. Time: 4.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.03 minutes ---\n",
            " Step 157/306: Forecasting for target date 2012-04-01\n",
            "  Training window ends: 2012-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 603, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 157 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.06 minutes ---\n",
            " Step 158/306: Forecasting for target date 2012-05-01\n",
            "  Training window ends: 2012-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 604, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 158 finished. Time: 1.72s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.09 minutes ---\n",
            " Step 159/306: Forecasting for target date 2012-06-01\n",
            "  Training window ends: 2012-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 605, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 159 finished. Time: 1.80s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.12 minutes ---\n",
            " Step 160/306: Forecasting for target date 2012-07-01\n",
            "  Training window ends: 2012-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 606, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 160 finished. Time: 1.92s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.15 minutes ---\n",
            " Step 161/306: Forecasting for target date 2012-08-01\n",
            "  Training window ends: 2012-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 607, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 161 finished. Time: 1.92s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.18 minutes ---\n",
            " Step 162/306: Forecasting for target date 2012-09-01\n",
            "  Training window ends: 2012-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 608, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 162 finished. Time: 3.13s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.23 minutes ---\n",
            " Step 163/306: Forecasting for target date 2012-10-01\n",
            "  Training window ends: 2012-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 609, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 163 finished. Time: 2.45s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.28 minutes ---\n",
            " Step 164/306: Forecasting for target date 2012-11-01\n",
            "  Training window ends: 2012-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 610, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 164 finished. Time: 1.82s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.31 minutes ---\n",
            " Step 165/306: Forecasting for target date 2012-12-01\n",
            "  Training window ends: 2012-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 611, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 165 finished. Time: 1.73s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.33 minutes ---\n",
            " Step 166/306: Forecasting for target date 2013-01-01\n",
            "  Training window ends: 2012-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 612, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 166 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.37 minutes ---\n",
            " Step 167/306: Forecasting for target date 2013-02-01\n",
            "  Training window ends: 2013-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 613, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 167 finished. Time: 1.79s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.39 minutes ---\n",
            " Step 168/306: Forecasting for target date 2013-03-01\n",
            "  Training window ends: 2013-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 614, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 168 finished. Time: 1.78s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.42 minutes ---\n",
            " Step 169/306: Forecasting for target date 2013-04-01\n",
            "  Training window ends: 2013-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 615, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 169 finished. Time: 3.17s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.48 minutes ---\n",
            " Step 170/306: Forecasting for target date 2013-05-01\n",
            "  Training window ends: 2013-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 616, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 170 finished. Time: 2.37s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.52 minutes ---\n",
            " Step 171/306: Forecasting for target date 2013-06-01\n",
            "  Training window ends: 2013-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 617, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 171 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.55 minutes ---\n",
            " Step 172/306: Forecasting for target date 2013-07-01\n",
            "  Training window ends: 2013-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 618, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 172 finished. Time: 1.80s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.58 minutes ---\n",
            " Step 173/306: Forecasting for target date 2013-08-01\n",
            "  Training window ends: 2013-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 619, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 173 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.61 minutes ---\n",
            " Step 174/306: Forecasting for target date 2013-09-01\n",
            "  Training window ends: 2013-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 620, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 174 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.64 minutes ---\n",
            " Step 175/306: Forecasting for target date 2013-10-01\n",
            "  Training window ends: 2013-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 621, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 175 finished. Time: 1.99s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.67 minutes ---\n",
            " Step 176/306: Forecasting for target date 2013-11-01\n",
            "  Training window ends: 2013-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 622, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 176 finished. Time: 4.03s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.74 minutes ---\n",
            " Step 177/306: Forecasting for target date 2013-12-01\n",
            "  Training window ends: 2013-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 623, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 177 finished. Time: 1.79s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.77 minutes ---\n",
            " Step 178/306: Forecasting for target date 2014-01-01\n",
            "  Training window ends: 2013-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 624, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 178 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.80 minutes ---\n",
            " Step 179/306: Forecasting for target date 2014-02-01\n",
            "  Training window ends: 2014-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 625, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 179 finished. Time: 1.78s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.83 minutes ---\n",
            " Step 180/306: Forecasting for target date 2014-03-01\n",
            "  Training window ends: 2014-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 626, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 180 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.86 minutes ---\n",
            " Step 181/306: Forecasting for target date 2014-04-01\n",
            "  Training window ends: 2014-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 627, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 181 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.89 minutes ---\n",
            " Step 182/306: Forecasting for target date 2014-05-01\n",
            "  Training window ends: 2014-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 628, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 182 finished. Time: 3.18s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.94 minutes ---\n",
            " Step 183/306: Forecasting for target date 2014-06-01\n",
            "  Training window ends: 2014-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 629, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 183 finished. Time: 2.43s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 5.98 minutes ---\n",
            " Step 184/306: Forecasting for target date 2014-07-01\n",
            "  Training window ends: 2014-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 630, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 184 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.01 minutes ---\n",
            " Step 185/306: Forecasting for target date 2014-08-01\n",
            "  Training window ends: 2014-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 631, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 185 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.05 minutes ---\n",
            " Step 186/306: Forecasting for target date 2014-09-01\n",
            "  Training window ends: 2014-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 632, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 186 finished. Time: 1.84s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.08 minutes ---\n",
            " Step 187/306: Forecasting for target date 2014-10-01\n",
            "  Training window ends: 2014-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 633, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 187 finished. Time: 1.80s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.11 minutes ---\n",
            " Step 188/306: Forecasting for target date 2014-11-01\n",
            "  Training window ends: 2014-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 634, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 188 finished. Time: 2.03s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.14 minutes ---\n",
            " Step 189/306: Forecasting for target date 2014-12-01\n",
            "  Training window ends: 2014-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 635, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 189 finished. Time: 3.96s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.21 minutes ---\n",
            " Step 190/306: Forecasting for target date 2015-01-01\n",
            "  Training window ends: 2014-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 636, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 190 finished. Time: 1.79s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.24 minutes ---\n",
            " Step 191/306: Forecasting for target date 2015-02-01\n",
            "  Training window ends: 2015-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 637, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 191 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.27 minutes ---\n",
            " Step 192/306: Forecasting for target date 2015-03-01\n",
            "  Training window ends: 2015-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 638, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 192 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.30 minutes ---\n",
            " Step 193/306: Forecasting for target date 2015-04-01\n",
            "  Training window ends: 2015-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 639, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 193 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.33 minutes ---\n",
            " Step 194/306: Forecasting for target date 2015-05-01\n",
            "  Training window ends: 2015-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 640, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 194 finished. Time: 1.86s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.36 minutes ---\n",
            " Step 195/306: Forecasting for target date 2015-06-01\n",
            "  Training window ends: 2015-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 641, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 195 finished. Time: 3.17s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.41 minutes ---\n",
            " Step 196/306: Forecasting for target date 2015-07-01\n",
            "  Training window ends: 2015-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 642, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 196 finished. Time: 2.59s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.45 minutes ---\n",
            " Step 197/306: Forecasting for target date 2015-08-01\n",
            "  Training window ends: 2015-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 643, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 197 finished. Time: 1.82s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.48 minutes ---\n",
            " Step 198/306: Forecasting for target date 2015-09-01\n",
            "  Training window ends: 2015-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 644, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 198 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.51 minutes ---\n",
            " Step 199/306: Forecasting for target date 2015-10-01\n",
            "  Training window ends: 2015-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 645, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 199 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.55 minutes ---\n",
            " Step 200/306: Forecasting for target date 2015-11-01\n",
            "  Training window ends: 2015-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 646, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 200 finished. Time: 1.76s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.58 minutes ---\n",
            " Step 201/306: Forecasting for target date 2015-12-01\n",
            "  Training window ends: 2015-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 647, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 201 finished. Time: 1.80s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.61 minutes ---\n",
            " Step 202/306: Forecasting for target date 2016-01-01\n",
            "  Training window ends: 2015-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 648, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 202 finished. Time: 3.28s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.66 minutes ---\n",
            " Step 203/306: Forecasting for target date 2016-02-01\n",
            "  Training window ends: 2016-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 649, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 203 finished. Time: 2.29s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.70 minutes ---\n",
            " Step 204/306: Forecasting for target date 2016-03-01\n",
            "  Training window ends: 2016-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 650, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 204 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.73 minutes ---\n",
            " Step 205/306: Forecasting for target date 2016-04-01\n",
            "  Training window ends: 2016-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 651, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 205 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.76 minutes ---\n",
            " Step 206/306: Forecasting for target date 2016-05-01\n",
            "  Training window ends: 2016-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 652, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 206 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.79 minutes ---\n",
            " Step 207/306: Forecasting for target date 2016-06-01\n",
            "  Training window ends: 2016-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 653, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 207 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.82 minutes ---\n",
            " Step 208/306: Forecasting for target date 2016-07-01\n",
            "  Training window ends: 2016-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 654, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 208 finished. Time: 2.19s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.86 minutes ---\n",
            " Step 209/306: Forecasting for target date 2016-08-01\n",
            "  Training window ends: 2016-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 655, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 209 finished. Time: 3.96s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.92 minutes ---\n",
            " Step 210/306: Forecasting for target date 2016-09-01\n",
            "  Training window ends: 2016-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 656, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 210 finished. Time: 1.93s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.96 minutes ---\n",
            " Step 211/306: Forecasting for target date 2016-10-01\n",
            "  Training window ends: 2016-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 657, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 211 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 6.99 minutes ---\n",
            " Step 212/306: Forecasting for target date 2016-11-01\n",
            "  Training window ends: 2016-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 658, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 212 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.02 minutes ---\n",
            " Step 213/306: Forecasting for target date 2016-12-01\n",
            "  Training window ends: 2016-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 659, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 213 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.05 minutes ---\n",
            " Step 214/306: Forecasting for target date 2017-01-01\n",
            "  Training window ends: 2016-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 660, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 214 finished. Time: 1.87s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.08 minutes ---\n",
            " Step 215/306: Forecasting for target date 2017-02-01\n",
            "  Training window ends: 2017-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 661, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 215 finished. Time: 4.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.15 minutes ---\n",
            " Step 216/306: Forecasting for target date 2017-03-01\n",
            "  Training window ends: 2017-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 662, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 216 finished. Time: 1.83s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.18 minutes ---\n",
            " Step 217/306: Forecasting for target date 2017-04-01\n",
            "  Training window ends: 2017-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 663, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 217 finished. Time: 1.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.21 minutes ---\n",
            " Step 218/306: Forecasting for target date 2017-05-01\n",
            "  Training window ends: 2017-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 664, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 218 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.24 minutes ---\n",
            " Step 219/306: Forecasting for target date 2017-06-01\n",
            "  Training window ends: 2017-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 665, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 219 finished. Time: 1.76s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.27 minutes ---\n",
            " Step 220/306: Forecasting for target date 2017-07-01\n",
            "  Training window ends: 2017-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 666, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 220 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.30 minutes ---\n",
            " Step 221/306: Forecasting for target date 2017-08-01\n",
            "  Training window ends: 2017-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 667, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 221 finished. Time: 3.10s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.35 minutes ---\n",
            " Step 222/306: Forecasting for target date 2017-09-01\n",
            "  Training window ends: 2017-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 668, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 222 finished. Time: 2.77s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.40 minutes ---\n",
            " Step 223/306: Forecasting for target date 2017-10-01\n",
            "  Training window ends: 2017-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 669, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 223 finished. Time: 1.94s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.43 minutes ---\n",
            " Step 224/306: Forecasting for target date 2017-11-01\n",
            "  Training window ends: 2017-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 670, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 224 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.46 minutes ---\n",
            " Step 225/306: Forecasting for target date 2017-12-01\n",
            "  Training window ends: 2017-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 671, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 225 finished. Time: 1.93s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.50 minutes ---\n",
            " Step 226/306: Forecasting for target date 2018-01-01\n",
            "  Training window ends: 2017-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 672, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 226 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.53 minutes ---\n",
            " Step 227/306: Forecasting for target date 2018-02-01\n",
            "  Training window ends: 2018-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 673, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 227 finished. Time: 2.34s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.57 minutes ---\n",
            " Step 228/306: Forecasting for target date 2018-03-01\n",
            "  Training window ends: 2018-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 674, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 228 finished. Time: 3.55s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.63 minutes ---\n",
            " Step 229/306: Forecasting for target date 2018-04-01\n",
            "  Training window ends: 2018-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 675, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 229 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.66 minutes ---\n",
            " Step 230/306: Forecasting for target date 2018-05-01\n",
            "  Training window ends: 2018-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 676, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 230 finished. Time: 2.00s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.69 minutes ---\n",
            " Step 231/306: Forecasting for target date 2018-06-01\n",
            "  Training window ends: 2018-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 677, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 231 finished. Time: 1.84s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.72 minutes ---\n",
            " Step 232/306: Forecasting for target date 2018-07-01\n",
            "  Training window ends: 2018-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 678, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 232 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.75 minutes ---\n",
            " Step 233/306: Forecasting for target date 2018-08-01\n",
            "  Training window ends: 2018-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 679, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 233 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.78 minutes ---\n",
            " Step 234/306: Forecasting for target date 2018-09-01\n",
            "  Training window ends: 2018-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 680, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 234 finished. Time: 3.20s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.84 minutes ---\n",
            " Step 235/306: Forecasting for target date 2018-10-01\n",
            "  Training window ends: 2018-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 681, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 235 finished. Time: 2.65s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.88 minutes ---\n",
            " Step 236/306: Forecasting for target date 2018-11-01\n",
            "  Training window ends: 2018-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 682, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 236 finished. Time: 2.06s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.91 minutes ---\n",
            " Step 237/306: Forecasting for target date 2018-12-01\n",
            "  Training window ends: 2018-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 683, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 237 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.95 minutes ---\n",
            " Step 238/306: Forecasting for target date 2019-01-01\n",
            "  Training window ends: 2018-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 684, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 238 finished. Time: 2.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 7.98 minutes ---\n",
            " Step 239/306: Forecasting for target date 2019-02-01\n",
            "  Training window ends: 2019-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 685, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 239 finished. Time: 2.08s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.02 minutes ---\n",
            " Step 240/306: Forecasting for target date 2019-03-01\n",
            "  Training window ends: 2019-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 686, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 240 finished. Time: 3.42s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.07 minutes ---\n",
            " Step 241/306: Forecasting for target date 2019-04-01\n",
            "  Training window ends: 2019-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 687, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 241 finished. Time: 2.54s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.11 minutes ---\n",
            " Step 242/306: Forecasting for target date 2019-05-01\n",
            "  Training window ends: 2019-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 688, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 242 finished. Time: 2.06s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.15 minutes ---\n",
            " Step 243/306: Forecasting for target date 2019-06-01\n",
            "  Training window ends: 2019-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 689, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 243 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.18 minutes ---\n",
            " Step 244/306: Forecasting for target date 2019-07-01\n",
            "  Training window ends: 2019-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 690, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 244 finished. Time: 1.87s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.21 minutes ---\n",
            " Step 245/306: Forecasting for target date 2019-08-01\n",
            "  Training window ends: 2019-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 691, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 245 finished. Time: 1.85s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.24 minutes ---\n",
            " Step 246/306: Forecasting for target date 2019-09-01\n",
            "  Training window ends: 2019-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 692, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 246 finished. Time: 2.19s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.28 minutes ---\n",
            " Step 247/306: Forecasting for target date 2019-10-01\n",
            "  Training window ends: 2019-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 693, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 247 finished. Time: 3.68s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.34 minutes ---\n",
            " Step 248/306: Forecasting for target date 2019-11-01\n",
            "  Training window ends: 2019-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 694, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 248 finished. Time: 1.88s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.37 minutes ---\n",
            " Step 249/306: Forecasting for target date 2019-12-01\n",
            "  Training window ends: 2019-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 695, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 249 finished. Time: 1.90s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.40 minutes ---\n",
            " Step 250/306: Forecasting for target date 2020-01-01\n",
            "  Training window ends: 2019-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 696, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 250 finished. Time: 1.93s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.44 minutes ---\n",
            " Step 251/306: Forecasting for target date 2020-02-01\n",
            "  Training window ends: 2020-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 697, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 251 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.47 minutes ---\n",
            " Step 252/306: Forecasting for target date 2020-03-01\n",
            "  Training window ends: 2020-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 698, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 252 finished. Time: 1.94s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.50 minutes ---\n",
            " Step 253/306: Forecasting for target date 2020-04-01\n",
            "  Training window ends: 2020-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 699, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 253 finished. Time: 3.97s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.57 minutes ---\n",
            " Step 254/306: Forecasting for target date 2020-05-01\n",
            "  Training window ends: 2020-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 700, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 254 finished. Time: 2.03s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.60 minutes ---\n",
            " Step 255/306: Forecasting for target date 2020-06-01\n",
            "  Training window ends: 2020-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 701, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 255 finished. Time: 1.93s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.63 minutes ---\n",
            " Step 256/306: Forecasting for target date 2020-07-01\n",
            "  Training window ends: 2020-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 702, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 256 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.66 minutes ---\n",
            " Step 257/306: Forecasting for target date 2020-08-01\n",
            "  Training window ends: 2020-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 703, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 257 finished. Time: 1.90s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.70 minutes ---\n",
            " Step 258/306: Forecasting for target date 2020-09-01\n",
            "  Training window ends: 2020-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 704, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 258 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.73 minutes ---\n",
            " Step 259/306: Forecasting for target date 2020-10-01\n",
            "  Training window ends: 2020-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 705, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 259 finished. Time: 3.26s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.78 minutes ---\n",
            " Step 260/306: Forecasting for target date 2020-11-01\n",
            "  Training window ends: 2020-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 706, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 260 finished. Time: 2.51s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.82 minutes ---\n",
            " Step 261/306: Forecasting for target date 2020-12-01\n",
            "  Training window ends: 2020-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 707, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 261 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.86 minutes ---\n",
            " Step 262/306: Forecasting for target date 2021-01-01\n",
            "  Training window ends: 2020-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 708, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 262 finished. Time: 1.90s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.89 minutes ---\n",
            " Step 263/306: Forecasting for target date 2021-02-01\n",
            "  Training window ends: 2021-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 709, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 263 finished. Time: 1.92s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.92 minutes ---\n",
            " Step 264/306: Forecasting for target date 2021-03-01\n",
            "  Training window ends: 2021-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 710, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 264 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.95 minutes ---\n",
            " Step 265/306: Forecasting for target date 2021-04-01\n",
            "  Training window ends: 2021-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 711, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 265 finished. Time: 2.25s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 8.99 minutes ---\n",
            " Step 266/306: Forecasting for target date 2021-05-01\n",
            "  Training window ends: 2021-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 712, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 266 finished. Time: 3.55s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.05 minutes ---\n",
            " Step 267/306: Forecasting for target date 2021-06-01\n",
            "  Training window ends: 2021-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 713, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 267 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.08 minutes ---\n",
            " Step 268/306: Forecasting for target date 2021-07-01\n",
            "  Training window ends: 2021-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 714, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 268 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.11 minutes ---\n",
            " Step 269/306: Forecasting for target date 2021-08-01\n",
            "  Training window ends: 2021-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 715, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 269 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.14 minutes ---\n",
            " Step 270/306: Forecasting for target date 2021-09-01\n",
            "  Training window ends: 2021-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 716, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 270 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.17 minutes ---\n",
            " Step 271/306: Forecasting for target date 2021-10-01\n",
            "  Training window ends: 2021-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 717, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 271 finished. Time: 1.89s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.21 minutes ---\n",
            " Step 272/306: Forecasting for target date 2021-11-01\n",
            "  Training window ends: 2021-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 718, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 272 finished. Time: 3.31s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.26 minutes ---\n",
            " Step 273/306: Forecasting for target date 2021-12-01\n",
            "  Training window ends: 2021-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 719, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 273 finished. Time: 2.36s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.30 minutes ---\n",
            " Step 274/306: Forecasting for target date 2022-01-01\n",
            "  Training window ends: 2021-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 720, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 274 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.33 minutes ---\n",
            " Step 275/306: Forecasting for target date 2022-02-01\n",
            "  Training window ends: 2022-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 721, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 275 finished. Time: 1.90s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.36 minutes ---\n",
            " Step 276/306: Forecasting for target date 2022-03-01\n",
            "  Training window ends: 2022-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 722, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 276 finished. Time: 1.93s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.40 minutes ---\n",
            " Step 277/306: Forecasting for target date 2022-04-01\n",
            "  Training window ends: 2022-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 723, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 277 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.43 minutes ---\n",
            " Step 278/306: Forecasting for target date 2022-05-01\n",
            "  Training window ends: 2022-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 724, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 278 finished. Time: 2.32s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.47 minutes ---\n",
            " Step 279/306: Forecasting for target date 2022-06-01\n",
            "  Training window ends: 2022-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 725, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 279 finished. Time: 3.50s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.53 minutes ---\n",
            " Step 280/306: Forecasting for target date 2022-07-01\n",
            "  Training window ends: 2022-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 726, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 280 finished. Time: 1.91s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.56 minutes ---\n",
            " Step 281/306: Forecasting for target date 2022-08-01\n",
            "  Training window ends: 2022-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 727, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 281 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.59 minutes ---\n",
            " Step 282/306: Forecasting for target date 2022-09-01\n",
            "  Training window ends: 2022-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 728, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 282 finished. Time: 1.92s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.62 minutes ---\n",
            " Step 283/306: Forecasting for target date 2022-10-01\n",
            "  Training window ends: 2022-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 729, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 283 finished. Time: 1.99s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.66 minutes ---\n",
            " Step 284/306: Forecasting for target date 2022-11-01\n",
            "  Training window ends: 2022-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 730, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 284 finished. Time: 2.00s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.69 minutes ---\n",
            " Step 285/306: Forecasting for target date 2022-12-01\n",
            "  Training window ends: 2022-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 731, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 285 finished. Time: 3.58s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.75 minutes ---\n",
            " Step 286/306: Forecasting for target date 2023-01-01\n",
            "  Training window ends: 2022-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 732, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 286 finished. Time: 2.08s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.78 minutes ---\n",
            " Step 287/306: Forecasting for target date 2023-02-01\n",
            "  Training window ends: 2023-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 733, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 287 finished. Time: 1.96s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.82 minutes ---\n",
            " Step 288/306: Forecasting for target date 2023-03-01\n",
            "  Training window ends: 2023-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 734, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 288 finished. Time: 1.93s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.85 minutes ---\n",
            " Step 289/306: Forecasting for target date 2023-04-01\n",
            "  Training window ends: 2023-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 735, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 289 finished. Time: 2.04s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.88 minutes ---\n",
            " Step 290/306: Forecasting for target date 2023-05-01\n",
            "  Training window ends: 2023-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 736, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 290 finished. Time: 1.96s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.91 minutes ---\n",
            " Step 291/306: Forecasting for target date 2023-06-01\n",
            "  Training window ends: 2023-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 737, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 291 finished. Time: 3.64s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 9.98 minutes ---\n",
            " Step 292/306: Forecasting for target date 2023-07-01\n",
            "  Training window ends: 2023-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 738, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 292 finished. Time: 2.44s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.02 minutes ---\n",
            " Step 293/306: Forecasting for target date 2023-08-01\n",
            "  Training window ends: 2023-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 739, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 293 finished. Time: 2.00s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.05 minutes ---\n",
            " Step 294/306: Forecasting for target date 2023-09-01\n",
            "  Training window ends: 2023-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 740, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 294 finished. Time: 2.00s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.08 minutes ---\n",
            " Step 295/306: Forecasting for target date 2023-10-01\n",
            "  Training window ends: 2023-09-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 741, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 295 finished. Time: 2.16s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.12 minutes ---\n",
            " Step 296/306: Forecasting for target date 2023-11-01\n",
            "  Training window ends: 2023-10-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 742, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 296 finished. Time: 2.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.15 minutes ---\n",
            " Step 297/306: Forecasting for target date 2023-12-01\n",
            "  Training window ends: 2023-11-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 743, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 297 finished. Time: 3.36s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.21 minutes ---\n",
            " Step 298/306: Forecasting for target date 2024-01-01\n",
            "  Training window ends: 2023-12-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 744, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 298 finished. Time: 2.53s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.25 minutes ---\n",
            " Step 299/306: Forecasting for target date 2024-02-01\n",
            "  Training window ends: 2024-01-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 745, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 299 finished. Time: 1.97s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.28 minutes ---\n",
            " Step 300/306: Forecasting for target date 2024-03-01\n",
            "  Training window ends: 2024-02-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 746, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 300 finished. Time: 2.01s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.32 minutes ---\n",
            " Step 301/306: Forecasting for target date 2024-04-01\n",
            "  Training window ends: 2024-03-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 747, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 301 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.35 minutes ---\n",
            " Step 302/306: Forecasting for target date 2024-05-01\n",
            "  Training window ends: 2024-04-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 748, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 302 finished. Time: 1.94s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.38 minutes ---\n",
            " Step 303/306: Forecasting for target date 2024-06-01\n",
            "  Training window ends: 2024-05-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 749, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 303 finished. Time: 3.24s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.44 minutes ---\n",
            " Step 304/306: Forecasting for target date 2024-07-01\n",
            "  Training window ends: 2024-06-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 750, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 304 finished. Time: 2.81s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.48 minutes ---\n",
            " Step 305/306: Forecasting for target date 2024-08-01\n",
            "  Training window ends: 2024-07-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 751, NaNs: 1\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "Training HGBoost...\n",
            "   Step 305 finished. Time: 1.95s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.51 minutes ---\n",
            " Step 306/306: Forecasting for target date 2024-09-01\n",
            "  Training window ends: 2024-08-01\n",
            "Processing Input: CBDI\n",
            "     Window samples before imputation: 752, NaNs: 1\n",
            "Training RandomForest...\n",
            "    Storing importance/coeffs for FINAL model (CBDI/RandomForest)...\n",
            "    Saved final model to /content/drive/MyDrive/Diffusion Indices/Final_Models_Joblib/model_CBDI_RandomForest_6mo_final.joblib\n",
            "Training XGBoost...\n",
            "    Storing importance/coeffs for FINAL model (CBDI/XGBoost)...\n",
            "    Saved final model to /content/drive/MyDrive/Diffusion Indices/Final_Models_Joblib/model_CBDI_XGBoost_6mo_final.joblib\n",
            "Training HGBoost...\n",
            "    Storing importance/coeffs for FINAL model (CBDI/HGBoost)...\n",
            "      WARN: Could not get feature_importances_ for HGBoost\n",
            "    Saved final model to /content/drive/MyDrive/Diffusion Indices/Final_Models_Joblib/model_CBDI_HGBoost_6mo_final.joblib\n",
            "   Step 306 finished. Time: 2.82s\n",
            "\n",
            "--- Recursive Loop Finished --- Total time: 10.56 minutes ---\n",
            "Saved prediction arrays.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_importances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3fqRJZRrg-N",
        "outputId": "beca33df-559a-4b10-a9b4-1c048c919a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('CBDI',\n",
              "  'RandomForest'): Output_Income__DI                           0.014348\n",
              " Labor_Market__DI                            0.150501\n",
              " Housing__DI                                 0.030370\n",
              " Consumption_Orders_Inventories__DI          0.007216\n",
              " Money_Credit__DI                            0.013792\n",
              " Interest_Rates_Spreads__DI                  0.030489\n",
              " FX_Rates__DI                                0.003938\n",
              " Prices__DI                                  0.006308\n",
              " Stock_Market__DI                            0.020435\n",
              " Overall_DI                                  0.054338\n",
              " Output_Income__DI_lag1                      0.021529\n",
              " Labor_Market__DI_lag1                       0.096697\n",
              " Housing__DI_lag1                            0.033363\n",
              " Consumption_Orders_Inventories__DI_lag1     0.004263\n",
              " Money_Credit__DI_lag1                       0.012106\n",
              " Interest_Rates_Spreads__DI_lag1             0.015165\n",
              " FX_Rates__DI_lag1                           0.002544\n",
              " Prices__DI_lag1                             0.006660\n",
              " Stock_Market__DI_lag1                       0.010050\n",
              " Overall_DI_lag1                             0.044124\n",
              " Output_Income__DI_lag2                      0.010100\n",
              " Labor_Market__DI_lag2                       0.034351\n",
              " Housing__DI_lag2                            0.026747\n",
              " Consumption_Orders_Inventories__DI_lag2     0.006684\n",
              " Money_Credit__DI_lag2                       0.015938\n",
              " Interest_Rates_Spreads__DI_lag2             0.012697\n",
              " FX_Rates__DI_lag2                           0.005449\n",
              " Prices__DI_lag2                             0.012070\n",
              " Stock_Market__DI_lag2                       0.004403\n",
              " Overall_DI_lag2                             0.029065\n",
              " Output_Income__DI_lag6                      0.006207\n",
              " Labor_Market__DI_lag6                       0.010064\n",
              " Housing__DI_lag6                            0.017248\n",
              " Consumption_Orders_Inventories__DI_lag6     0.008561\n",
              " Money_Credit__DI_lag6                       0.010231\n",
              " Interest_Rates_Spreads__DI_lag6             0.034596\n",
              " FX_Rates__DI_lag6                           0.006759\n",
              " Prices__DI_lag6                             0.010782\n",
              " Stock_Market__DI_lag6                       0.002812\n",
              " Overall_DI_lag6                             0.016432\n",
              " Output_Income__DI_lag12                     0.009286\n",
              " Labor_Market__DI_lag12                      0.022816\n",
              " Housing__DI_lag12                           0.013180\n",
              " Consumption_Orders_Inventories__DI_lag12    0.015814\n",
              " Money_Credit__DI_lag12                      0.005727\n",
              " Interest_Rates_Spreads__DI_lag12            0.026323\n",
              " FX_Rates__DI_lag12                          0.005504\n",
              " Prices__DI_lag12                            0.009609\n",
              " Stock_Market__DI_lag12                      0.004213\n",
              " Overall_DI_lag12                            0.028096\n",
              " dtype: float64,\n",
              " ('CBDI',\n",
              "  'XGBoost'): Output_Income__DI                           0.009994\n",
              " Labor_Market__DI                            0.097748\n",
              " Housing__DI                                 0.028096\n",
              " Consumption_Orders_Inventories__DI          0.008652\n",
              " Money_Credit__DI                            0.018141\n",
              " Interest_Rates_Spreads__DI                  0.028579\n",
              " FX_Rates__DI                                0.006455\n",
              " Prices__DI                                  0.007360\n",
              " Stock_Market__DI                            0.020402\n",
              " Overall_DI                                  0.048820\n",
              " Output_Income__DI_lag1                      0.019697\n",
              " Labor_Market__DI_lag1                       0.058804\n",
              " Housing__DI_lag1                            0.030243\n",
              " Consumption_Orders_Inventories__DI_lag1     0.008051\n",
              " Money_Credit__DI_lag1                       0.017738\n",
              " Interest_Rates_Spreads__DI_lag1             0.014914\n",
              " FX_Rates__DI_lag1                           0.013453\n",
              " Prices__DI_lag1                             0.006724\n",
              " Stock_Market__DI_lag1                       0.020800\n",
              " Overall_DI_lag1                             0.034918\n",
              " Output_Income__DI_lag2                      0.019692\n",
              " Labor_Market__DI_lag2                       0.020823\n",
              " Housing__DI_lag2                            0.028037\n",
              " Consumption_Orders_Inventories__DI_lag2     0.011088\n",
              " Money_Credit__DI_lag2                       0.018148\n",
              " Interest_Rates_Spreads__DI_lag2             0.023189\n",
              " FX_Rates__DI_lag2                           0.010165\n",
              " Prices__DI_lag2                             0.011017\n",
              " Stock_Market__DI_lag2                       0.011985\n",
              " Overall_DI_lag2                             0.043638\n",
              " Output_Income__DI_lag6                      0.008050\n",
              " Labor_Market__DI_lag6                       0.008149\n",
              " Housing__DI_lag6                            0.015460\n",
              " Consumption_Orders_Inventories__DI_lag6     0.013392\n",
              " Money_Credit__DI_lag6                       0.005666\n",
              " Interest_Rates_Spreads__DI_lag6             0.023687\n",
              " FX_Rates__DI_lag6                           0.017311\n",
              " Prices__DI_lag6                             0.010448\n",
              " Stock_Market__DI_lag6                       0.004429\n",
              " Overall_DI_lag6                             0.028983\n",
              " Output_Income__DI_lag12                     0.012001\n",
              " Labor_Market__DI_lag12                      0.021842\n",
              " Housing__DI_lag12                           0.023062\n",
              " Consumption_Orders_Inventories__DI_lag12    0.023945\n",
              " Money_Credit__DI_lag12                      0.010412\n",
              " Interest_Rates_Spreads__DI_lag12            0.024507\n",
              " FX_Rates__DI_lag12                          0.008439\n",
              " Prices__DI_lag12                            0.013302\n",
              " Stock_Market__DI_lag12                      0.013782\n",
              " Overall_DI_lag12                            0.015762\n",
              " dtype: float32}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Feature Importances / Coefficients from FINAL Recursive Models ---\")\n",
        "for (input_name, model_name), importance_series in final_model_importances.items():\n",
        "  print(f\"\\n=== Input: {input_name}, Model: {model_name} ===\")\n",
        "  if model_name == \"Logit\" or \"Logit\" in model_name:\n",
        "    coef_df = pd.DataFrame({'Coefficient': importance_series})\n",
        "    coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
        "    coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "    print(\"   Top 15 Coefficients (Absolute Value):\")\n",
        "    print(coef_df[['Coefficient']].head(15).to_string())\n",
        "  else:\n",
        "    imp_df = pd.DataFrame({'Importance': importance_series})\n",
        "    imp_df = imp_df.sort_values(by='Importance', ascending=False)\n",
        "    print(\"   Top 15 Feature Importances:\")\n",
        "    print(imp_df.head(15).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK8C2oiRF8oy",
        "outputId": "a0de45ec-ca92-4a96-e64a-a8cdfbf77a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Feature Importances / Coefficients from FINAL Recursive Models ---\n",
            "\n",
            "=== Input: CBDI, Model: RandomForest ===\n",
            "   Top 15 Feature Importances:\n",
            "                                  Importance\n",
            "Labor_Market__DI                    0.150501\n",
            "Labor_Market__DI_lag1               0.096697\n",
            "Overall_DI                          0.054338\n",
            "Overall_DI_lag1                     0.044124\n",
            "Interest_Rates_Spreads__DI_lag6     0.034596\n",
            "Labor_Market__DI_lag2               0.034351\n",
            "Housing__DI_lag1                    0.033363\n",
            "Interest_Rates_Spreads__DI          0.030489\n",
            "Housing__DI                         0.030370\n",
            "Overall_DI_lag2                     0.029065\n",
            "Overall_DI_lag12                    0.028096\n",
            "Housing__DI_lag2                    0.026747\n",
            "Interest_Rates_Spreads__DI_lag12    0.026323\n",
            "Labor_Market__DI_lag12              0.022816\n",
            "Output_Income__DI_lag1              0.021529\n",
            "\n",
            "=== Input: CBDI, Model: XGBoost ===\n",
            "   Top 15 Feature Importances:\n",
            "                                          Importance\n",
            "Labor_Market__DI                            0.097748\n",
            "Labor_Market__DI_lag1                       0.058804\n",
            "Overall_DI                                  0.048820\n",
            "Overall_DI_lag2                             0.043638\n",
            "Overall_DI_lag1                             0.034918\n",
            "Housing__DI_lag1                            0.030243\n",
            "Overall_DI_lag6                             0.028983\n",
            "Interest_Rates_Spreads__DI                  0.028579\n",
            "Housing__DI                                 0.028096\n",
            "Housing__DI_lag2                            0.028037\n",
            "Interest_Rates_Spreads__DI_lag12            0.024507\n",
            "Consumption_Orders_Inventories__DI_lag12    0.023945\n",
            "Interest_Rates_Spreads__DI_lag6             0.023687\n",
            "Interest_Rates_Spreads__DI_lag2             0.023189\n",
            "Housing__DI_lag12                           0.023062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Evaluation"
      ],
      "metadata": {
        "id": "dL-Qi52U7L-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Evaluating Out-of-Sample Performance ---\")\n",
        "oos_target = y_final.loc[oos_target_indices]\n",
        "\n",
        "final_evaluation_dfs = {}\n",
        "all_metrics_list = []\n",
        "\n",
        "for input_name in oos_predictions:\n",
        "  print(f\"Evaluating Input Set: {input_name}\")\n",
        "  evaluation_results_rec = {}\n",
        "\n",
        "  for model_name in oos_predictions[input_name]:\n",
        "    y_pred_oos_list = oos_predictions[input_name][model_name]\n",
        "    y_proba_oos_list = oos_probabilities[input_name][model_name]\n",
        "    y_pred_oos = np.array(y_pred_oos_list)\n",
        "    y_proba_oos = np.array(y_proba_oos_list)\n",
        "    # Find only successful predictions (no errors)\n",
        "    valid_idx = ~np.isnan(y_proba_oos) & ~np.isnan(y_pred_oos)\n",
        "\n",
        "    y_test_eval = oos_target[valid_idx].values\n",
        "    y_pred_eval = y_pred_oos[valid_idx]\n",
        "    y_proba_eval = y_proba_oos[valid_idx]\n",
        "\n",
        "    print(f\"\\n  Model: {model_name} ({sum(valid_idx)} / {len(oos_target)} valid forecasts)\")\n",
        "    if sum(valid_idx) == 0 or len(y_test_eval) == 0:\n",
        "      print(\"    No valid OOS predictions to evaluate.\")\n",
        "      results_rec = {'PR AUC': np.nan, 'Recall (1)': np.nan, 'Precision (1)': np.nan, 'F1 (1)': np.nan, 'ROC AUC': np.nan, 'Brier Score': np.nan, 'Confusion Matrix': 'N/A'}\n",
        "      evaluation_results_rec[model_name] = results_rec\n",
        "      continue\n",
        "\n",
        "    results_rec = {}\n",
        "    try:\n",
        "      cm_rec = confusion_matrix(y_test_eval, y_pred_eval)\n",
        "      results_rec['Confusion Matrix'] = cm_rec\n",
        "      print(f\"    Confusion Matrix (0.5 Thr):\\n{cm_rec}\")\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating CM: {e}\")\n",
        "      results_rec['Confusion Matrix'] = 'Error'\n",
        "\n",
        "    try:\n",
        "      target_names = ['Non-Recession (0)', 'Recession (1)']\n",
        "      report_str = classification_report(y_test_eval, y_pred_eval, target_names=target_names, zero_division=0)\n",
        "      print(f\"    Classification Report (0.5 Thr):\\n{report_str}\")\n",
        "      cr_dict = classification_report(y_test_eval, y_pred_eval, output_dict=True, zero_division=0)\n",
        "      results_rec['Recall (1)'] = cr_dict.get('1.0', {}).get('recall', 0)\n",
        "      results_rec['Precision (1)'] = cr_dict.get('1.0', {}).get('precision', 0)\n",
        "      results_rec['F1 (1)'] = cr_dict.get('1.0', {}).get('f1-score', 0)\n",
        "      print(f\"      -> Recall(1): {results_rec['Recall (1)']:.3f}, Precision(1): {results_rec['Precision (1)']:.3f}, F1(1): {results_rec['F1 (1)']:.3f}\")\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating Classification Report: {e}\")\n",
        "      results_rec['Recall (1)'] = np.nan; results_rec['Precision (1)'] = np.nan; results_rec['F1 (1)'] = np.nan\n",
        "\n",
        "    try:\n",
        "      results_rec['ROC AUC'] = roc_auc_score(y_test_eval, y_proba_eval)\n",
        "      print(f\"      -> ROC AUC: {results_rec['ROC AUC']:.3f}\")\n",
        "    except ValueError:\n",
        "      print(\"    ROC AUC cannot be computed (likely only one class in evaluation period).\")\n",
        "      results_rec['ROC AUC'] = np.nan\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating ROC AUC: {e}\")\n",
        "      results_rec['ROC AUC'] = np.nan\n",
        "\n",
        "    try:\n",
        "      results_rec['PR AUC'] = average_precision_score(y_test_eval, y_proba_eval)\n",
        "      print(f\"      -> PR AUC (Avg Precision): {results_rec['PR AUC']:.3f}\")\n",
        "    except ValueError:\n",
        "      print(\"    PR AUC cannot be computed (likely only one class in evaluation period).\")\n",
        "      results_rec['PR AUC'] = np.nan\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating PR AUC: {e}\")\n",
        "      results_rec['PR AUC'] = np.nan\n",
        "\n",
        "    try:\n",
        "      results_rec['Brier Score'] = brier_score_loss(y_test_eval, y_proba_eval)\n",
        "      print(f\"      -> Brier Score: {results_rec['Brier Score']:.3f}\")\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating Brier Score: {e}\")\n",
        "      results_rec['Brier Score'] = np.nan\n",
        "\n",
        "    evaluation_results_rec[model_name] = results_rec\n",
        "\n",
        "    # Add results to the combined list for the summary table\n",
        "    row = {\n",
        "          'Input': input_name, 'Model': model_name,\n",
        "          'PR AUC': results_rec.get('PR AUC'), 'ROC AUC': results_rec.get('ROC AUC'),\n",
        "          'Recall (1)': results_rec.get('Recall (1)'), 'Precision (1)': results_rec.get('Precision (1)'),\n",
        "          'F1 (1)': results_rec.get('F1 (1)'), 'Brier Score': results_rec.get('Brier Score'),\n",
        "          'Num Forecasts': sum(valid_idx)\n",
        "          }\n",
        "    all_metrics_list.append(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgTy5Wef7InO",
        "outputId": "ba2f8ed6-87cc-4d65-ad93-1b482ec9ce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Out-of-Sample Performance ---\n",
            "Evaluating Input Set: CBDI\n",
            "\n",
            "  Model: RandomForest (306 / 306 valid forecasts)\n",
            "    Confusion Matrix (0.5 Thr):\n",
            "[[267   8]\n",
            " [  3  28]]\n",
            "    Classification Report (0.5 Thr):\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Non-Recession (0)       0.99      0.97      0.98       275\n",
            "    Recession (1)       0.78      0.90      0.84        31\n",
            "\n",
            "         accuracy                           0.96       306\n",
            "        macro avg       0.88      0.94      0.91       306\n",
            "     weighted avg       0.97      0.96      0.97       306\n",
            "\n",
            "      -> Recall(1): 0.903, Precision(1): 0.778, F1(1): 0.836\n",
            "      -> ROC AUC: 0.979\n",
            "      -> PR AUC (Avg Precision): 0.888\n",
            "      -> Brier Score: 0.051\n",
            "\n",
            "  Model: XGBoost (306 / 306 valid forecasts)\n",
            "    Confusion Matrix (0.5 Thr):\n",
            "[[272   3]\n",
            " [  3  28]]\n",
            "    Classification Report (0.5 Thr):\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Non-Recession (0)       0.99      0.99      0.99       275\n",
            "    Recession (1)       0.90      0.90      0.90        31\n",
            "\n",
            "         accuracy                           0.98       306\n",
            "        macro avg       0.95      0.95      0.95       306\n",
            "     weighted avg       0.98      0.98      0.98       306\n",
            "\n",
            "      -> Recall(1): 0.903, Precision(1): 0.903, F1(1): 0.903\n",
            "      -> ROC AUC: 0.956\n",
            "      -> PR AUC (Avg Precision): 0.866\n",
            "      -> Brier Score: 0.022\n",
            "\n",
            "  Model: HGBoost (306 / 306 valid forecasts)\n",
            "    Confusion Matrix (0.5 Thr):\n",
            "[[272   3]\n",
            " [  3  28]]\n",
            "    Classification Report (0.5 Thr):\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Non-Recession (0)       0.99      0.99      0.99       275\n",
            "    Recession (1)       0.90      0.90      0.90        31\n",
            "\n",
            "         accuracy                           0.98       306\n",
            "        macro avg       0.95      0.95      0.95       306\n",
            "     weighted avg       0.98      0.98      0.98       306\n",
            "\n",
            "      -> Recall(1): 0.903, Precision(1): 0.903, F1(1): 0.903\n",
            "      -> ROC AUC: 0.958\n",
            "      -> PR AUC (Avg Precision): 0.883\n",
            "      -> Brier Score: 0.019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(oos_target_indices):\", len(oos_target_indices))\n",
        "print(\"len(oos_target):\", len(oos_target))\n",
        "print(\"len(y_pred_oos):\", len(y_pred_oos))\n",
        "print(\"len(y_proba_oos):\", len(y_proba_oos))\n",
        "print(\"len(valid_idx):\", len(valid_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuFluAhJdshQ",
        "outputId": "0ce7e8a4-2eea-44c0-b4b9-64761ef83523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(oos_target_indices): 306\n",
            "len(oos_target): 306\n",
            "len(y_pred_oos): 306\n",
            "len(y_proba_oos): 306\n",
            "len(valid_idx): 306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display Results"
      ],
      "metadata": {
        "id": "6S3XwMID9zHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Final Recursive Evaluation Summary (Default 0.5 Threshold) ---\")\n",
        "if all_metrics_list:\n",
        "  results_df_rec = pd.DataFrame(all_metrics_list).round(4)\n",
        "  if 'Confusion Matrix' in results_df_rec.columns:\n",
        "    results_df_rec = results_df_rec.drop(columns=['Confusion Matrix'])\n",
        "  results_df_rec = results_df_rec.set_index(['Input', 'Model'])\n",
        "  print(results_df_rec.sort_values(by='PR AUC', ascending=False)) # Sort by PR AUC\n",
        "else:\n",
        "  print(\"No final recursive evaluation results generated to display.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzKBJanr9yf9",
        "outputId": "d10dffe2-249e-4789-b357-1e5b4648bc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Recursive Evaluation Summary (Default 0.5 Threshold) ---\n",
            "                    PR AUC  ROC AUC  Recall (1)  Precision (1)  F1 (1)  \\\n",
            "Input Model                                                              \n",
            "CBDI  RandomForest  0.8885   0.9790      0.9032         0.7778  0.8358   \n",
            "      HGBoost       0.8829   0.9582      0.9032         0.9032  0.9032   \n",
            "      XGBoost       0.8657   0.9564      0.9032         0.9032  0.9032   \n",
            "\n",
            "                    Brier Score  Num Forecasts  \n",
            "Input Model                                     \n",
            "CBDI  RandomForest       0.0515            306  \n",
            "      HGBoost            0.0195            306  \n",
            "      XGBoost            0.0217            306  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_COLORS = {\n",
        "    'Logit': 'red',\n",
        "    'Logit_L2': 'orange',\n",
        "    'RandomForest': 'blue',\n",
        "    'XGBoost': 'green',\n",
        "    'HGBoost': 'brown'\n",
        "\n",
        "}\n",
        "DEFAULT_COLOR = 'grey'\n",
        "\n",
        "\n",
        "print(\"\\n--- Plotting Out-of-Sample Precision-Recall Curves (One Plot Per Input Set) ---\")\n",
        "\n",
        "# Calculate No-Skill line based on full OOS target prevalence\n",
        "if len(oos_target) > 0:\n",
        "    no_skill_level = oos_target.mean()\n",
        "else:\n",
        "    no_skill_level = 0.5\n",
        "\n",
        "for input_name in predictor_sets.keys():\n",
        "    print(f\"\\n--- Generating PR Curve Plot for Input Set: {input_name} ---\")\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.set_title(f\"OOS Precision-Recall Curve - Input: {input_name}\")\n",
        "\n",
        "    if input_name not in oos_probabilities:\n",
        "         print(f\"  Skipping {input_name}: No probabilities found.\")\n",
        "         plt.close(fig)\n",
        "         continue\n",
        "\n",
        "    models_to_plot = oos_probabilities[input_name]\n",
        "    plot_count = 0\n",
        "\n",
        "\n",
        "    ax.plot([0, 1], [no_skill_level, no_skill_level], linestyle='--',\n",
        "            label=f'No Skill ({no_skill_level:.2f})', color='grey', alpha=0.7)\n",
        "\n",
        "\n",
        "    for model_name, y_proba_list in models_to_plot.items():\n",
        "        y_proba_raw = np.array(y_proba_list)\n",
        "\n",
        "\n",
        "        valid_idx_plot = ~np.isnan(y_proba_raw)\n",
        "        if sum(valid_idx_plot) == 0:\n",
        "            print(f\"  Skipping {model_name}: No valid probabilities.\")\n",
        "            continue\n",
        "\n",
        "        y_test_eval_plot = oos_target[valid_idx_plot].values\n",
        "        y_proba_eval_plot = y_proba_raw[valid_idx_plot]\n",
        "\n",
        "\n",
        "        if len(np.unique(y_test_eval_plot)) <= 1:\n",
        "            print(f\"  Skipping {model_name}: Only one class present in valid OOS target slice.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate PR AUC to include in label\n",
        "        try:\n",
        "             pr_auc = average_precision_score(y_test_eval_plot, y_proba_eval_plot)\n",
        "             model_label = f'{model_name}'\n",
        "        except Exception:\n",
        "             pr_auc = np.nan\n",
        "             model_label = f'{model_name} (AUC=N/A)'\n",
        "\n",
        "\n",
        "        # Plot PR curve using from_predictions\n",
        "        try:\n",
        "            color = MODEL_COLORS.get(model_name, DEFAULT_COLOR) # Get consistent color\n",
        "            pr_display = PrecisionRecallDisplay.from_predictions(\n",
        "                y_test_eval_plot,\n",
        "                y_proba_eval_plot,\n",
        "                name=model_label, # Add AUC to the label\n",
        "                ax=ax,            # Plot on the CURRENT axes      # Use defined color\n",
        "                lw=2,             # Line width\n",
        "                alpha=0.8         # Transparency\n",
        "            )\n",
        "            plot_count += 1\n",
        "        except ValueError as ve:\n",
        "             if \"contains only one label\" in str(ve):\n",
        "                 print(f\"  Skipping {model_name}: Only one class value present in predictions for plotting (possibly constant probability).\")\n",
        "             else:\n",
        "                 print(f\"  Error plotting PR curve for {model_name}: {ve}\")\n",
        "        except Exception as e:\n",
        "             print(f\"  Error plotting PR curve for {model_name}: {e}\")\n",
        "\n",
        "\n",
        "    # Finalize plot\n",
        "    if plot_count > 0:\n",
        "        ax.grid(True, linestyle=':', alpha=0.6)\n",
        "        ax.legend(loc='lower right', fontsize='small')\n",
        "    else:\n",
        "         ax.text(0.5, 0.5, 'No valid data to plot', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "\n",
        "    ax.set_xlabel(\"Recall\")\n",
        "    ax.set_ylabel(\"Precision\")\n",
        "    ax.set_xlim([-0.05, 1.05])\n",
        "    ax.set_ylim([-0.05, 1.05])\n",
        "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
        "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "    plt.tight_layout()\n",
        "    fig_save_path = os.path.join(\"/content/drive/MyDrive/Diffusion Indices/Visuals/\", f'PR_Curve_{input_name}_{prediction_horizon}mo.png')\n",
        "    plt.savefig(fig_save_path, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- Finished Plotting PR Curves ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "8dSK3pxF97Wk",
        "outputId": "fea9e55f-4531-4d35-a1bc-069df5460d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Plotting Out-of-Sample Precision-Recall Curves (One Plot Per Input Set) ---\n",
            "\n",
            "--- Generating PR Curve Plot for Input Set: CBDI ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Finished Plotting PR Curves ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating Prediction vs Actual DataFrame ---\")\n",
        "graph_folder = \"/content/drive/MyDrive/Diffusion Indices/Visuals/\"\n",
        "\n",
        "def visualize(chosen_input, chosen_model, aligned=False, save=True):\n",
        "  comparison_df = pd.DataFrame({'Actual': oos_target})\n",
        "\n",
        "  if chosen_input in oos_predictions and chosen_model in oos_predictions[chosen_input]:\n",
        "    pred_list = oos_predictions[chosen_input][chosen_model]\n",
        "    proba_list = oos_probabilities[chosen_input][chosen_model]\n",
        "\n",
        "\n",
        "    if len(pred_list) == len(oos_target_indices) and len(proba_list) == len(oos_target_indices):\n",
        "      comparison_df[f'{chosen_model}_Pred'] = pd.Series(pred_list, index=oos_target_indices)\n",
        "      comparison_df[f'{chosen_model}_Proba'] = pd.Series(proba_list, index=oos_target_indices)\n",
        "      print(f\" Added predictions/probabilities for {chosen_model} on {chosen_input}.\")\n",
        "    else:\n",
        "      print(f\"WARNING: Length mismatch for {model_name} on {input_name}. Cannot add to comparison.\")\n",
        "      print(f\"  Expected length: {len(oos_target_indices)}, Pred length: {len(pred_list)}, Proba length: {len(proba_list)}\")\n",
        "\n",
        "\n",
        "  else:\n",
        "    print(f\"WARNING: Could not find results for Input='{chosen_input}', Model='{chosen_model}'\")\n",
        "\n",
        "\n",
        "  print(\"\\nComparison DataFrame (Actual vs Predicted [0.5 Thr] vs Probability):\")\n",
        "  print(comparison_df.head(20))\n",
        "  print(\"...\")\n",
        "  print(comparison_df.tail(20))\n",
        "\n",
        "  print(\"\\n--- Analyzing Misclassifications ---\")\n",
        "  if f'{chosen_model}_Pred' in comparison_df.columns:\n",
        "    misclassified = comparison_df[comparison_df['Actual'] != comparison_df[f'{chosen_model}_Pred']]\n",
        "    false_positives = misclassified[misclassified['Actual'] == 0]\n",
        "    false_negatives = misclassified[misclassified['Actual'] == 1]\n",
        "\n",
        "    print(f\"\\nTotal Misclassified ({chosen_model} on {chosen_input}): {len(misclassified)}\")\n",
        "\n",
        "    print(f\"\\nFalse Positives (Predicted 1, Actual 0): {len(false_positives)}\")\n",
        "    if not false_positives.empty:\n",
        "      print(false_positives.sort_index())\n",
        "\n",
        "    print(f\"\\nFalse Negatives (Predicted 0, Actual 1): {len(false_negatives)}\")\n",
        "    if not false_negatives.empty:\n",
        "      print(false_negatives.sort_index())\n",
        "\n",
        "\n",
        "  print(\"\\\\n--- Plotting Predictions Over Time ---\")\n",
        "  if f'{chosen_model}_Proba' in comparison_df.columns:\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "    plot_start_date = min(oos_target_indices)\n",
        "    plot_end_date = max(oos_target_indices)\n",
        "\n",
        "\n",
        "    y_raw_plot_period = y_raw.loc[plot_start_date : plot_end_date + pd.DateOffset(months=1)] # Ensure we cover the end date\n",
        "\n",
        "    nber_recession_dates = y_raw_plot_period[y_raw_plot_period == 1].index\n",
        "    start_shade = None\n",
        "    first_label = True\n",
        "    for date in y_raw_plot_period.index:\n",
        "      is_rec = date in nber_recession_dates\n",
        "      if is_rec and start_shade is None:\n",
        "        start_shade = date\n",
        "      elif not is_rec and start_shade is not None:\n",
        "        end_shade = date\n",
        "        ax.axvspan(start_shade, end_shade,\n",
        "                    color='red', alpha=0.2, label='Actual Recession (NBER)' if first_label else \"\")\n",
        "        start_shade = None\n",
        "        first_label=False\n",
        "    if start_shade is not None:\n",
        "      ax.axvspan(start_shade, plot_end_date + pd.DateOffset(months=1), color='red', alpha=0.2, label='Actual Recession (NBER)' if first_label else \"\")\n",
        "\n",
        "\n",
        "    if aligned:\n",
        "      ax.plot(comparison_df.index + pd.DateOffset(months=prediction_horizon), comparison_df[f'{chosen_model}_Proba'], label=f'{chosen_model} Prob (Predicting t + {prediction_horizon}mo)', color='blue', alpha=0.8)\n",
        "    else:\n",
        "      ax.plot(comparison_df.index, comparison_df[f'{chosen_model}_Proba'], label=f'{chosen_model} Prob (Predicting t + 3mo)', color='blue', alpha=0.8)\n",
        "\n",
        "\n",
        "    ax.axhline(0.5, color='grey', linestyle='--', label='0.5 Threshold', alpha=0.7)\n",
        "\n",
        "\n",
        "    tuned_threshold = results_df_tuned.loc[chosen_input].loc[chosen_model]['Threshold'] # Default if not found\n",
        "\n",
        "\n",
        "\n",
        "    nber_starts = y_raw_plot_period[(y_raw_plot_period == 1) & (y_raw_plot_period.shift(1) == 0)].index\n",
        "\n",
        "\n",
        "    if not aligned:\n",
        "      nber_start_2001 = nber_starts[nber_starts.year == 2001][0]\n",
        "      pred_peak_date_2001 = comparison_df.loc[:nber_start_2001, f'{chosen_model}_Proba'].idxmax() # Find peak BEFORE start\n",
        "      pred_peak_val_2001 = comparison_df.loc[pred_peak_date_2001, f'{chosen_model}_Proba']\n",
        "      if pd.notna(nber_start_2001) and pd.notna(pred_peak_date_2001):\n",
        "        ax.annotate('Forecast Peak\\n(Predicting 3mo Ahead)', xy=(pred_peak_date_2001, pred_peak_val_2001),\n",
        "                    xytext=(pred_peak_date_2001 - pd.DateOffset(years=1), pred_peak_val_2001 + 0.1),\n",
        "                    arrowprops=dict(facecolor='green', shrink=0.05, alpha=0.7),\n",
        "                    fontsize=9, color='green')\n",
        "        ax.annotate('Actual Start', xy=(nber_start_2001, 0.05), # Point near bottom\n",
        "                    xytext=(nber_start_2001 + pd.DateOffset(months=6), 0.15),\n",
        "                    arrowprops=dict(facecolor='red', shrink=0.05, alpha=0.7),\n",
        "                    fontsize=9, color='red')\n",
        "\n",
        "\n",
        "    ax.set_ylabel(f'Recession Probability (Predicted for t + {prediction_horizon} Months)')\n",
        "    ax.set_xlabel('Date (Prediction Made at Time t)') # Clarify axis meaning\n",
        "    ax.set_title(f'NBER Recessions vs. Predicted Probability ({chosen_model} on {chosen_input})')\n",
        "\n",
        "    # Adjust legend position if needed\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    # Filter out duplicate labels if NBER span triggered multiple times\n",
        "    unique_labels = {}\n",
        "    for handle, label in zip(handles, labels):\n",
        "      if label not in unique_labels:\n",
        "        unique_labels[label] = handle\n",
        "    ax.legend(unique_labels.values(), unique_labels.keys(), loc='upper right', frameon=True)\n",
        "\n",
        "\n",
        "    ax.grid(True, axis='y', linestyle=':')\n",
        "    ax.set_xlim(plot_start_date, plot_end_date) # Ensure plot range matches evaluation\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "      if aligned:\n",
        "        plt.savefig(f'{graph_folder}{chosen_model}_{chosen_input}_{prediction_horizon}mo_aligned.png')\n",
        "      else:\n",
        "        plt.savefig(f'{graph_folder}{chosen_model}_{chosen_input}_{prediction_horizon}mo.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  else:\n",
        "      print(\"Could not plot - probabilities not found.\")\n",
        "\n",
        "# for input in ['Factors', 'CBDI', 'Full', 'FBDI', 'FBDI_Recursive', 'Yield']:\n",
        "#   for model in ['Logit', 'Logit_L2', 'RandomForest', 'XGBoost', 'HGBoost']:\n",
        "visualize('CBDI', 'HGBoost', aligned=True, save=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bqrbyz8eogcm",
        "outputId": "6e641877-ffed-4e52-90cc-454fe9387194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating Prediction vs Actual DataFrame ---\n",
            " Added predictions/probabilities for HGBoost on CBDI.\n",
            "\n",
            "Comparison DataFrame (Actual vs Predicted [0.5 Thr] vs Probability):\n",
            "            Actual  HGBoost_Pred  HGBoost_Proba\n",
            "1999-04-01     0.0           0.0       0.001869\n",
            "1999-05-01     0.0           0.0       0.001600\n",
            "1999-06-01     0.0           0.0       0.001319\n",
            "1999-07-01     0.0           0.0       0.006705\n",
            "1999-08-01     0.0           0.0       0.000685\n",
            "1999-09-01     0.0           0.0       0.002881\n",
            "1999-10-01     0.0           0.0       0.003658\n",
            "1999-11-01     0.0           0.0       0.003215\n",
            "1999-12-01     0.0           0.0       0.005001\n",
            "2000-01-01     0.0           0.0       0.000094\n",
            "2000-02-01     0.0           0.0       0.001266\n",
            "2000-03-01     0.0           0.0       0.007725\n",
            "2000-04-01     0.0           0.0       0.007030\n",
            "2000-05-01     0.0           0.0       0.000648\n",
            "2000-06-01     0.0           0.0       0.000851\n",
            "2000-07-01     0.0           0.0       0.002359\n",
            "2000-08-01     0.0           0.0       0.007154\n",
            "2000-09-01     1.0           0.0       0.012087\n",
            "2000-10-01     1.0           1.0       0.997274\n",
            "2000-11-01     1.0           1.0       0.997146\n",
            "...\n",
            "            Actual  HGBoost_Pred  HGBoost_Proba\n",
            "2023-02-01     0.0           0.0       0.003150\n",
            "2023-03-01     0.0           0.0       0.001916\n",
            "2023-04-01     0.0           0.0       0.011863\n",
            "2023-05-01     0.0           0.0       0.016273\n",
            "2023-06-01     0.0           0.0       0.018745\n",
            "2023-07-01     0.0           0.0       0.001917\n",
            "2023-08-01     0.0           0.0       0.002200\n",
            "2023-09-01     0.0           0.0       0.017163\n",
            "2023-10-01     0.0           0.0       0.013362\n",
            "2023-11-01     0.0           0.0       0.015467\n",
            "2023-12-01     0.0           0.0       0.007729\n",
            "2024-01-01     0.0           0.0       0.009469\n",
            "2024-02-01     0.0           0.0       0.005635\n",
            "2024-03-01     0.0           0.0       0.005486\n",
            "2024-04-01     0.0           0.0       0.009269\n",
            "2024-05-01     0.0           0.0       0.018676\n",
            "2024-06-01     0.0           0.0       0.012489\n",
            "2024-07-01     0.0           0.0       0.001393\n",
            "2024-08-01     0.0           0.0       0.014499\n",
            "2024-09-01     0.0           0.0       0.026154\n",
            "\n",
            "--- Analyzing Misclassifications ---\n",
            "\n",
            "Total Misclassified (HGBoost on CBDI): 6\n",
            "\n",
            "False Positives (Predicted 1, Actual 0): 3\n",
            "            Actual  HGBoost_Pred  HGBoost_Proba\n",
            "2001-06-01     0.0           1.0       0.995438\n",
            "2009-01-01     0.0           1.0       0.994790\n",
            "2019-11-01     0.0           1.0       0.997045\n",
            "\n",
            "False Negatives (Predicted 0, Actual 1): 3\n",
            "            Actual  HGBoost_Pred  HGBoost_Proba\n",
            "2000-09-01     1.0           0.0       0.012087\n",
            "2007-06-01     1.0           0.0       0.001148\n",
            "2019-08-01     1.0           0.0       0.003883\n",
            "\\n--- Plotting Predictions Over Time ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_tuned"
      ],
      "metadata": {
        "id": "ca7CBegTFm7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "dca5d87c-223d-4a71-ca89-9b36c4c757dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Threshold  PR AUC  ROC AUC  Recall (1)  Precision (1)  \\\n",
              "Input Model                                                                 \n",
              "CBDI  RandomForest     0.6111  0.8885   0.9790      0.9032         0.9032   \n",
              "      XGBoost          0.9255  0.8657   0.9564      0.9032         0.9032   \n",
              "      HGBoost          0.9932  0.8829   0.9582      0.9032         0.9032   \n",
              "\n",
              "                    F1 (1)  Num Forecasts  \n",
              "Input Model                                \n",
              "CBDI  RandomForest  0.9032            306  \n",
              "      XGBoost       0.9032            306  \n",
              "      HGBoost       0.9032            306  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dee52490-9090-47f7-8887-28ad2d7360f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Threshold</th>\n",
              "      <th>PR AUC</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>Recall (1)</th>\n",
              "      <th>Precision (1)</th>\n",
              "      <th>F1 (1)</th>\n",
              "      <th>Num Forecasts</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Input</th>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">CBDI</th>\n",
              "      <th>RandomForest</th>\n",
              "      <td>0.6111</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>0.9790</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.9255</td>\n",
              "      <td>0.8657</td>\n",
              "      <td>0.9564</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HGBoost</th>\n",
              "      <td>0.9932</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>0.9582</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dee52490-9090-47f7-8887-28ad2d7360f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dee52490-9090-47f7-8887-28ad2d7360f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dee52490-9090-47f7-8887-28ad2d7360f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ff041bee-c699-4df7-a625-289036df75a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff041bee-c699-4df7-a625-289036df75a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ff041bee-c699-4df7-a625-289036df75a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4d94fb48-8cf9-4a5b-b6d6-1237f283f201\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_tuned')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4d94fb48-8cf9-4a5b-b6d6-1237f283f201 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_tuned');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_tuned",
              "summary": "{\n  \"name\": \"results_df_tuned\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2038917441519723,\n        \"min\": 0.6111,\n        \"max\": 0.9932,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6111,\n          0.9255,\n          0.9932\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PR AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011881638495314217,\n        \"min\": 0.8657,\n        \"max\": 0.8885,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8885,\n          0.8657,\n          0.8829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012560785538067772,\n        \"min\": 0.9564,\n        \"max\": 0.979,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.979,\n          0.9564,\n          0.9582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.9032,\n        \"max\": 0.9032,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision (1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.9032,\n        \"max\": 0.9032,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 (1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.9032,\n        \"max\": 0.9032,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Num Forecasts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 306,\n        \"max\": 306,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          306\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics_df = pd.DataFrame(all_metrics_list)"
      ],
      "metadata": {
        "id": "eouZDX7_08z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Preparing data for bar chart ---\")\n",
        "plot_data = []\n",
        "\n",
        "input_order_plot1 = ['CBDI']\n",
        "model_order = ['RandomForest', 'XGBoost', 'HGBoost']\n",
        "all_inputs_ordered = input_order_plot1\n",
        "\n",
        "\n",
        "models_present = set()\n",
        "for input_name in all_inputs_ordered:\n",
        "    if input_name in results_df_rec.index.get_level_values(0):\n",
        "        models_present.update(results_df_rec.loc[input_name].index)\n",
        "\n",
        "print(f\"Input Sets to Plot: {all_inputs_ordered}\")\n",
        "print(f\"Models to Plot: {model_order}\")\n",
        "\n",
        "# Extract data\n",
        "for input_name in all_inputs_ordered:\n",
        "     if input_name in results_df_rec.index.get_level_values(0):\n",
        "         for model_name in model_order:\n",
        "\n",
        "             pr_auc = results_df_rec.loc[input_name].loc[model_name]['PR AUC']\n",
        "             plot_group = 1 if input_name in input_order_plot1 else 2\n",
        "             plot_data.append({'Input Set': input_name,\n",
        "                               'Model': model_name,\n",
        "                               'PR AUC': pr_auc,\n",
        "                               'Plot Group': plot_group})\n",
        "\n",
        "# Convert to DataFrame\n",
        "plot_df_full = pd.DataFrame(plot_data)\n",
        "plot_df_full.dropna(subset=['PR AUC'], inplace=True) # Drop if metric is missing\n",
        "\n",
        "# Ensure categorical order for plots\n",
        "plot_df_full['Input Set'] = pd.Categorical(plot_df_full['Input Set'], categories=all_inputs_ordered, ordered=True)\n",
        "plot_df_full['Model'] = pd.Categorical(plot_df_full['Model'], categories=model_order, ordered=True)\n",
        "\n",
        "print(\"\\nPrepared DataFrame for plotting (first few rows):\")\n",
        "print(plot_df_full.head())\n",
        "\n",
        "\n",
        "print(\"\\n--- Generating Bar Charts (Split) ---\")\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "num_models_plot = len(plot_df_full['Model'].unique())\n",
        "try:\n",
        "    if num_models_plot <= 10: palette_name = 'viridis' # Viridis often good contrast\n",
        "    elif num_models_plot <= 20: palette_name = 'tab20'\n",
        "    else: palette_name = 'viridis'\n",
        "    palette = sns.color_palette(palette_name, n_colors=num_models_plot)\n",
        "except Exception as e:\n",
        "    palette = sns.color_palette(n_colors=num_models_plot)\n",
        "\n",
        "\n",
        "for plot_num in [1, 2]:\n",
        "    print(f\"\\n Generating Plot {plot_num}...\")\n",
        "    plot_df_subset = plot_df_full[plot_df_full['Plot Group'] == plot_num].copy()\n",
        "\n",
        "    if plot_df_subset.empty:\n",
        "         print(f\" No data for Plot {plot_num}. Skipping.\")\n",
        "         continue\n",
        "\n",
        "    input_sets_in_plot = plot_df_subset['Input Set'].unique().tolist()\n",
        "\n",
        "\n",
        "    fig_width = max(8, 2.5 * len(input_sets_in_plot))\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, 7))\n",
        "\n",
        "\n",
        "    barplot = sns.barplot(x='Input Set', y='PR AUC', hue='Model',\n",
        "                          data=plot_df_subset, palette=palette, ax=ax, errorbar=None)\n",
        "\n",
        "\n",
        "    for container in ax.containers:\n",
        "        try:\n",
        "             ax.bar_label(container, fmt='%.3f', fontsize=8, padding=3, rotation=0)\n",
        "        except Exception as e:\n",
        "             print(f\" Warning: Could not add bar labels - {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    ax.set_title(f'Out-of-Sample Precision-Recall AUC (h={prediction_horizon} Months)', fontsize=14, pad=15)\n",
        "    ax.set_xlabel('Input Data Representation', fontsize=12, labelpad=10)\n",
        "    ax.set_ylabel('Average Precision (PR AUC)', fontsize=12, labelpad=10)\n",
        "    ax.tick_params(axis='x', rotation=0, labelsize=11)\n",
        "    ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1.01, 0.5), fontsize='medium', title='Model')\n",
        "\n",
        "\n",
        "    min_auc = max(0, plot_df_subset['PR AUC'].min() - 0.05)\n",
        "    max_auc = min(1, plot_df_subset['PR AUC'].max() + 0.05)\n",
        "    if max_auc - min_auc < 0.1:\n",
        "         min_auc = max(0, min_auc - 0.05)\n",
        "         max_auc = min(1, max_auc + 0.05)\n",
        "    ax.set_ylim(min_auc, max_auc)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 0.88, 0.95])\n",
        "\n",
        "\n",
        "    graph_folder = '/content/drive/MyDrive/Diffusion Indices/Visuals/'\n",
        "    os.makedirs(graph_folder, exist_ok=True)\n",
        "    save_path = os.path.join(graph_folder, f'PR_AUC_Comparison_BarChart_Plot{plot_num}_CBDI_h{prediction_horizon}.png')\n",
        "    try:\n",
        "        plt.savefig(save_path, dpi=500)\n",
        "        print(f\" Saved Bar Chart Plot {plot_num} to: {save_path}\")\n",
        "    except Exception as e:\n",
        "         print(f\" ERROR saving Bar Chart Plot {plot_num}: {e}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NDiUaPl1KDdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "outputId": "f75e53cd-b4ab-43f6-943f-02045de2c071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preparing data for bar chart ---\n",
            "Input Sets to Plot: ['CBDI']\n",
            "Models to Plot: ['RandomForest', 'XGBoost', 'HGBoost']\n",
            "\n",
            "Prepared DataFrame for plotting (first few rows):\n",
            "  Input Set         Model  PR AUC  Plot Group\n",
            "0      CBDI  RandomForest  0.8885           1\n",
            "1      CBDI       XGBoost  0.8657           1\n",
            "2      CBDI       HGBoost  0.8829           1\n",
            "\n",
            "--- Generating Bar Charts (Split) ---\n",
            "\n",
            " Generating Plot 1...\n",
            " Saved Bar Chart Plot 1 to: /content/drive/MyDrive/Diffusion Indices/Visuals/PR_AUC_Comparison_BarChart_Plot1_CBDI_h6.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Generating Plot 2...\n",
            " No data for Plot 2. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_for_avg = ['Logit', 'Logit_L2']\n",
        "metrics_to_avg = ['PR AUC']\n",
        "\n",
        "\n",
        "filtered_results = results_df_rec[results_df_rec.index.get_level_values('Model').isin(models_for_avg)]\n",
        "\n",
        "\n",
        "avg_performance = filtered_results.groupby(level='Input')[metrics_to_avg].mean().round(3)\n",
        "avg_performance = avg_performance.sort_values(by='PR AUC', ascending=False)\n",
        "\n",
        "print(\"\\\\n--- Average Performance Across Top Models ---\")\n",
        "avg_performance"
      ],
      "metadata": {
        "id": "4sHjRaBx8HJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRIC_TO_PLOT_HM = 'PR AUC'\n",
        "PLOT_TITLE_HM = f'Model Performance Heatmap ({METRIC_TO_PLOT_HM})'\n",
        "\n",
        "if METRIC_TO_PLOT_HM not in results_df_tuned.columns:\n",
        "  print(f\"ERROR: Metric '{METRIC_TO_PLOT_HM}' not found in results DataFrame columns.\")\n",
        "  exit()\n",
        "\n",
        "\n",
        "try:\n",
        "  heatmap_data = results_df_tuned[METRIC_TO_PLOT_HM].unstack(level='Model')\n",
        "  model_order = ['Logit', 'Logit_L2', 'RandomForest', 'XGBoost', 'HGBoost']\n",
        "  input_order = ['Yield', 'Factors', 'Full', 'CBDI', 'FBDI', 'FBDI_Recursive']\n",
        "  models_present = [m for m in model_order if m in heatmap_data.columns]\n",
        "  inputs_present = [i for i in input_order if i in heatmap_data.index]\n",
        "  heatmap_data = heatmap_data.loc[inputs_present, models_present]\n",
        "  print(\"\\nPivoted DataFrame for Heatmap:\")\n",
        "  print(heatmap_data)\n",
        "except KeyError as e:\n",
        "  print(f\"ERROR unstacking DataFrame, potentially missing combinations or incorrect index levels: {e}\")\n",
        "  exit()\n",
        "except Exception as e:\n",
        "  print(f\"Error preparing heatmap data: {e}\")\n",
        "  exit()\n",
        "\n",
        "if heatmap_data.empty:\n",
        "  print(\"ERROR: No data available for heatmap after pivoting/filtering.\")\n",
        "  exit()\n",
        "\n",
        "print(\"\\n--- Generating Heatmap ---\")\n",
        "\n",
        "\n",
        "num_rows = len(heatmap_data.index)\n",
        "num_cols = len(heatmap_data.columns)\n",
        "fig_width = max(8, 1.5 * num_cols)\n",
        "fig_height = max(6, 0.8 * num_rows)\n",
        "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "cmap_heatmap = \"viridis\"\n",
        "\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    annot=True,\n",
        "    fmt=\".3f\",\n",
        "    linewidths=.5,\n",
        "    cmap=cmap_heatmap,\n",
        "    ax=ax,\n",
        "    cbar_kws={'label': METRIC_TO_PLOT_HM},\n",
        "    annot_kws={\"size\": 9}\n",
        ")\n",
        "\n",
        "\n",
        "ax.set_title(PLOT_TITLE_HM, fontsize=14, pad=15)\n",
        "ax.set_xlabel('Model', fontsize=12)\n",
        "ax.set_ylabel('Input Data Representation', fontsize=12)\n",
        "ax.tick_params(axis='x', labelsize=10, rotation=45, ha='right')\n",
        "ax.tick_params(axis='y', labelsize=10, rotation=0)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "\n",
        "\n",
        "graph_folder = '/content/drive/MyDrive/Diffusion Indices/Visuals/'\n",
        "os.makedirs(graph_folder, exist_ok=True)\n",
        "save_path = os.path.join(graph_folder, f'{METRIC_TO_PLOT_HM.replace(\" \",\"\")}_Comparison_Heatmap_h{prediction_horizon}.png')\n",
        "try:\n",
        "  # plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "  print(f\"\\nSaved Heatmap to: {save_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR saving Heatmap: {e}\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x5DHBbvTq5Uz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}