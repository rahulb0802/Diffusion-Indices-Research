{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOptxgB+cwla4Yy+M4HhQa4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "-nV3lTg_3uKq",
        "outputId": "e154d1ad-1e9b-457b-84ce-84a3b5b09cef",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4a9477bb5af6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "drive.mount('/content/drive')\n",
        "API_KEY = userdata.get('API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fredapi\n",
        "!pip install joblib"
      ],
      "metadata": {
        "id": "P4ZIRwnu4kd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "AijC_5G6d77V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fredapi as fa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "import pickle\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "brier_score_loss, roc_auc_score, precision_recall_fscore_support, recall_score, make_scorer, precision_score, precision_recall_curve, PrecisionRecallDisplay, f1_score, average_precision_score)\n",
        "import sklearn.model_selection as skm\n",
        "from sklearn.decomposition import PCA, FactorAnalysis, SparsePCA\n",
        "from statsmodels.multivariate.pca import PCA as smPCA\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.tree import (DecisionTreeClassifier as DTC, plot_tree, export_text)\n",
        "from sklearn.metrics import (accuracy_score)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA)\n",
        "from imblearn.pipeline import Pipeline\n",
        "import xgboost as xgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import shap\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy.stats import randint, uniform\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "wrZZj7gA4Kun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup\n",
        "### Loading"
      ],
      "metadata": {
        "id": "aN8XIq5P5wiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars_raw = pd.read_csv('/content/drive/MyDrive/Diffusion Indices/2025-04-MD.csv')\n",
        "all_vars_raw"
      ],
      "metadata": {
        "id": "tmBpIq_q4iCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting transformation codes\n",
        "tcodes = all_vars_raw.iloc[0].copy()\n",
        "tcodes = tcodes.drop('sasdate')"
      ],
      "metadata": {
        "id": "zmgt1XNC8CBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars_data = all_vars_raw.drop(0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "HU3kG0B48dbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set index and convert to datetime\n",
        "all_vars_data = all_vars_data.set_index('sasdate')\n",
        "all_vars_data.index = pd.to_datetime(all_vars_data.index)\n",
        "all_vars_data.index.name = 'Date'"
      ],
      "metadata": {
        "id": "uBcK3EtY8m4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cols = all_vars_data.columns\n",
        "for col in data_cols:\n",
        "  all_vars_data[col] = pd.to_numeric(all_vars_data[col], errors='coerce')"
      ],
      "metadata": {
        "id": "Umo1Z7Be8_S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vars_data = all_vars_data['1959-01-01':'2025-03-01']"
      ],
      "metadata": {
        "id": "WsxawFiH9b7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed = pd.DataFrame(index=all_vars_data.index)\n",
        "nan_counts_per_transform = {1: 0, 2: 1, 3: 2, 4: 0, 5: 1, 6: 2, 7: 12}\n",
        "max_transform_nan = 0"
      ],
      "metadata": {
        "id": "gvPmHsCRfRW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing problematic variables\n",
        "vars_to_remove = ['ACOGNO', 'TWEXAFEGSMTHx', 'OILPRICEx', 'UMCSENTx', 'ANDENOx']\n",
        "\n",
        "# Remove them from the main data DataFrame AND the tcodes Series\n",
        "original_cols = list(all_vars_data.columns)\n",
        "removed_count = 0\n",
        "for var in vars_to_remove:\n",
        "    if var in all_vars_data.columns:\n",
        "        all_vars_data = all_vars_data.drop(columns=[var])\n",
        "        if var in tcodes.index:\n",
        "            tcodes = tcodes.drop(var)\n",
        "        print(f\"Removed problematic variable: {var}\")\n",
        "        removed_count += 1\n",
        "    else:\n",
        "        print(f\"Warning: Variable {var} listed for removal not found in DataFrame.\")\n",
        "\n",
        "print(f\"Removed {removed_count} variables based on McCracken & Ng (2016) recommendations.\")\n",
        "print(f\"Shape after removal: {all_vars_data.shape}\")\n",
        "\n",
        "# Update data_cols list if you use it later\n",
        "data_cols = all_vars_data.columns"
      ],
      "metadata": {
        "id": "LPcCAZUW_Nfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming"
      ],
      "metadata": {
        "id": "RZH19U7ek-eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data_cols:\n",
        "  series = all_vars_data[col]\n",
        "  code = int(tcodes[col])\n",
        "  current_max_nan = nan_counts_per_transform[code]\n",
        "  max_transform_nan = max(max_transform_nan, current_max_nan)\n",
        "\n",
        "  if code == 1:\n",
        "    transformed_series = series\n",
        "  elif code == 2:\n",
        "    transformed_series = series.diff(1)\n",
        "  elif code == 3:\n",
        "    transformed_series = series.diff(1).diff(1)\n",
        "  elif code == 4:\n",
        "    transformed_series = np.log(series.clip(lower=1e-10))\n",
        "    if (series <= 0).any():\n",
        "      print(f\"Column {col} has negatives, logs will cause NaNs\")\n",
        "  elif code == 5:\n",
        "    series_clipped = series.clip(lower=1e-10)\n",
        "    transformed_series = np.log(series_clipped).diff(1)\n",
        "    if (series <= 0).any():\n",
        "      print(f\"Column {col} (Code 5) has non-positive values. Log difference applied, NaNs expected\")\n",
        "  elif code == 6:\n",
        "    series_clipped = series.clip(lower=1e-10)\n",
        "    transformed_series = np.log(series_clipped).diff(1).diff(1)\n",
        "    if (series <= 0).any():\n",
        "      print(f\"Column {col} (Code 5) has non-positive values. Log difference applied, NaNs expected\")\n",
        "  elif code == 7:\n",
        "    denominator = series.shift(12)\n",
        "    denominator = denominator.replace(0, np.nan)\n",
        "    denominator[denominator.abs() < 1e-10] = np.nan\n",
        "    transformed_series = ((series / denominator) - 1)\n",
        "  else:\n",
        "    print(f\"Unexpected code {code} for {col}, keeping original\")\n",
        "    transformed_series = series\n",
        "\n",
        "  X_transformed[col] = transformed_series\n",
        "\n",
        "print(f\"Transformations applied, max NaNs introduced by a single transform: {max_transform_nan}\")\n",
        "print(\"\\nTransformed Data Head (showing initial NaNs):\")\n",
        "print(X_transformed.head(max(15, max_transform_nan + 2))) # Show enough rows to see initial NaNs\n",
        "print(\"\\nNaN count per column after transformations (Top 20):\")\n",
        "print(X_transformed.isna().sum().sort_values(ascending=False).head(20))\n",
        "print(f\"\\nTransformed data shape: {X_transformed.shape}\")"
      ],
      "metadata": {
        "id": "HF_ORP6XgRmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Target"
      ],
      "metadata": {
        "id": "2qxWor2elO28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fred = fa.Fred(api_key=API_KEY)\n",
        "y_raw = fred.get_series('USRECM', observation_start='1959-01-01', observation_end='2025-03-01')\n",
        "print(len(y_raw))"
      ],
      "metadata": {
        "id": "Q326J2NJjd3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift target\n",
        "prediction_horizon = 6\n",
        "y_shifted = y_raw.shift(-prediction_horizon).rename('Target')\n",
        "print(y_shifted.tail(prediction_horizon+5))"
      ],
      "metadata": {
        "id": "gOJbfIDyl6_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determining Analysis Window"
      ],
      "metadata": {
        "id": "FwZEduAymgiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_lag_later = 12\n",
        "total_initial_drop = max_transform_nan + max_lag_later\n",
        "first_usable_idx_pos = total_initial_drop\n",
        "first_usable_date = X_transformed.index[first_usable_idx_pos]\n",
        "last_usable_date = y_shifted.last_valid_index()\n",
        "print(f\"\\n--> Analysis Window START: {first_usable_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"--> Analysis Window END:   {last_usable_date.strftime('%Y-%m-%d')}\")"
      ],
      "metadata": {
        "id": "z8MIa3wPmbeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After last_usable_date = y_shifted.last_valid_index() in Cell 75\n",
        "print(f\"DEBUG: last_valid_index() from y_shifted used for last_usable_date: {last_usable_date}\")\n",
        "print(f\"DEBUG: Expected end based on data end and horizon: {pd.to_datetime('2024-12-01') - pd.DateOffset(months=prediction_horizon)}\")"
      ],
      "metadata": {
        "id": "t69jvMINKy5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this AFTER Cell 74 (where y_shifted is created)\n",
        "print(f\"Last valid index calculated from y_shifted: {y_shifted.last_valid_index()}\")\n",
        "print(f\"Last date expected from y_raw: {last_usable_date}\") # last_valid_date used for y_raw fetch\n",
        "# Expected last_usable_date is 6 months before last_valid_date\n",
        "expected_last_usable = pd.to_datetime(last_usable_date) - pd.DateOffset(months=prediction_horizon)\n",
        "print(f\"Expected last usable date based on horizon: {expected_last_usable}\")"
      ],
      "metadata": {
        "id": "6ijM2sdpIwZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed_core = X_transformed.loc[first_usable_date:last_usable_date].copy()\n",
        "print(f\"Shape of full set base: {X_transformed_core.shape}\")"
      ],
      "metadata": {
        "id": "iPAhGrA-o9Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare final target variable for the window\n",
        "y_final = y_shifted.loc[first_usable_date:last_usable_date].copy()\n",
        "print(f\"Shape of final target: {y_final.shape}\")\n",
        "y_final"
      ],
      "metadata": {
        "id": "vHTnwKIoqKdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Validation"
      ],
      "metadata": {
        "id": "RwnjVGBQqXSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(y_final) == len(X_transformed_core), \"ERROR: Length mismatch between target and features.\""
      ],
      "metadata": {
        "id": "XZGzmRtHqT9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"NaNs in X_transformed_core: {X_transformed_core.isna().sum().sum()}\")"
      ],
      "metadata": {
        "id": "KF5_OA04qj4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed_core.isna().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "gaFf4heSqt13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to check if transformation caused NAs even in the core window"
      ],
      "metadata": {
        "id": "aY1dZtd2CIrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# col_to_check = 'COMPAPFFx'\n",
        "# print(f\"Transformation code for {col_to_check}: {tcodes.get(col_to_check)}\")\n",
        "\n",
        "# # Compare original vs transformed WITHIN the core window\n",
        "# print(\"\\nOriginal Data in Core Window (Head & Tail):\")\n",
        "# print(all_vars_data.loc[first_usable_date:last_usable_date, col_to_check].head(10))\n",
        "# print(all_vars_data.loc[first_usable_date:last_usable_date, col_to_check].tail(10))\n",
        "# print(f\"Original NaN count in core window: {all_vars_data.loc[first_usable_date:last_usable_date, col_to_check].isna().sum()}\")\n",
        "\n",
        "\n",
        "# print(f\"\\nTransformed {col_to_check} in Core Window (Head & Tail):\")\n",
        "# print(X_transformed_core[col_to_check].head(15)) # Show more to see effect\n",
        "# print(X_transformed_core[col_to_check].tail(15))\n",
        "# print(f\"Transformed NaN count in core window: {X_transformed_core[col_to_check].isna().sum()}\")\n",
        "\n",
        "# # If differencing, check for consecutive identical values in original\n",
        "# if tcodes.get(col_to_check) in [2, 3, 5, 6]:\n",
        "#      print(\"\\nChecking for consecutive duplicates in original data within core window + lookback:\")\n",
        "#      lookback = 2 if tcodes.get(col_to_check) in [3,6] else 1\n",
        "#      orig_slice_with_lookback = all_vars_data.loc[:last_usable_date, col_to_check] # Look from start up to end of core\n",
        "#      consecutive_duplicates = orig_slice_with_lookback[orig_slice_with_lookback == orig_slice_with_lookback.shift(1)]\n",
        "#      print(consecutive_duplicates.tail(20)) # See if recent duplicates exist that affect the core window diff\n",
        "\n",
        "# # If log, check for non-positive values\n",
        "# if tcodes.get(col_to_check) in [4, 5, 6]:\n",
        "#      print(\"\\nChecking for non-positive values in original data within core window:\")\n",
        "#      print(all_vars_data.loc[first_usable_date:last_usable_date, col_to_check][all_vars_data.loc[first_usable_date:last_usable_date, col_to_check] <= 0])\n",
        "\n",
        "#  # If YoY %, check denominator NaNs/Zeros\n",
        "# if tcodes.get(col_to_check) == 7:\n",
        "#     print(\"\\nChecking for NaNs/Zeros in original data 12 months prior within core window:\")\n",
        "#     denominator_slice = all_vars_data[col_to_check].shift(12).loc[first_usable_date:last_usable_date]\n",
        "#     print(denominator_slice[denominator_slice.isna() | (denominator_slice.abs() < 1e-9)].head(20)) # Check where denominator has issues"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l2Ur5bYJuS1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Predictor Set Building Blocks"
      ],
      "metadata": {
        "id": "HwI_X2TNpCsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Yield Curve"
      ],
      "metadata": {
        "id": "-44IhhviDHEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spread_data = pd.read_csv('/content/drive/MyDrive/Diffusion Indices/yieldspread.csv')\n",
        "spread_df = pd.DataFrame({'Date': spread_data['Date'], 'Spread': spread_data['Spread']})\n",
        "spread_df_og = spread_df.set_index('Date')\n",
        "spread_df = spread_df_og.loc['31-Jan-59':'30-Jun-17']\n",
        "spread_df['Spread']\n",
        "spread_index = spread_df.index\n",
        "date_index = []\n",
        "for date in spread_index:\n",
        "    datetime = pd.to_datetime(date, format='%d-%b-%y')\n",
        "    if datetime.year >= 2059:\n",
        "        datetime = datetime.replace(year=datetime.year-100)\n",
        "    date_index.append(datetime)\n",
        "print(len(date_index))\n",
        "spread_df = pd.DataFrame({'Date': date_index, 'Spread': spread_df['Spread']})\n",
        "spread_df_1 = spread_df.set_index('Date')\n",
        "spread_df_2 = spread_df_og.loc['7/31/2017':'12/31/2024']\n",
        "spread_index_2 = spread_df_2.index\n",
        "date_index_2 = []\n",
        "for date in spread_index_2:\n",
        "    datetime = pd.to_datetime(date)\n",
        "    if datetime.year >= 2059:\n",
        "        datetime = datetime.replace(year=datetime.year-100)\n",
        "    date_index_2.append(datetime)\n",
        "print(len(date_index))\n",
        "spread_df = pd.DataFrame({'Date': date_index_2, 'Spread': spread_df_2['Spread']})\n",
        "spread_df_2 = spread_df.set_index('Date')\n",
        "X_raw_spread = pd.concat([spread_df_1, spread_df_2])\n",
        "X_raw_spread = X_raw_spread.resample('MS').mean()\n",
        "X_raw_spread = X_raw_spread.loc[first_usable_date:last_usable_date]\n",
        "X_raw_spread"
      ],
      "metadata": {
        "id": "3bguV-JADGNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Factor Set"
      ],
      "metadata": {
        "id": "0A18d5v8DTr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer_pca = KNNImputer(n_neighbors=5)\n",
        "X_filled_for_pca = pd.DataFrame(imputer_pca.fit_transform(X_transformed_core),\n",
        "                                index=X_transformed_core.index,\n",
        "                                columns=X_transformed_core.columns)\n",
        "scaler_sm_pca = StandardScaler()\n",
        "X_scaled_for_sm_pca = scaler_sm_pca.fit_transform(X_filled_for_pca)\n",
        "\n",
        "\n",
        "max_potential_factors = 50\n",
        "print(f\" Running statsmodels PCA considering up to {max_potential_factors} components...\")\n",
        "sm_pca_results = smPCA(X_scaled_for_sm_pca,\n",
        "                       ncomp=max_potential_factors,\n",
        "                       standardize=False, # Data is already scaled\n",
        "                       demean=True)\n",
        "\n",
        "print(\" Calculating Bai & Ng Information Criteria...\")\n",
        "ic_values_array = sm_pca_results.ic\n",
        "\n",
        "\n",
        "ICs_df = pd.DataFrame(ic_values_array,\n",
        "                      index=np.arange(0, max_potential_factors+1), # Index k = 1, 2, ...\n",
        "                      columns=['IC_p1', 'IC_p2', 'IC_p3']) # Name the columns\n",
        "\n",
        "\n",
        "print(\" Information Criteria DataFrame (IC_p1, IC_p2, IC_p3) Head:\")\n",
        "print(ICs_df.head())\n",
        "\n",
        "try:\n",
        "    optimal_k_ic2 = ICs_df['IC_p2'].idxmin() # Now works on the DataFrame\n",
        "    min_ic2_value = ICs_df['IC_p2'].min()\n",
        "    print(f\"\\n Optimal number of factors according to Bai & Ng IC_p2: {optimal_k_ic2}\")\n",
        "    print(f\"    (Minimum IC_p2 value: {min_ic2_value:.4f})\")\n",
        "\n",
        "    # Optionally find for others\n",
        "    optimal_k_ic1 = ICs_df['IC_p1'].idxmin()\n",
        "    optimal_k_ic3 = ICs_df['IC_p3'].idxmin()\n",
        "    print(f\"    (Optimal for IC_p1: {optimal_k_ic1}, IC_p3: {optimal_k_ic3})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" ERROR finding optimal k from ICs: {e}\")\n",
        "    print(\"  ICs DataFrame:\")\n",
        "    print(ICs_df) # Print the DataFrame for debugging\n",
        "    optimal_k_ic2 = 8 # Default if fails\n",
        "    print(f\"  Defaulting to {optimal_k_ic2} factors.\")\n",
        "\n",
        "\n",
        "final_n_factors = optimal_k_ic2\n",
        "all_eigenvals = sm_pca_results.eigenvals\n",
        "if isinstance(all_eigenvals, np.ndarray): # Ensure it's usable\n",
        "  total_variance = all_eigenvals.sum()\n",
        "  if total_variance > 1e-9:\n",
        "    all_explained_variance_ratios = all_eigenvals / total_variance\n",
        "    # Select the ratios ONLY for the 'final_n_factors' we chose\n",
        "    explained_variance_ratios_final = all_explained_variance_ratios[:final_n_factors] # Get as numpy array\n",
        "  else:\n",
        "    print(\"ERROR: Total variance (sum of eigenvalues) is zero or negative.\")\n",
        "    explained_variance_ratios_final = np.array([np.nan]*final_n_factors) # Error case\n",
        "else:\n",
        "  print(\"ERROR: Could not extract eigenvalues as expected Series/Array.\")\n",
        "  explained_variance_ratios_final = np.array([np.nan]*final_n_factors) # Error case\n",
        "\n",
        "print(f\" Extracting the top {final_n_factors} factors...\")\n",
        "\n",
        "factors_final_values = sm_pca_results.factors[:, :final_n_factors]\n",
        "\n",
        "X_factors_raw_final = pd.DataFrame(factors_final_values,\n",
        "                                   index=X_filled_for_pca.index,\n",
        "                                   columns=[f'Factor_{i+1}' for i in range(final_n_factors)])\n",
        "\n",
        "print(\"\\n Final Factor DataFrame head (using Bai & Ng factors):\")\n",
        "print(X_factors_raw_final.head())\n",
        "print(f\"\\n Final Factor DF shape: {X_factors_raw_final.shape}\")\n",
        "print(f\" Final Factor DF NaNs: {X_factors_raw_final.isna().sum().sum()}\")\n",
        "print(\"\\n--- End of Factor Generation using Bai & Ng Criteria ---\")"
      ],
      "metadata": {
        "id": "FseXz9QJbj-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(explained_variance_ratios_final)"
      ],
      "metadata": {
        "id": "_A06-icbOxkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing Category-Based Diffusion Index"
      ],
      "metadata": {
        "id": "2EIwDxksGPZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining categories (given by McCracken and Ng (2015))\n",
        "variable_groups = {\n",
        "    'Output_Income': ['RPI', 'W875RX1', 'INDPRO', 'IPFPNSS', 'IPFINAL', 'IPCONGD', 'IPDCONGD', 'IPNCONGD', 'IPBUSEQ', 'IPMAT', 'IPDMAT', 'IPNMAT', 'IPMANSICS', 'IPB51222S', 'IPFUELS', 'CUMFNS'],\n",
        "    'Labor_Market': ['HWI', 'HWIURATIO', 'CLF16OV', 'CE16OV', 'UNRATE', 'UEMPMEAN', 'UEMPLT5', 'UEMP5TO14', 'UEMP15OV', 'UEMP15T26', 'UEMP27OV', 'CLAIMSx', 'PAYEMS', 'USGOOD', 'CES1021000001', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP', 'SRVPRD', 'USTPU', 'USWTRADE', 'USTRADE', 'USFIRE', 'USGOVT', 'CES0600000007', 'AWOTMAN', 'AWHMAN', 'CES0600000008', 'CES2000000008', 'CES3000000008'],\n",
        "    'Housing': ['HOUST', 'HOUSTNE', 'HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE', 'PERMITMW', 'PERMITS', 'PERMITW'],\n",
        "    'Consumption_Orders_Inventories': ['DPCERA3M086SBEA', 'CMRMTSPLx', 'RETAILx', 'AMDMNOx', 'AMDMUOx', 'BUSINVx', 'ISRATIOx'],\n",
        "    'Money_Credit': ['M1SL', 'M2SL', 'M2REAL', 'BOGMBASE', 'TOTRESNS', 'NONBORRES', 'BUSLOANS', 'REALLN', 'NONREVSL', 'CONSPI', 'DTCOLNVHFNM', 'DTCTHFNM', 'INVEST'],\n",
        "    'Interest_Rates_Spreads': ['FEDFUNDS', 'CP3Mx', 'TB3MS', 'TB6MS', 'GS1', 'GS5', 'GS10', 'AAA', 'BAA', 'COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'T10YFFM', 'AAAFFM', 'BAAFFM'],\n",
        "    'FX_Rates': ['EXSZUSx', 'EXJPUSx', 'EXUSUKx', 'EXCAUSx'],\n",
        "    'Prices': ['WPSFD49207', 'WPSFD49502', 'WPSID61', 'WPSID62', 'PPICMM', 'CPIAUCSL', 'CPIAPPSL', 'CPITRNSL', 'CPIMEDSL', 'CUSR0000SAC', 'CUSR0000SAD', 'CUSR0000SAS', 'CPIULFSL', 'CUSR0000SA0L2', 'CUSR0000SA0L5', 'PCEPI', 'DDURRG3M086SBEA', 'DNDGRG3M086SBEA', 'DSERRG3M086SBEA'],\n",
        "    'Stock_Market': ['S&P 500', 'S&P div yield', 'S&P PE ratio', 'VIXCLSx']\n",
        "}\n",
        "\n",
        "# Other scenarios\n",
        "counter_cyclical_vars = {\n",
        "    'UNRATE', 'UEMPMEAN', 'UEMPLT5', 'UEMP5TO14', 'UEMP15OV', 'UEMP15T26', 'UEMP27OV',\n",
        "    'CLAIMSx', 'ISRATIOx'\n",
        "}\n",
        "\n",
        "level_log_positive_impact = {\n",
        "    'CES0600000007', 'AWHMAN', 'HOUST', 'HOUSTNE', 'HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE', 'PERMITMW', 'PERMITS', 'PERMITW', 'T10YFFM'\n",
        "}\n",
        "\n",
        "level_log_negative_impact ={\n",
        "    'VIXCLSx', 'COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'AAAFFM', 'BAAFFM'\n",
        "}\n",
        "leading_indicators_group = {\n",
        "    'Leading_Indicators': [\n",
        "        'AWOTMAN',          # Avg Weekly Overtime Hours, Mfg (tcode 2, Pro-cyclical >0)\n",
        "        'AWHMAN',           # Avg Weekly Hours, Mfg (tcode 1, level_pos: diff>0)\n",
        "        'HOUST',            # Housing Starts (tcode 4, level_pos: diff>0)\n",
        "        'PERMIT',           # Building Permits (tcode 4, level_pos: diff>0)\n",
        "        'CLAIMSx',          # Initial Claims (tcode 5, counter: <0)\n",
        "        'T10YFFM',          # 10-Year Treasury minus Fed Funds (tcode 1, level_pos: diff>0)\n",
        "        'S&P 500',          # S&P 500 Index (tcode 5, Pro-cyclical >0)\n",
        "        'AMDMNOx',          # New Orders, Durable Goods (tcode 5, Pro-cyclical >0) - *Check exact orders series used*\n",
        "        # Add others like M2REAL (Money Supply) if desired and tcode allows >0 logic easily\n",
        "        # Remove any from this list if not present in your final columns\n",
        "     ]\n",
        "}\n",
        "# Threshold for small increase relative to standard deviation\n",
        "small_change_threshold_fraction = 0.1"
      ],
      "metadata": {
        "id": "Q62nRs8MqBcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_indices = {}\n",
        "all_grouped_vars_found = set()\n",
        "imputer_core = KNNImputer(n_neighbors=5)\n",
        "X_imputed_core = pd.DataFrame(imputer_core.fit_transform(X_transformed_core),\n",
        "                                  index=X_transformed_core.index,\n",
        "                                  columns=X_transformed_core.columns)\n",
        "# Calculate standard deviations for thresholding\n",
        "std_devs = X_imputed_core.std()\n",
        "small_change_thresholds = std_devs * small_change_threshold_fraction\n",
        "\n",
        "for category_name, category_vars in variable_groups.items():\n",
        "  valid_category_vars = [var for var in category_vars if var in X_imputed_core.columns]\n",
        "  if not valid_category_vars:\n",
        "    print(f'Skipping category {category_name}, no valid variables')\n",
        "    continue\n",
        "\n",
        "  all_grouped_vars_found.update(valid_category_vars)\n",
        "  category_data = X_imputed_core[valid_category_vars]\n",
        "\n",
        "  # Stores numerical state for category\n",
        "  improvement_state_values = pd.DataFrame(index=category_data.index, dtype=float)\n",
        "\n",
        "  for col_name in valid_category_vars:\n",
        "    series = category_data[col_name]\n",
        "    threshold = small_change_thresholds.get(col_name, 0)\n",
        "    state_col = pd.Series(index=series.index, dtype=float)\n",
        "\n",
        "    if col_name in level_log_positive_impact:\n",
        "      diff_series = series.diff(1)\n",
        "      state_col[diff_series > threshold] = 1.0 # Strong increase = good\n",
        "      state_col[(diff_series > -threshold) & (diff_series <= threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[diff_series <= -threshold] = 0.0 # Decrease = Bad\n",
        "    elif col_name in level_log_negative_impact:\n",
        "      diff_series = series.diff(1)\n",
        "      state_col[diff_series < -threshold] = 1.0 # Strong Decrease = Good\n",
        "      state_col[(diff_series >= -threshold) & (diff_series < threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[diff_series >= threshold] = 0.0 # Increase = Bad\n",
        "    elif col_name in counter_cyclical_vars:\n",
        "      state_col[series < -threshold] = 1.0 # Strong Decrease = Good\n",
        "      state_col[(series >= -threshold) & (series < threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[series >= threshold] = 0.0 # Increase = Bad\n",
        "    else:\n",
        "      state_col[series > threshold] = 1.0 # Strong Increase = Good\n",
        "      state_col[(series > -threshold) & (series <= threshold)] = 0.5 # Flat/Small Change = Mid\n",
        "      state_col[series <= -threshold] = 0.0 # Decrease = Bad\n",
        "\n",
        "    improvement_state_values[col_name] = state_col\n",
        "  # Average state calculation\n",
        "  di_series = improvement_state_values.mean(axis=1, skipna=True)\n",
        "  diffusion_indices[category_name + '__DI'] = di_series\n",
        "  print(f\"Calculated diffusion index for {category_name} ({len(valid_category_vars)} variables)\")\n",
        "\n",
        "X_cbdi_raw = pd.DataFrame(diffusion_indices)"
      ],
      "metadata": {
        "id": "caoyzVbIo8Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding overall DI\n",
        "overall_data = X_imputed_core[list(all_grouped_vars_found)]\n",
        "overall_improvement_state_values = pd.DataFrame(index=overall_data.index, dtype=float)\n",
        "\n",
        "for col_name in overall_data.columns:\n",
        "    # Apply same logic as above to ALL variables used in groups\n",
        "    series = overall_data[col_name]\n",
        "    threshold = small_change_thresholds.get(col_name, 0)\n",
        "    state_col = pd.Series(index=series.index, dtype=float)\n",
        "    if col_name in level_log_positive_impact:\n",
        "        diff_series = series.diff(1)\n",
        "        state_col[diff_series > threshold] = 1.0\n",
        "        state_col[(diff_series > -threshold) & (diff_series <= threshold)] = 0.5\n",
        "        state_col[diff_series <= -threshold] = 0.0\n",
        "    elif col_name in level_log_negative_impact:\n",
        "        diff_series = series.diff(1);\n",
        "        state_col[diff_series < -threshold] = 1.0\n",
        "        state_col[(diff_series >= -threshold) & (diff_series < threshold)] = 0.5\n",
        "        state_col[diff_series >= threshold] = 0.0\n",
        "    elif col_name in counter_cyclical_vars:\n",
        "        state_col[series < -threshold] = 1.0\n",
        "        state_col[(series >= -threshold) & (series < threshold)] = 0.5\n",
        "        state_col[series >= threshold] = 0.0\n",
        "    else:\n",
        "        state_col[series > threshold] = 1.0\n",
        "        state_col[(series > -threshold) & (series <= threshold)] = 0.5\n",
        "        state_col[series <= -threshold] = 0.0\n",
        "    overall_improvement_state_values[col_name] = state_col\n",
        "\n",
        "X_cbdi_raw['Overall_DI'] = overall_improvement_state_values.mean(axis=1, skipna=True)\n",
        "print(X_cbdi_raw.head())\n",
        "print(f\"Total NaNs: {X_cbdi_raw.isna().sum().sum()}\")\n"
      ],
      "metadata": {
        "id": "Ds8GRDBPseAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if X_cbdi_raw.index[1:].equals(X_imputed_core.index[1:]):\n",
        "     print(\"Index alignment verified (ignoring first row potentially affected by diff()).\")\n",
        "else:\n",
        "     print(\"Index mismatch suspected\")\n",
        "\n",
        "X_cbdi_raw.to_pickle(\"X_cbdi_raw_3state.pkl\")\n",
        "print(\"3-State Category Diffusion Index DataFrame saved as X_cbdi_raw_3state.pkl\")"
      ],
      "metadata": {
        "id": "QPAhFDJOth91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Factor-Based Diffusion Index"
      ],
      "metadata": {
        "id": "ZA1rKMXko70a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Calculating Factor-Based Diffusion Indices (Method 1: Sign-Based Contribution) ---\")\n",
        "\n",
        "if isinstance(sm_pca_results.loadings, pd.DataFrame):\n",
        "  loadings_df = sm_pca_results.loadings\n",
        "  print(\"Loadings appear to be a DataFrame.\")\n",
        "elif isinstance(sm_pca_results.loadings, np.ndarray):\n",
        "  print(\"Loadings are a NumPy array. Converting to DataFrame...\")\n",
        "  try:\n",
        "      factor_columns_generated = [f'Factor_{i+1}' for i in range(sm_pca_results.loadings.shape[1])]\n",
        "      variable_index = X_imputed_core.columns\n",
        "      loadings_df = pd.DataFrame(sm_pca_results.loadings,\n",
        "                                  index=variable_index,\n",
        "                                  columns=factor_columns_generated)\n",
        "      optimized_factors = X_factors_raw_final.columns\n",
        "      loadings_df = loadings_df[optimized_factors]\n",
        "      print(\"Conversion successful.\")\n",
        "  except Exception as e:\n",
        "    print(f\"ERROR converting loadings NumPy array to DataFrame: {e}\")\n",
        "    loadings_df = None # Indicate failure\n",
        "else:\n",
        "  print(\"ERROR: sm_pca_results.loadings is an unexpected type. Cannot proceed.\")\n",
        "  loadings_df = None\n",
        "\n",
        "if loadings_df is None:\n",
        "  print(\"Stopping FBDI calculation due to loading issues.\")\n",
        "  X_fbdi_raw_m1 = pd.DataFrame()\n",
        "  nan_check = pd.Series()\n",
        "else:\n",
        "  available_factors = list(X_factors_raw_final.columns)\n",
        "  factors_to_include = [f for f in ['Factor_1', 'Factor_2', 'Factor_3', 'Factor_4'] if f in available_factors]\n",
        "  print(f\" Factors used for FBDI calculation: {factors_to_include}\")\n",
        "\n",
        "  if not factors_to_include:\n",
        "    print(\"ERROR: None of the specified factors found. Skipping FBDI.\")\n",
        "    X_fbdi_raw_m1 = pd.DataFrame()\n",
        "    nan_check = pd.Series()\n",
        "  else:\n",
        "    fbdi_results = {} # Dictionary to store each factor's DI Series\n",
        "\n",
        "for factor_to_analyze in factors_to_include:\n",
        "  print(f\"\\n-- Calculating FBDI for: {factor_to_analyze} --\")\n",
        "\n",
        "  # Get the specific factor from factor dataframe\n",
        "  target_factor_series = X_factors_raw_final[factor_to_analyze]\n",
        "  print(f\"  NaNs check in input {factor_to_analyze}: {target_factor_series.isna().sum()}\")\n",
        "  if target_factor_series.isna().any():\n",
        "    print(f\"  ERROR: Input factor series {factor_to_analyze} contains NaNs!\")\n",
        "    continue\n",
        "\n",
        "  # Get the loadings\n",
        "  if factor_to_analyze not in loadings_df.columns:\n",
        "    print(f\"  ERROR: Loadings column for {factor_to_analyze} not found. Skipping.\")\n",
        "    continue\n",
        "  target_factor_loadings = loadings_df[factor_to_analyze] # This is a pandas Series (Var -> Loading)\n",
        "  if target_factor_loadings.isna().any():\n",
        "    print(f\"  ERROR: Loadings for {factor_to_analyze} contain NaNs!\")\n",
        "    continue\n",
        "\n",
        "  # Calculate Factor Difference\n",
        "  factor_diff = target_factor_series.diff(1)\n",
        "  print(f\"  NaNs check in factor_diff (expect <= 1): {factor_diff.isna().sum()}\")\n",
        "  if factor_diff.iloc[1:].isna().any(): # Check if unexpected NaNs exist beyond the first one\n",
        "    print(f\"  WARN: Unexpected NaNs found in factor_diff beyond the first row!\")\n",
        "\n",
        "  # Calculate Absolute Loadings and Total for normalization\n",
        "  absolute_loadings = target_factor_loadings.abs()\n",
        "\n",
        "  variables_in_analysis = X_imputed_core.columns\n",
        "  total_abs_loading = absolute_loadings.loc[variables_in_analysis].sum()\n",
        "  print(f\"  Total absolute loading for {factor_to_analyze} (across {len(variables_in_analysis)} vars): {total_abs_loading:.4f}\")\n",
        "\n",
        "  if pd.isna(total_abs_loading) or total_abs_loading < 1e-9:\n",
        "    print(f\"  ERROR: Total absolute loading is zero/NaN for {factor_to_analyze}. Skipping FBDI calculation.\")\n",
        "    fbdi_results[f'FBDI_Weighted_{factor_to_analyze}'] = pd.Series(np.nan, index=X_imputed_core.index)\n",
        "    continue\n",
        "\n",
        "  # Loop Through Variables and Accumulate Weighted States\n",
        "  fbdi_contrib_weighted = pd.Series(0.0, index=factor_diff.index)\n",
        "\n",
        "  for var_name in variables_in_analysis:\n",
        "    loading = target_factor_loadings.get(var_name) # Get scalar loading\n",
        "    abs_loading_val = absolute_loadings.get(var_name, 0) # Get scalar absolute loading\n",
        "\n",
        "    if loading is None or pd.isna(loading) or abs_loading_val == 0:\n",
        "      continue\n",
        "\n",
        "    # Calculate approximate change contribution\n",
        "    contribution_diff = loading * factor_diff\n",
        "\n",
        "    # Get the threshold specific to this variable\n",
        "    threshold = small_change_thresholds.get(var_name, 0)\n",
        "\n",
        "    # Determine state (0, 0.5, 1) based on the factor's push\n",
        "    state_col = pd.Series(0.5, index=contribution_diff.index, dtype=float) # Default neutral\n",
        "    state_col[contribution_diff > threshold] = 1.0  # Strong Positive Push\n",
        "    state_col[contribution_diff < -threshold] = 0.0 # Strong Negative Push\n",
        "    # Fill initial NaN in diff with neutral state\n",
        "    # (This should affect only the first row if factor_diff has only 1 NaN)\n",
        "    state_col = state_col.fillna(0.5)\n",
        "\n",
        "    # Accumulate state weighted by the absolute loading of the variable on this factor\n",
        "    fbdi_contrib_weighted += state_col * abs_loading_val\n",
        "\n",
        "  # Normalize\n",
        "  fbdi_series_method1 = fbdi_contrib_weighted / total_abs_loading\n",
        "  fbdi_results[f'FBDI_Weighted_{factor_to_analyze}'] = fbdi_series_method1\n",
        "  print(f\"  Finished calculating FBDI for {factor_to_analyze}.\")\n",
        "\n",
        "X_fbdi_raw_method1 = pd.DataFrame(fbdi_results)\n",
        "\n",
        "print(f\"\\nFactor-Based Diffusion Index DataFrame (Method 1 - Factors {factors_to_include}) head(15):\")\n",
        "print(X_fbdi_raw_method1.head(15))\n",
        "nan_check = X_fbdi_raw_method1.isna().sum()\n",
        "print(f\"NaN Check per column (expect <= 1 each):\\n{nan_check}\")\n",
        "total_nans = nan_check.sum()\n",
        "print(f\"Total NaNs: {total_nans}\")\n",
        "\n",
        "if (nan_check <= 1).all():\n",
        "  save_path = \"X_fbdi_raw_method1.pkl\" # Save locally in Colab session first\n",
        "  try:\n",
        "      X_fbdi_raw_method1.to_pickle(save_path)\n",
        "      print(f\"\\nSaved: {save_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"\\nERROR saving FBDI file: {e}\")\n",
        "else:\n",
        "  print(\"\\nERROR: Excessive NaNs (>1 per column) remain in FBDI Method 1. Not saved. Please debug.\")"
      ],
      "metadata": {
        "id": "W6sHrvXsqFmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_factor_loadings(loadings_df, factor_name, top_n=15):\n",
        "    \"\"\"Prints variables with highest positive/negative absolute loadings for a factor.\"\"\"\n",
        "    if factor_name not in loadings_df.columns:\n",
        "        print(f\"Factor '{factor_name}' not found in loadings DataFrame.\")\n",
        "        return\n",
        "    print(f\"\\\\n--- Analyzing Loadings for: {factor_name} ---\")\n",
        "\n",
        "    # Get loadings for this factor\n",
        "    factor_loadings = loadings_df[factor_name].copy()\n",
        "\n",
        "    # Calculate absolute loadings and sort\n",
        "    abs_loadings = factor_loadings.abs().sort_values(ascending=False)\n",
        "\n",
        "    # Get top N variables by absolute loading\n",
        "    top_vars = abs_loadings.head(top_n).index\n",
        "\n",
        "    # Show actual loadings\n",
        "    print(f\"Top {top_n} variables by Absolute Loading on {factor_name}:\")\n",
        "    print(loadings_df.loc[top_vars, [factor_name]].sort_values(by=factor_name, ascending=False)) # Sort by signed loading\n",
        "\n",
        "# Example: Analyze first 4 factors\n",
        "if not loadings_df.empty:\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_1')\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_2')\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_3')\n",
        "    analyze_factor_loadings(loadings_df, 'Factor_4')\n",
        "else:\n",
        "     print(\"Loadings DataFrame is empty, cannot analyze.\")"
      ],
      "metadata": {
        "id": "MpuuGlWFIvBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\n--- Calculating Recursive FBDI (NumPy Accumulation) ---\")\n",
        "\n",
        "RECURSION_START_DATE = '1961-01-01'\n",
        "N_FACTORS_FIXED_REC = 8 # Keep reasonable number fixed\n",
        "ALIGN_FACTOR = 'Factor_1'\n",
        "\n",
        "X_for_recursion = X_imputed_core.loc[X_imputed_core.index.min():last_usable_date].copy()\n",
        "dates_to_estimate = X_for_recursion.loc[RECURSION_START_DATE:].index\n",
        "num_steps = len(dates_to_estimate)\n",
        "first_window_sign_f1 = None\n",
        "\n",
        "latest_factor_estimates_array = np.full((num_steps, N_FACTORS_FIXED_REC), np.nan)\n",
        "\n",
        "scaler_rec = StandardScaler()\n",
        "pca_rec = PCA(n_components=N_FACTORS_FIXED_REC, random_state=42)\n",
        "\n",
        "start_time_rec_loop = time.time()\n",
        "print(f\"Starting recursive PCA loop from {RECURSION_START_DATE}...\")\n",
        "\n",
        "# Recursive Loop\n",
        "for i, t in enumerate(dates_to_estimate): # Use enumerate to get index 'i' for array\n",
        "  loop_step_start_rec = time.time()\n",
        "  print(f\" Processing t = {t.strftime('%Y-%m-%d')} ({i+1}/{num_steps})...\", end=\"\")\n",
        "\n",
        "  X_upto_t = X_for_recursion.loc[:t]\n",
        "\n",
        "  if len(X_upto_t) < N_FACTORS_FIXED_REC + 10:\n",
        "    print(\" Skipping, window too small.\")\n",
        "\n",
        "    continue\n",
        "\n",
        "  try:\n",
        "    X_scaled_upto_t = scaler_rec.fit_transform(X_upto_t)\n",
        "    pca_rec.fit(X_scaled_upto_t)\n",
        "    factors_upto_t = pca_rec.transform(X_scaled_upto_t)\n",
        "    current_latest_factors = factors_upto_t[-1, :]\n",
        "\n",
        "    # Sign Alignment\n",
        "    if first_window_sign_f1 is None:\n",
        "      first_window_sign_f1 = np.sign(current_latest_factors[0])\n",
        "      if first_window_sign_f1 == 0: first_window_sign_f1 = 1\n",
        "    if np.sign(current_latest_factors[0]) != first_window_sign_f1:\n",
        "      current_latest_factors = -current_latest_factors\n",
        "\n",
        "    latest_factor_estimates_array[i, :] = current_latest_factors\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\" ERROR PCA at {t}: {e}. Storing NaNs.\")\n",
        "\n",
        "\n",
        "  print(f\" Step Time: {(time.time() - loop_step_start_rec):.2f}s\")\n",
        "\n",
        "print(f\"--- Recursive Loop Finished --- Total time: {(time.time() - start_time_rec_loop)/60:.2f} minutes ---\")\n",
        "\n",
        "\n",
        "print(\" Constructing Cumulative Recursive Factor Indices from NumPy array...\")\n",
        "# Convert NumPy array to DataFrame\n",
        "latest_factors_df = pd.DataFrame(\n",
        "  latest_factor_estimates_array,\n",
        "  index=dates_to_estimate,\n",
        "  columns=[f'Factor_{j+1}_Latest' for j in range(N_FACTORS_FIXED_REC)]\n",
        ")\n",
        "\n",
        "\n",
        "if latest_factors_df.empty:\n",
        "  print(\"ERROR: No valid factor estimates generated.\")\n",
        "\n",
        "else:\n",
        "  # Calculate cumulative sum\n",
        "  X_fbdi_raw_recursive = latest_factors_df.cumsum(axis=0)\n",
        "  X_fbdi_raw_recursive.columns = [f'RFDI_{i+1}' for i in range(X_fbdi_raw_recursive.shape[1])]\n",
        "\n",
        "\n",
        "  print(\"\\nRecursive Factor Diffusion Index (RFDI) DataFrame head(15):\")\n",
        "  print(X_fbdi_raw_recursive.head(15))\n",
        "  nan_check = X_fbdi_raw_recursive.isna().sum()\n",
        "  print(f\"NaN Check:\\n{nan_check}\")\n",
        "\n",
        "  save_path = \"X_fbdi_raw_recursive.pkl\"\n",
        "  try:\n",
        "    X_fbdi_raw_recursive.to_pickle(save_path)\n",
        "    print(f\"\\nSaved: {save_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"\\nERROR saving RFDI file: {e}\")"
      ],
      "metadata": {
        "id": "4AwKb9WPo32j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\n--- Calculating Residual Distribution Shape Index (RDSI) ---\")\n",
        "# MAIN FACTOR-BASED DIFFUSION INDEX\n",
        "ROLLING_WINDOW_DIST = 11 # Short window for smoothing skew/kurtosis\n",
        "FINAL_SMOOTH_RDSI = 4   # Dinal smoothing on indices\n",
        "\n",
        "print(\" Calculating residuals...\")\n",
        "Predicted_Values = X_factors_raw_final @ loadings_df.T\n",
        "Predicted_Values.columns = X_imputed_core.columns\n",
        "Residuals_df = X_imputed_core - Predicted_Values\n",
        "\n",
        "print(f\" Calculating rolling ({ROLLING_WINDOW_DIST}m window) cross-sectional skew/kurtosis:\")\n",
        "\n",
        "\n",
        "Skew_t = Residuals_df.skew(axis=1, skipna=True)\n",
        "Kurt_t = Residuals_df.kurt(axis=1, skipna=True) # Fisher's kurtosis\n",
        "\n",
        "# Apply rolling window smoothing\n",
        "Rolling_Skew = Skew_t.rolling(window=ROLLING_WINDOW_DIST, min_periods=ROLLING_WINDOW_DIST // 2).mean()\n",
        "Rolling_Kurt = Kurt_t.rolling(window=ROLLING_WINDOW_DIST, min_periods=ROLLING_WINDOW_DIST // 2).mean()\n",
        "\n",
        "\n",
        "X_fbdi_raw_rdsi = pd.DataFrame({\n",
        "    f'FBDI_ResidSkew_Roll{ROLLING_WINDOW_DIST}': Rolling_Skew,\n",
        "    f'FBDI_ResidKurt_Roll{ROLLING_WINDOW_DIST}': Rolling_Kurt\n",
        "})\n",
        "\n",
        "\n",
        "if FINAL_SMOOTH_RDSI > 1:\n",
        "    print(f\" Applying final smoothing (window={FINAL_SMOOTH_RDSI})...\")\n",
        "    cols_to_smooth = X_fbdi_raw_rdsi.columns\n",
        "    for col in cols_to_smooth:\n",
        "        X_fbdi_raw_rdsi[f'{col}_Smooth{FINAL_SMOOTH_RDSI}'] = X_fbdi_raw_rdsi[col].rolling(window=FINAL_SMOOTH_RDSI, min_periods=1).mean()\n",
        "\n",
        "    final_cols = [f'{col}_Smooth{FINAL_SMOOTH_RDSI}' for col in cols_to_smooth]\n",
        "    X_fbdi_final_to_save = X_fbdi_raw_rdsi[final_cols]\n",
        "else:\n",
        "    X_fbdi_final_to_save = X_fbdi_raw_rdsi\n",
        "\n",
        "\n",
        "print(f\"\\nResidual Distribution Shape Index (RDSI) head:\")\n",
        "\n",
        "print(X_fbdi_final_to_save.head(ROLLING_WINDOW_DIST + FINAL_SMOOTH_RDSI + 5))\n",
        "nan_check = X_fbdi_final_to_save.isna().sum()\n",
        "print(f\"NaN Check (expect NaNs at start from rolling({ROLLING_WINDOW_DIST})):\\n{nan_check}\")\n",
        "\n",
        "save_path = \"X_fbdi_raw_rdsi.pkl\"\n",
        "try:\n",
        "     X_fbdi_final_to_save.to_pickle(save_path)\n",
        "     print(f\"\\nSaved (NaNs dropped): {save_path}\")\n",
        "except Exception as e:\n",
        "      print(f\"\\nERROR saving RDSI file: {e}\")"
      ],
      "metadata": {
        "id": "UX2KBf505qJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc. Prep"
      ],
      "metadata": {
        "id": "6eGS_nVT9bjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lagging Variables"
      ],
      "metadata": {
        "id": "4ero2Hgh9e34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_cbdi_raw_3state = pd.read_pickle(\"X_cbdi_raw_3state.pkl\")\n",
        "X_fbdi_raw_method1 = pd.read_pickle('X_fbdi_raw_method1.pkl')\n",
        "X_fbdi_raw_recursive = pd.read_pickle('X_fbdi_raw_recursive.pkl')\n",
        "X_fbdi_raw_rdsi = pd.read_pickle('X_fbdi_raw_rdsi.pkl')\n",
        "\n",
        "lags_to_add = [1, 2, 6, 12]\n",
        "# Function for lagging\n",
        "def add_lags(df, lags):\n",
        "  df_lagged_list = [df]\n",
        "  for lag in lags:\n",
        "    df_shifted = df.shift(lag).add_suffix(f'_lag{lag}')\n",
        "    df_lagged_list.append(df_shifted)\n",
        "  return pd.concat(df_lagged_list, axis=1)\n",
        "\n",
        "# Lagging Factor Set\n",
        "X_factors_lagged = add_lags(X_factors_raw_final, lags_to_add)\n",
        "\n",
        "# Lagging CBDI Set\n",
        "X_cbdi_lagged = add_lags(X_cbdi_raw_3state, lags_to_add)\n",
        "\n",
        "# Lagging FBDI Set\n",
        "X_fbdi_lagged = add_lags(X_fbdi_raw_rdsi, lags_to_add)\n",
        "\n",
        "# Lagging FBDI Recursive\n",
        "X_fbdi_recursive_lagged = add_lags(X_fbdi_raw_recursive, lags_to_add)\n",
        "\n",
        "# Lagging Full Set\n",
        "X_full_lagged = add_lags(X_imputed_core, lags_to_add)\n",
        "\n",
        "# Lagging yield\n",
        "X_yield_lagged = add_lags(X_raw_spread, lags_to_add)"
      ],
      "metadata": {
        "id": "16tdVPBV9IY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting Data"
      ],
      "metadata": {
        "id": "frSnAfrRBYrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_size = 0.4\n",
        "X_train_factors, X_test_factors, y_train, y_test = skm.train_test_split(X_factors_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_cbdi, X_test_cbdi, _, _ = skm.train_test_split(X_cbdi_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_full, X_test_full, _, _ = skm.train_test_split(X_full_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_fbdi, X_test_fbdi, _, _ = skm.train_test_split(X_fbdi_lagged, y_final, test_size = test_set_size, shuffle=False)\n",
        "X_train_fbdi_recursive, X_test_fbdi_recursive, _, _ = skm.train_test_split(X_fbdi_recursive_lagged, y_final, test_size = test_set_size, shuffle = False)\n",
        "X_train_yield, X_test_yield, _, _ = skm.train_test_split(X_yield_lagged, y_final, test_size = test_set_size, shuffle = False)"
      ],
      "metadata": {
        "id": "frlgvAt6_MzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.to_pickle(X_train_factors, \"X_train_factors.pkl\")\n",
        "pd.to_pickle(X_test_factors, \"X_test_factors.pkl\")\n",
        "pd.to_pickle(X_train_cbdi, \"X_train_cbdi.pkl\")\n",
        "pd.to_pickle(X_test_cbdi, \"X_test_cbdi.pkl\")\n",
        "pd.to_pickle(X_train_full, \"X_train_full.pkl\")\n",
        "pd.to_pickle(X_test_full, \"X_test_full.pkl\")\n",
        "pd.to_pickle(X_train_fbdi, 'X_train_fbdi.pkl')\n",
        "pd.to_pickle(X_test_fbdi, 'X_test_fbdi.pkl')\n",
        "pd.to_pickle(X_train_fbdi, 'X_train_fbdi_recursive.pkl')\n",
        "pd.to_pickle(X_test_fbdi, 'X_test_fbdi_recursive.pkl')\n",
        "pd.to_pickle(y_train, \"y_train.pkl\")\n",
        "pd.to_pickle(y_test, \"y_test.pkl\")"
      ],
      "metadata": {
        "id": "23Hf3tW2B7lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Model Processing"
      ],
      "metadata": {
        "id": "kd-DwsBWCcDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute factors\n",
        "imputer_factors = KNNImputer(n_neighbors=5)\n",
        "imputer_factors.fit(X_train_factors)\n",
        "X_train_factors_imp = imputer_factors.transform(X_train_factors)\n",
        "X_test_factors_imp = imputer_factors.transform(X_test_factors)\n",
        "\n",
        "# Scale factors\n",
        "scaler_factors = StandardScaler()\n",
        "scaler_factors.fit(X_train_factors_imp)\n",
        "X_train_factors_scaled = scaler_factors.transform(X_train_factors_imp)\n",
        "X_test_factors_scaled = scaler_factors.transform(X_test_factors_imp)\n",
        "\n",
        "# Repeat for CBDI\n",
        "imputer_cbdi = KNNImputer(n_neighbors=5)\n",
        "imputer_cbdi.fit(X_train_cbdi)\n",
        "X_train_cbdi_imp = imputer_cbdi.transform(X_train_cbdi)\n",
        "X_test_cbdi_imp = imputer_cbdi.transform(X_test_cbdi)\n",
        "\n",
        "scaler_cbdi = StandardScaler()\n",
        "scaler_cbdi.fit(X_train_cbdi_imp)\n",
        "X_train_cbdi_scaled = scaler_cbdi.transform(X_train_cbdi_imp)\n",
        "X_test_cbdi_scaled = scaler_cbdi.transform(X_test_cbdi_imp)\n",
        "\n",
        "# Full set\n",
        "imputer_full = KNNImputer(n_neighbors=5)\n",
        "imputer_full.fit(X_train_full)\n",
        "X_train_full_imp = imputer_full.transform(X_train_full)\n",
        "X_test_full_imp = imputer_full.transform(X_test_full)\n",
        "\n",
        "scaler_full = StandardScaler()\n",
        "scaler_full.fit(X_train_full_imp)\n",
        "X_train_full_scaled = scaler_full.transform(X_train_full_imp)\n",
        "X_test_full_scaled = scaler_full.transform(X_test_full_imp)\n",
        "\n",
        "# FBDI\n",
        "imputer_fbdi = KNNImputer(n_neighbors=5)\n",
        "imputer_fbdi.fit(X_train_fbdi)\n",
        "X_train_fbdi_imp = imputer_fbdi.transform(X_train_fbdi)\n",
        "X_test_fbdi_imp = imputer_fbdi.transform(X_test_fbdi)\n",
        "\n",
        "scaler_fbdi = StandardScaler()\n",
        "scaler_fbdi.fit(X_train_fbdi_imp)\n",
        "X_train_fbdi_scaled = scaler_fbdi.transform(X_train_fbdi_imp)\n",
        "X_test_fbdi_scaled = scaler_fbdi.transform(X_test_fbdi_imp)\n",
        "\n",
        "# FBDI Recursive\n",
        "imputer_fbdi_recursive = KNNImputer(n_neighbors=5)\n",
        "imputer_fbdi_recursive.fit(X_train_fbdi_recursive)\n",
        "X_train_fbdi_recursive_imp = imputer_fbdi_recursive.transform(X_train_fbdi_recursive)\n",
        "X_test_fbdi_recursive_imp = imputer_fbdi_recursive.transform(X_test_fbdi_recursive)\n",
        "\n",
        "scaler_fbdi_recursive = StandardScaler()\n",
        "scaler_fbdi_recursive.fit(X_train_fbdi_recursive_imp)\n",
        "X_train_fbdi_recursive_scaled = scaler_fbdi_recursive.transform(X_train_fbdi_recursive_imp)\n",
        "X_test_fbdi_recursive_scaled = scaler_fbdi_recursive.transform(X_test_fbdi_recursive_imp)\n",
        "\n",
        "# Yield\n",
        "imputer_yield = KNNImputer(n_neighbors=5)\n",
        "imputer_yield.fit(X_train_yield)\n",
        "X_train_yield_imp = imputer_yield.transform(X_train_yield)\n",
        "X_test_yield_imp = imputer_yield.transform(X_test_yield)\n",
        "\n",
        "scaler_yield = StandardScaler()\n",
        "scaler_yield.fit(X_train_yield_imp)\n",
        "X_train_yield_scaled = scaler_yield.transform(X_train_yield_imp)\n",
        "X_test_yield_scaled = scaler_yield.transform(X_test_yield_imp)\n",
        "\n",
        "# Finalizing sets\n",
        "X_train_factors_final = pd.DataFrame(X_train_factors_scaled, index=X_train_factors.index, columns=X_train_factors.columns)\n",
        "X_test_factors_final = pd.DataFrame(X_test_factors_scaled, index=X_test_factors.index, columns=X_test_factors.columns)\n",
        "\n",
        "X_train_cbdi_final = pd.DataFrame(X_train_cbdi_scaled, index=X_train_cbdi.index, columns=X_train_cbdi.columns)\n",
        "X_test_cbdi_final = pd.DataFrame(X_test_cbdi_scaled, index=X_test_cbdi.index, columns=X_test_cbdi.columns)\n",
        "\n",
        "X_train_full_final = pd.DataFrame(X_train_full_scaled, index=X_train_full.index, columns=X_train_full.columns)\n",
        "X_test_full_final = pd.DataFrame(X_test_full_scaled, index=X_test_full.index, columns=X_test_full.columns)\n",
        "\n",
        "X_train_fbdi_final = pd.DataFrame(X_train_fbdi_scaled, index=X_train_fbdi.index, columns=X_train_fbdi.columns)\n",
        "X_test_fbdi_final = pd.DataFrame(X_test_fbdi_scaled, index=X_test_fbdi.index, columns=X_test_fbdi.columns)\n",
        "\n",
        "X_train_fbdi_recursive_final = pd.DataFrame(X_train_fbdi_recursive_scaled, index=X_train_fbdi_recursive.index, columns=X_train_fbdi_recursive.columns)\n",
        "X_test_fbdi_recursive_final = pd.DataFrame(X_test_fbdi_recursive_scaled, index=X_test_fbdi_recursive.index, columns=X_test_fbdi_recursive.columns)\n",
        "\n",
        "X_train_yield_final = pd.DataFrame(X_train_yield_scaled, index=X_train_yield.index, columns=X_train_yield.columns)\n",
        "X_test_yield_final = pd.DataFrame(X_test_yield_scaled, index=X_test_yield.index, columns=X_test_yield.columns)"
      ],
      "metadata": {
        "id": "oJ4x1WFSCQJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "8Qmg5UaED8p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sets = {\n",
        "    'Factors': X_train_factors_final,\n",
        "    'CBDI': X_train_cbdi_final,\n",
        "    'Full': X_train_full_final,\n",
        "    'FBDI': X_train_fbdi_final,\n",
        "    'FBDI_Recursive': X_train_fbdi_recursive_final,\n",
        "    'Yield': X_train_yield_final\n",
        "}\n",
        "\n",
        "test_sets = {\n",
        "    'Factors': X_test_factors_final,\n",
        "    'CBDI': X_test_cbdi_final,\n",
        "    'Full': X_test_full_final,\n",
        "    'FBDI': X_test_fbdi_final,\n",
        "    'FBDI_Recursive': X_test_fbdi_recursive_final,\n",
        "    'Yield': X_test_yield_final\n",
        "}"
      ],
      "metadata": {
        "id": "MDrTyZ2LDvFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = skm.cross_val_score(xgb.XGBClassifier(objective='binary:logistic', eval_metric='aucpr', use_label_encoder=False, random_state=42), X_train_fbdi_final, y_train, cv=skm.TimeSeriesSplit(n_splits=3), scoring='average_precision')\n",
        "print(f\"Index: [Name of your FBDI]\")\n",
        "print(f\"  Time Series CV PR AUC Scores: {scores}\")\n",
        "print(f\"  Mean PR AUC: {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")"
      ],
      "metadata": {
        "id": "oEOlXUgcSZZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_run_defs = {\n",
        "    \"Logit\": lambda: LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000),\n",
        "    \"Logit_L2\": lambda: LogisticRegression(penalty='l2', solver='liblinear', class_weight='balanced', random_state=42, max_iter=1000),\n",
        "    \"RandomForest\": lambda: RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    \"XGBoost\": lambda: xgb.XGBClassifier(objective='binary:logistic', eval_metric='aucpr', use_label_encoder=False, random_state=42),\n",
        "    'HGBoost': lambda: HistGradientBoostingClassifier(loss='log_loss', random_state=42, class_weight='balanced')\n",
        "}"
      ],
      "metadata": {
        "id": "UPolDOCeFh-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "mCnwoZ-6pgKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RF Param Grid\n",
        "rf_param_grid = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None] + list(randint(5, 20).rvs(5)),\n",
        "    'min_samples_split': randint(5, 50),\n",
        "    'min_samples_leaf': randint(3, 30),\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': ['balanced', 'balanced_subsample'] + [{0: 1, 1: w} for w in [10, 12, 18, 21]],\n",
        "}\n",
        "\n",
        "# XGB Param Grid\n",
        "scale_pos_weight_calc = sum(y_train==0) / sum(y_train==1)\n",
        "xgb_param_grid = {\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'max_depth': randint(3, 7),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'min_child_weight': randint(7, 25),\n",
        "    'gamma': uniform(0.1, 0.5),\n",
        "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
        "    'reg_lambda': [0.1, 1, 5],\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'scale_pos_weight': [scale_pos_weight_calc]\n",
        "}\n",
        "\n",
        "# HGB Param Grid\n",
        "hgb_param_grid = {\n",
        "    'learning_rate': uniform(0.01, 0.15),\n",
        "    'max_iter': randint(100, 500),\n",
        "    'max_leaf_nodes': [None] + list(randint(15, 41).rvs(4)),\n",
        "    'max_depth': [None] + list(randint(4, 10).rvs(3)),\n",
        "    'min_samples_leaf': randint(10, 50),\n",
        "    'l2_regularization': uniform(0, 1.0),\n",
        "}"
      ],
      "metadata": {
        "id": "JsYRy5F2GtlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_param_grid_set = {\n",
        "    'learning_rate': [0.3],\n",
        "    'max_depth': [6],\n",
        "    'subsample': [1],\n",
        "    'colsample_bytree': [1],\n",
        "    'min_child_weight': [1],\n",
        "    'gamma': [0],\n",
        "    'reg_alpha': [0],\n",
        "    'reg_lambda': [1],\n",
        "    'n_estimators': [100],\n",
        "    # 'scale_pos_weight': [scale_pos_weight_calc] # Set calculated value\n",
        "}"
      ],
      "metadata": {
        "id": "ispXYGyz0KiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_tune_ratio = 0.6\n",
        "tune_end_index = int(len(y_final) * initial_tune_ratio)\n",
        "y_train_tune = y_final.iloc[:tune_end_index]\n",
        "\n",
        "RUN_RECURSIVE_LOOP = True\n",
        "\n",
        "best_params_found = {}\n",
        "models_to_tune = ['RandomForest', 'XGBoost', 'HGBoost']\n",
        "if RUN_RECURSIVE_LOOP:\n",
        "  for input_name in train_sets:\n",
        "    print(f\"\\n == Tuning for Input: {input_name} == \")\n",
        "    if input_name == \"Factors\":\n",
        "      X_train_tune_full = X_factors_lagged.iloc[:tune_end_index]\n",
        "    elif input_name == \"CBDI\":\n",
        "      X_train_tune_full = X_cbdi_lagged.iloc[:tune_end_index]\n",
        "    elif input_name == 'FBDI':\n",
        "      X_train_tune_full = X_fbdi_lagged.iloc[:tune_end_index]\n",
        "    elif input_name == 'FBDI_Recursive':\n",
        "      X_train_tune_full = X_fbdi_recursive_lagged.iloc[:tune_end_index]\n",
        "    else:\n",
        "      X_train_tune_full = X_full_lagged.iloc[:tune_end_index]\n",
        "\n",
        "    imputer_tune = KNNImputer(n_neighbors=5)\n",
        "    X_train_tune_imputed = imputer_tune.fit_transform(X_train_tune_full)\n",
        "    scaler_tune = StandardScaler()\n",
        "    X_train_tune_final = scaler_tune.fit_transform(X_train_tune_imputed)\n",
        "\n",
        "    best_params_found[input_name] = {}\n",
        "    for model_name in models_to_tune:\n",
        "      model_instance = models_to_run_defs[model_name]()\n",
        "      param_grid = rf_param_grid if model_name == 'RandomForest' else xgb_param_grid\n",
        "      if model_name == 'RandomForest':\n",
        "        param_grid = rf_param_grid\n",
        "      elif model_name == 'XGBoost':\n",
        "        if input_name == 'FBDI':\n",
        "          param_grid = xgb_param_grid_set\n",
        "        else:\n",
        "          param_grid = xgb_param_grid\n",
        "      else:\n",
        "        param_grid = hgb_param_grid\n",
        "      print(f\"Tuning {model_name} on {input_name}\")\n",
        "      if model_name == 'RandomForest' or model_name == 'HGBoost' or model_name == 'XGBoost':\n",
        "        random_search_tune = skm.RandomizedSearchCV(\n",
        "            estimator=model_instance,\n",
        "            param_distributions=param_grid,\n",
        "            n_iter=70,\n",
        "            cv=skm.TimeSeriesSplit(n_splits=3),\n",
        "            scoring='average_precision',\n",
        "            refit=False,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "      # else:\n",
        "      #   random_search_tune = skm.RandomizedSearchCV(\n",
        "      #       estimator=model_instance,\n",
        "      #       param_distributions=param_grid,\n",
        "      #       n_iter=70,\n",
        "      #       cv=skm.TimeSeriesSplit(n_splits=3),\n",
        "      #       scoring='average_precision',\n",
        "      #       refit=False,\n",
        "      #       random_state=42,\n",
        "      #       n_jobs=1\n",
        "      #   )\n",
        "      random_search_tune.fit(X_train_tune_final, y_train_tune)\n",
        "      best_params_found[input_name][model_name] = random_search_tune.best_params_\n",
        "      print(f\"    Best Params for {model_name} ({input_name}): {random_search_tune.best_params_}\")\n",
        "      print(f\"    Best CV Score: {random_search_tune.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "-RVeU2mHpkkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recursive Forecasting Loop"
      ],
      "metadata": {
        "id": "y7tr27PHuVs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits_recursive = int(len(y_final) * 0.4)\n",
        "evaluation_start_date = y_final.index[-n_splits_recursive]\n",
        "print(f\"Recursive evaluation period starting from: {evaluation_start_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"Using PRE-TUNED hyperparameters found on initial ~{(1-test_set_size)*100:.0f}% of data.\")\n",
        "\n",
        "predictor_sets = {\n",
        "    'Factors': X_factors_raw_final,\n",
        "    'CBDI': X_cbdi_raw_3state,\n",
        "    'Full': X_transformed_core,\n",
        "    'FBDI': X_fbdi_raw_rdsi,\n",
        "    'FBDI_Recursive': X_fbdi_raw_recursive,\n",
        "    'Yield': X_raw_spread\n",
        "}\n",
        "save_dir = \"/content/drive/MyDrive/Diffusion Indices/Final_Models_Joblib/\" # Separate folder maybe\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "arrays_path = os.path.join(save_dir, 'cached_outputs')  # For saving key arrays\n",
        "os.makedirs(arrays_path, exist_ok=True)\n",
        "\n",
        "\n",
        "oos_predictions = {input_name: {model_name: [] for model_name in models_to_run_defs} for input_name in predictor_sets}\n",
        "oos_probabilities = {input_name: {model_name: [] for model_name in models_to_run_defs} for input_name in predictor_sets}\n",
        "oos_target_indices = []\n",
        "final_model_importances = {}\n",
        "\n",
        "# if RUN_RECURSIVE_LOOP:\n",
        "#   oos_predictions = joblib.load(os.path.join(arrays_path, f'oos_predictions_{prediction_horizon}mo.joblib'))\n",
        "#   oos_probabilities = joblib.load(os.path.join(arrays_path, f'oos_probabilities_{prediction_horizon}mo.joblib'))\n",
        "#   final_model_importances = joblib.load(os.path.join(arrays_path, f'oos_final_model_importances_{prediction_horizon}mo.joblib'))\n",
        "#   oos_predictions['Yield'] = {model_name: [] for model_name in models_to_run_defs}\n",
        "#   oos_probabilities['Yield'] = {model_name: [] for model_name in models_to_run_defs}\n",
        "\n",
        "\n",
        "# Loop Start\n",
        "start_time_loop = time.time()\n",
        "forecast_points = y_final.loc[evaluation_start_date:].index\n",
        "if RUN_RECURSIVE_LOOP:\n",
        "  for i, current_forecast_date in enumerate(forecast_points):\n",
        "    is_last_iteration = (i == len(forecast_points)-1)\n",
        "    loop_step_start = time.time()\n",
        "    print(f\" Step {i+1}/{len(forecast_points)}: Forecasting for target date {current_forecast_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    current_date_iloc = y_final.index.get_loc(current_forecast_date)\n",
        "    train_end_iloc = current_date_iloc - 1\n",
        "    if train_end_iloc < 0: continue\n",
        "    train_end_date = y_final.index[train_end_iloc]\n",
        "\n",
        "    print(f\"  Training window ends: {train_end_date.strftime('%Y-%m-%d')}\")\n",
        "    y_train_current = y_final.loc[:train_end_date]\n",
        "\n",
        "    # Process input reps\n",
        "    for input_name, base_data_raw in predictor_sets.items():\n",
        "      print(f\"Processing Input: {input_name}\")\n",
        "\n",
        "      X_train_base_current = base_data_raw.loc[:train_end_date]\n",
        "      X_train_lagged_current = add_lags(X_train_base_current, lags_to_add)\n",
        "\n",
        "      # Preparing single row for prediction\n",
        "      X_predict_now = X_train_lagged_current.iloc[-1:]\n",
        "\n",
        "      # Preprocess specific training window\n",
        "      max_current_lag = max(lags_to_add) if lags_to_add else 0\n",
        "      longest_lag_col = f'{base_data_raw.columns[0]}_lag{max_current_lag}'\n",
        "      if longest_lag_col in X_train_lagged_current.columns:\n",
        "        first_valid_lag_idx = X_train_lagged_current[longest_lag_col].first_valid_index()\n",
        "      else:\n",
        "        if len(X_train_lagged_current) > max_current_lag:\n",
        "          first_valid_lag_idx = X_train_lagged_current.index[max_current_lag]\n",
        "        else:\n",
        "          first_valid_lag_idx = None\n",
        "\n",
        "      if first_valid_lag_idx is None:\n",
        "        print(f\"    Skipping {input_name} - training window too short for max lag ({len(X_train_lagged_current)} < {max_current_lag})\")\n",
        "        for model_name in models_to_run_defs:\n",
        "            oos_predictions[input_name][model_name].append(np.nan)\n",
        "            oos_probabilities[input_name][model_name].append(np.nan)\n",
        "        continue\n",
        "\n",
        "      X_train_current_valid_lags = X_train_lagged_current.loc[first_valid_lag_idx:]\n",
        "      y_train_current_aligned = y_train_current.loc[first_valid_lag_idx:]\n",
        "\n",
        "      if len(X_train_current_valid_lags) < 50: # Check minimum samples AFTER lag drop\n",
        "        print(f\"    Skipping {input_name} - insufficient data after lag drop ({len(X_train_current_valid_lags)})\")\n",
        "        for model_name in models_to_run_defs:\n",
        "            oos_predictions[input_name][model_name].append(np.nan)\n",
        "            oos_probabilities[input_name][model_name].append(np.nan)\n",
        "        continue\n",
        "\n",
        "      # Impute and scale\n",
        "      print(f\"     Window samples before imputation: {len(X_train_current_valid_lags)}, NaNs: {X_train_current_valid_lags.isna().sum().sum()}\")\n",
        "      current_imputer = KNNImputer(n_neighbors=5)\n",
        "      current_imputer.fit(X_train_current_valid_lags)\n",
        "      X_train_imp = current_imputer.transform(X_train_current_valid_lags)\n",
        "      X_predict_imp = current_imputer.transform(X_predict_now[X_train_current_valid_lags.columns])\n",
        "\n",
        "      current_scaler = StandardScaler()\n",
        "      X_train_scaled = current_scaler.fit_transform(X_train_imp)\n",
        "      X_predict_scaled = current_scaler.transform(X_predict_imp)\n",
        "      current_feature_names = X_train_current_valid_lags.columns\n",
        "\n",
        "      X_train_scaled_df = pd.DataFrame(X_train_scaled, index=y_train_current_aligned.index, columns=X_train_current_valid_lags.columns)\n",
        "\n",
        "      for model_name, model_constructor in models_to_run_defs.items():\n",
        "        current_best_params = best_params_found.get(input_name, {}).get(model_name, None)\n",
        "        if current_best_params is None and model_name in models_to_tune:\n",
        "          print(f\"     Skipping {model_name} on {input_name}: No best parameters found.\")\n",
        "          oos_predictions[input_name][model_name].append(np.nan)\n",
        "          oos_probabilities[input_name][model_name].append(np.nan)\n",
        "          continue\n",
        "\n",
        "        print(f\"Training {model_name}...\")\n",
        "        if model_name in models_to_tune:\n",
        "          model_instance = model_constructor().set_params(**current_best_params)\n",
        "        else:\n",
        "          model_instance = model_constructor()\n",
        "        model_instance.fit(X_train_scaled_df, y_train_current_aligned)\n",
        "\n",
        "        # Make prediction\n",
        "        pred_proba = model_instance.predict_proba(X_predict_scaled)[:, 1][0]\n",
        "        pred_label = model_instance.predict(X_predict_scaled)[0]\n",
        "\n",
        "        # Store\n",
        "        oos_predictions[input_name][model_name].append(pred_label)\n",
        "        oos_probabilities[input_name][model_name].append(pred_proba)\n",
        "\n",
        "        if is_last_iteration:\n",
        "          print(f\"    Storing importance/coeffs for FINAL model ({input_name}/{model_name})...\")\n",
        "          if isinstance(model_instance, LogisticRegression):\n",
        "            if hasattr(model_instance, 'coef_'):\n",
        "              coefs = model_instance.coef_[0]\n",
        "              if len(current_feature_names) == len(coefs):\n",
        "                final_model_importances[(input_name, model_name)] = pd.Series(coefs, index=current_feature_names)\n",
        "              else: print(f\"      WARN: Coef/Feature length mismatch for {model_name}\")\n",
        "            else: print(f\"      WARN: Could not get coef_ for {model_name}\")\n",
        "          elif hasattr(model_instance, 'feature_importances_'):\n",
        "            imps = model_instance.feature_importances_\n",
        "            if len(current_feature_names) == len(imps):\n",
        "              final_model_importances[(input_name, model_name)] = pd.Series(imps, index=current_feature_names)\n",
        "            else: print(f\"      WARN: Importance/Feature length mismatch for {model_name}\")\n",
        "          else:\n",
        "            print(f\"      WARN: Could not get feature_importances_ for {model_name}\")\n",
        "\n",
        "          model_filename = f\"{save_dir}model_{input_name}_{model_name}_{prediction_horizon}mo_final.joblib\"\n",
        "          joblib.dump(model_instance, model_filename)\n",
        "          print(f\"    Saved final model to {model_filename}\")\n",
        "          # joblib.dump(oos_predictions, os.path.join(arrays_path, f'oos_predictions_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # joblib.dump(oos_probabilities, os.path.join(arrays_path, f'oos_probabilities_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # joblib.dump(oos_target_indices, os.path.join(arrays_path, f'oos_target_indices_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # joblib.dump(final_model_importances, os.path.join(arrays_path, f'oos_final_model_importances_{input_name}_{model_name}_{prediction_horizon}mo.joblib'))\n",
        "          # print(\"Saved prediction arrays.\")\n",
        "\n",
        "\n",
        "\n",
        "    oos_target_indices.append(current_forecast_date)\n",
        "    print(f\"   Step {i+1} finished. Time: {(time.time() - loop_step_start):.2f}s\")\n",
        "    print(f\"\\n--- Recursive Loop Finished --- Total time: {(time.time() - start_time_loop)/60:.2f} minutes ---\")\n",
        "  joblib.dump(oos_predictions, os.path.join(arrays_path, f'oos_predictions_yield_{prediction_horizon}mo.joblib'))\n",
        "  joblib.dump(oos_probabilities, os.path.join(arrays_path, f'oos_probabilities_yield_{prediction_horizon}mo.joblib'))\n",
        "  joblib.dump(oos_target_indices, os.path.join(arrays_path, f'oos_target_indices_yield_{prediction_horizon}mo.joblib'))\n",
        "  joblib.dump(final_model_importances, os.path.join(arrays_path, f'oos_final_model_importances_yield_{prediction_horizon}mo.joblib'))\n",
        "  print(\"Saved prediction arrays.\")\n",
        "else:\n",
        "  print(\"Skipping recursive loop. Loading saved prediction arrays...\")\n",
        "  oos_predictions = joblib.load(os.path.join(arrays_path, f'oos_predictions_yield_{prediction_horizon}mo.joblib'))\n",
        "  oos_probabilities = joblib.load(os.path.join(arrays_path, f'oos_probabilities_yield_{prediction_horizon}mo.joblib'))\n",
        "  oos_target_indices = joblib.load(os.path.join(arrays_path, f'oos_target_indices_yield_{prediction_horizon}mo.joblib'))\n",
        "  final_model_importances = joblib.load(os.path.join(arrays_path, f'oos_final_model_importances_yield_{prediction_horizon}mo.joblib'))\n",
        "  print(\"Loaded prediction arrays.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VBWcjsHYtecs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_importances"
      ],
      "metadata": {
        "id": "e3fqRJZRrg-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Feature Importances / Coefficients from FINAL Recursive Models ---\")\n",
        "for (input_name, model_name), importance_series in final_model_importances.items():\n",
        "  print(f\"\\n=== Input: {input_name}, Model: {model_name} ===\")\n",
        "  if model_name == \"Logit\" or \"Logit\" in model_name:\n",
        "    coef_df = pd.DataFrame({'Coefficient': importance_series})\n",
        "    coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
        "    coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "    print(\"   Top 15 Coefficients (Absolute Value):\")\n",
        "    print(coef_df[['Coefficient']].head(15).to_string())\n",
        "  else:\n",
        "    imp_df = pd.DataFrame({'Importance': importance_series})\n",
        "    imp_df = imp_df.sort_values(by='Importance', ascending=False)\n",
        "    print(\"   Top 15 Feature Importances:\")\n",
        "    print(imp_df.head(15).to_string())"
      ],
      "metadata": {
        "id": "GK8C2oiRF8oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Evaluation"
      ],
      "metadata": {
        "id": "dL-Qi52U7L-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Evaluating Out-of-Sample Performance ---\")\n",
        "oos_target = y_final.loc[oos_target_indices]\n",
        "\n",
        "final_evaluation_dfs = {}\n",
        "all_metrics_list = []\n",
        "\n",
        "for input_name in oos_predictions:\n",
        "  print(f\"Evaluating Input Set: {input_name}\")\n",
        "  evaluation_results_rec = {}\n",
        "\n",
        "  for model_name in oos_predictions[input_name]:\n",
        "    y_pred_oos_list = oos_predictions[input_name][model_name]\n",
        "    y_proba_oos_list = oos_probabilities[input_name][model_name]\n",
        "    y_pred_oos = np.array(y_pred_oos_list)\n",
        "    y_proba_oos = np.array(y_proba_oos_list)\n",
        "    # Find only successful predictions (no errors)\n",
        "    valid_idx = ~np.isnan(y_proba_oos) & ~np.isnan(y_pred_oos)\n",
        "\n",
        "    y_test_eval = oos_target[valid_idx].values\n",
        "    y_pred_eval = y_pred_oos[valid_idx]\n",
        "    y_proba_eval = y_proba_oos[valid_idx]\n",
        "\n",
        "    print(f\"\\n  Model: {model_name} ({sum(valid_idx)} / {len(oos_target)} valid forecasts)\")\n",
        "    if sum(valid_idx) == 0 or len(y_test_eval) == 0:\n",
        "      print(\"    No valid OOS predictions to evaluate.\")\n",
        "      results_rec = {'PR AUC': np.nan, 'Recall (1)': np.nan, 'Precision (1)': np.nan, 'F1 (1)': np.nan, 'ROC AUC': np.nan, 'Brier Score': np.nan, 'Confusion Matrix': 'N/A'}\n",
        "      evaluation_results_rec[model_name] = results_rec\n",
        "      continue\n",
        "\n",
        "    results_rec = {}\n",
        "    try:\n",
        "      cm_rec = confusion_matrix(y_test_eval, y_pred_eval)\n",
        "      results_rec['Confusion Matrix'] = cm_rec\n",
        "      print(f\"    Confusion Matrix (0.5 Thr):\\n{cm_rec}\")\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating CM: {e}\")\n",
        "      results_rec['Confusion Matrix'] = 'Error'\n",
        "\n",
        "    try:\n",
        "      target_names = ['Non-Recession (0)', 'Recession (1)']\n",
        "      report_str = classification_report(y_test_eval, y_pred_eval, target_names=target_names, zero_division=0)\n",
        "      print(f\"    Classification Report (0.5 Thr):\\n{report_str}\")\n",
        "      cr_dict = classification_report(y_test_eval, y_pred_eval, output_dict=True, zero_division=0)\n",
        "      results_rec['Recall (1)'] = cr_dict.get('1.0', {}).get('recall', 0)\n",
        "      results_rec['Precision (1)'] = cr_dict.get('1.0', {}).get('precision', 0)\n",
        "      results_rec['F1 (1)'] = cr_dict.get('1.0', {}).get('f1-score', 0)\n",
        "      print(f\"      -> Recall(1): {results_rec['Recall (1)']:.3f}, Precision(1): {results_rec['Precision (1)']:.3f}, F1(1): {results_rec['F1 (1)']:.3f}\")\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating Classification Report: {e}\")\n",
        "      results_rec['Recall (1)'] = np.nan; results_rec['Precision (1)'] = np.nan; results_rec['F1 (1)'] = np.nan\n",
        "\n",
        "    try:\n",
        "      results_rec['ROC AUC'] = roc_auc_score(y_test_eval, y_proba_eval)\n",
        "      print(f\"      -> ROC AUC: {results_rec['ROC AUC']:.3f}\")\n",
        "    except ValueError:\n",
        "      print(\"    ROC AUC cannot be computed (likely only one class in evaluation period).\")\n",
        "      results_rec['ROC AUC'] = np.nan\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating ROC AUC: {e}\")\n",
        "      results_rec['ROC AUC'] = np.nan\n",
        "\n",
        "    try:\n",
        "      results_rec['PR AUC'] = average_precision_score(y_test_eval, y_proba_eval)\n",
        "      print(f\"      -> PR AUC (Avg Precision): {results_rec['PR AUC']:.3f}\")\n",
        "    except ValueError:\n",
        "      print(\"    PR AUC cannot be computed (likely only one class in evaluation period).\")\n",
        "      results_rec['PR AUC'] = np.nan\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating PR AUC: {e}\")\n",
        "      results_rec['PR AUC'] = np.nan\n",
        "\n",
        "    try:\n",
        "      results_rec['Brier Score'] = brier_score_loss(y_test_eval, y_proba_eval)\n",
        "      print(f\"      -> Brier Score: {results_rec['Brier Score']:.3f}\")\n",
        "    except Exception as e:\n",
        "      print(f\"    Error calculating Brier Score: {e}\")\n",
        "      results_rec['Brier Score'] = np.nan\n",
        "\n",
        "    evaluation_results_rec[model_name] = results_rec\n",
        "\n",
        "    # Add results to the combined list for the summary table\n",
        "    row = {\n",
        "          'Input': input_name, 'Model': model_name,\n",
        "          'PR AUC': results_rec.get('PR AUC'), 'ROC AUC': results_rec.get('ROC AUC'),\n",
        "          'Recall (1)': results_rec.get('Recall (1)'), 'Precision (1)': results_rec.get('Precision (1)'),\n",
        "          'F1 (1)': results_rec.get('F1 (1)'), 'Brier Score': results_rec.get('Brier Score'),\n",
        "          'Num Forecasts': sum(valid_idx)\n",
        "          }\n",
        "    all_metrics_list.append(row)"
      ],
      "metadata": {
        "id": "NgTy5Wef7InO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(oos_target_indices):\", len(oos_target_indices))\n",
        "print(\"len(oos_target):\", len(oos_target))\n",
        "print(\"len(y_pred_oos):\", len(y_pred_oos))\n",
        "print(\"len(y_proba_oos):\", len(y_proba_oos))\n",
        "print(\"len(valid_idx):\", len(valid_idx))"
      ],
      "metadata": {
        "id": "SuFluAhJdshQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display Results"
      ],
      "metadata": {
        "id": "6S3XwMID9zHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Final Recursive Evaluation Summary (Default 0.5 Threshold) ---\")\n",
        "if all_metrics_list:\n",
        "  results_df_rec = pd.DataFrame(all_metrics_list).round(4)\n",
        "  if 'Confusion Matrix' in results_df_rec.columns:\n",
        "    results_df_rec = results_df_rec.drop(columns=['Confusion Matrix'])\n",
        "  results_df_rec = results_df_rec.set_index(['Input', 'Model'])\n",
        "  print(results_df_rec.sort_values(by='PR AUC', ascending=False)) # Sort by PR AUC\n",
        "else:\n",
        "  print(\"No final recursive evaluation results generated to display.\")"
      ],
      "metadata": {
        "id": "pzKBJanr9yf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_COLORS = {\n",
        "    'Logit': 'red',\n",
        "    'Logit_L2': 'orange',\n",
        "    'RandomForest': 'blue',\n",
        "    'XGBoost': 'green',\n",
        "    'HGBoost': 'brown'\n",
        "\n",
        "}\n",
        "DEFAULT_COLOR = 'grey'\n",
        "\n",
        "\n",
        "print(\"\\n--- Plotting Out-of-Sample Precision-Recall Curves (One Plot Per Input Set) ---\")\n",
        "\n",
        "# Calculate No-Skill line based on full OOS target prevalence\n",
        "if len(oos_target) > 0:\n",
        "    no_skill_level = oos_target.mean()\n",
        "else:\n",
        "    no_skill_level = 0.5\n",
        "\n",
        "for input_name in predictor_sets.keys():\n",
        "    print(f\"\\n--- Generating PR Curve Plot for Input Set: {input_name} ---\")\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.set_title(f\"OOS Precision-Recall Curve - Input: {input_name}\")\n",
        "\n",
        "    if input_name not in oos_probabilities:\n",
        "         print(f\"  Skipping {input_name}: No probabilities found.\")\n",
        "         plt.close(fig)\n",
        "         continue\n",
        "\n",
        "    models_to_plot = oos_probabilities[input_name]\n",
        "    plot_count = 0\n",
        "\n",
        "\n",
        "    ax.plot([0, 1], [no_skill_level, no_skill_level], linestyle='--',\n",
        "            label=f'No Skill ({no_skill_level:.2f})', color='grey', alpha=0.7)\n",
        "\n",
        "\n",
        "    for model_name, y_proba_list in models_to_plot.items():\n",
        "        y_proba_raw = np.array(y_proba_list)\n",
        "\n",
        "\n",
        "        valid_idx_plot = ~np.isnan(y_proba_raw)\n",
        "        if sum(valid_idx_plot) == 0:\n",
        "            print(f\"  Skipping {model_name}: No valid probabilities.\")\n",
        "            continue\n",
        "\n",
        "        y_test_eval_plot = oos_target[valid_idx_plot].values\n",
        "        y_proba_eval_plot = y_proba_raw[valid_idx_plot]\n",
        "\n",
        "\n",
        "        if len(np.unique(y_test_eval_plot)) <= 1:\n",
        "            print(f\"  Skipping {model_name}: Only one class present in valid OOS target slice.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate PR AUC to include in label\n",
        "        try:\n",
        "             pr_auc = average_precision_score(y_test_eval_plot, y_proba_eval_plot)\n",
        "             model_label = f'{model_name}'\n",
        "        except Exception:\n",
        "             pr_auc = np.nan\n",
        "             model_label = f'{model_name} (AUC=N/A)'\n",
        "\n",
        "\n",
        "        # Plot PR curve using from_predictions\n",
        "        try:\n",
        "            color = MODEL_COLORS.get(model_name, DEFAULT_COLOR) # Get consistent color\n",
        "            pr_display = PrecisionRecallDisplay.from_predictions(\n",
        "                y_test_eval_plot,\n",
        "                y_proba_eval_plot,\n",
        "                name=model_label, # Add AUC to the label\n",
        "                ax=ax,            # Plot on the CURRENT axes      # Use defined color\n",
        "                lw=2,             # Line width\n",
        "                alpha=0.8         # Transparency\n",
        "            )\n",
        "            plot_count += 1\n",
        "        except ValueError as ve:\n",
        "             if \"contains only one label\" in str(ve):\n",
        "                 print(f\"  Skipping {model_name}: Only one class value present in predictions for plotting (possibly constant probability).\")\n",
        "             else:\n",
        "                 print(f\"  Error plotting PR curve for {model_name}: {ve}\")\n",
        "        except Exception as e:\n",
        "             print(f\"  Error plotting PR curve for {model_name}: {e}\")\n",
        "\n",
        "\n",
        "    # Finalize plot\n",
        "    if plot_count > 0:\n",
        "        ax.grid(True, linestyle=':', alpha=0.6)\n",
        "        ax.legend(loc='lower right', fontsize='small')\n",
        "    else:\n",
        "         ax.text(0.5, 0.5, 'No valid data to plot', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "\n",
        "    ax.set_xlabel(\"Recall\")\n",
        "    ax.set_ylabel(\"Precision\")\n",
        "    ax.set_xlim([-0.05, 1.05])\n",
        "    ax.set_ylim([-0.05, 1.05])\n",
        "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
        "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "    plt.tight_layout()\n",
        "    fig_save_path = os.path.join(\"/content/drive/MyDrive/Diffusion Indices/Visuals/\", f'PR_Curve_{input_name}_{prediction_horizon}mo.png')\n",
        "    plt.savefig(fig_save_path, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- Finished Plotting PR Curves ---\")"
      ],
      "metadata": {
        "id": "8dSK3pxF97Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating Prediction vs Actual DataFrame ---\")\n",
        "graph_folder = \"/content/drive/MyDrive/Diffusion Indices/Visuals/\"\n",
        "\n",
        "def visualize(chosen_input, chosen_model, aligned=False, save=True):\n",
        "  comparison_df = pd.DataFrame({'Actual': oos_target})\n",
        "\n",
        "  if chosen_input in oos_predictions and chosen_model in oos_predictions[chosen_input]:\n",
        "    pred_list = oos_predictions[chosen_input][chosen_model]\n",
        "    proba_list = oos_probabilities[chosen_input][chosen_model]\n",
        "\n",
        "\n",
        "    if len(pred_list) == len(oos_target_indices) and len(proba_list) == len(oos_target_indices):\n",
        "      comparison_df[f'{chosen_model}_Pred'] = pd.Series(pred_list, index=oos_target_indices)\n",
        "      comparison_df[f'{chosen_model}_Proba'] = pd.Series(proba_list, index=oos_target_indices)\n",
        "      print(f\" Added predictions/probabilities for {chosen_model} on {chosen_input}.\")\n",
        "    else:\n",
        "      print(f\"WARNING: Length mismatch for {model_name} on {input_name}. Cannot add to comparison.\")\n",
        "      print(f\"  Expected length: {len(oos_target_indices)}, Pred length: {len(pred_list)}, Proba length: {len(proba_list)}\")\n",
        "\n",
        "\n",
        "  else:\n",
        "    print(f\"WARNING: Could not find results for Input='{chosen_input}', Model='{chosen_model}'\")\n",
        "\n",
        "\n",
        "  print(\"\\nComparison DataFrame (Actual vs Predicted [0.5 Thr] vs Probability):\")\n",
        "  print(comparison_df.head(20))\n",
        "  print(\"...\")\n",
        "  print(comparison_df.tail(20))\n",
        "\n",
        "  print(\"\\n--- Analyzing Misclassifications ---\")\n",
        "  if f'{chosen_model}_Pred' in comparison_df.columns:\n",
        "    misclassified = comparison_df[comparison_df['Actual'] != comparison_df[f'{chosen_model}_Pred']]\n",
        "    false_positives = misclassified[misclassified['Actual'] == 0]\n",
        "    false_negatives = misclassified[misclassified['Actual'] == 1]\n",
        "\n",
        "    print(f\"\\nTotal Misclassified ({chosen_model} on {chosen_input}): {len(misclassified)}\")\n",
        "\n",
        "    print(f\"\\nFalse Positives (Predicted 1, Actual 0): {len(false_positives)}\")\n",
        "    if not false_positives.empty:\n",
        "      print(false_positives.sort_index())\n",
        "\n",
        "    print(f\"\\nFalse Negatives (Predicted 0, Actual 1): {len(false_negatives)}\")\n",
        "    if not false_negatives.empty:\n",
        "      print(false_negatives.sort_index())\n",
        "\n",
        "\n",
        "  print(\"\\\\n--- Plotting Predictions Over Time ---\")\n",
        "  if f'{chosen_model}_Proba' in comparison_df.columns:\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "    plot_start_date = min(oos_target_indices)\n",
        "    plot_end_date = max(oos_target_indices)\n",
        "\n",
        "\n",
        "    y_raw_plot_period = y_raw.loc[plot_start_date : plot_end_date + pd.DateOffset(months=1)] # Ensure we cover the end date\n",
        "\n",
        "    nber_recession_dates = y_raw_plot_period[y_raw_plot_period == 1].index\n",
        "    start_shade = None\n",
        "    first_label = True\n",
        "    for date in y_raw_plot_period.index:\n",
        "      is_rec = date in nber_recession_dates\n",
        "      if is_rec and start_shade is None:\n",
        "        start_shade = date\n",
        "      elif not is_rec and start_shade is not None:\n",
        "        end_shade = date\n",
        "        ax.axvspan(start_shade, end_shade,\n",
        "                    color='red', alpha=0.2, label='Actual Recession (NBER)' if first_label else \"\")\n",
        "        start_shade = None\n",
        "        first_label=False\n",
        "    if start_shade is not None:\n",
        "      ax.axvspan(start_shade, plot_end_date + pd.DateOffset(months=1), color='red', alpha=0.2, label='Actual Recession (NBER)' if first_label else \"\")\n",
        "\n",
        "\n",
        "    if aligned:\n",
        "      ax.plot(comparison_df.index + pd.DateOffset(months=prediction_horizon), comparison_df[f'{chosen_model}_Proba'], label=f'{chosen_model} Prob (Predicting t + {prediction_horizon}mo)', color='blue', alpha=0.8)\n",
        "    else:\n",
        "      ax.plot(comparison_df.index, comparison_df[f'{chosen_model}_Proba'], label=f'{chosen_model} Prob (Predicting t + 3mo)', color='blue', alpha=0.8)\n",
        "\n",
        "\n",
        "    ax.axhline(0.5, color='grey', linestyle='--', label='0.5 Threshold', alpha=0.7)\n",
        "\n",
        "\n",
        "    tuned_threshold = results_df_tuned.loc[chosen_input].loc[chosen_model]['Threshold'] # Default if not found\n",
        "\n",
        "\n",
        "\n",
        "    nber_starts = y_raw_plot_period[(y_raw_plot_period == 1) & (y_raw_plot_period.shift(1) == 0)].index\n",
        "\n",
        "\n",
        "    if not aligned:\n",
        "      nber_start_2001 = nber_starts[nber_starts.year == 2001][0]\n",
        "      pred_peak_date_2001 = comparison_df.loc[:nber_start_2001, f'{chosen_model}_Proba'].idxmax() # Find peak BEFORE start\n",
        "      pred_peak_val_2001 = comparison_df.loc[pred_peak_date_2001, f'{chosen_model}_Proba']\n",
        "      if pd.notna(nber_start_2001) and pd.notna(pred_peak_date_2001):\n",
        "        ax.annotate('Forecast Peak\\n(Predicting 3mo Ahead)', xy=(pred_peak_date_2001, pred_peak_val_2001),\n",
        "                    xytext=(pred_peak_date_2001 - pd.DateOffset(years=1), pred_peak_val_2001 + 0.1),\n",
        "                    arrowprops=dict(facecolor='green', shrink=0.05, alpha=0.7),\n",
        "                    fontsize=9, color='green')\n",
        "        ax.annotate('Actual Start', xy=(nber_start_2001, 0.05), # Point near bottom\n",
        "                    xytext=(nber_start_2001 + pd.DateOffset(months=6), 0.15),\n",
        "                    arrowprops=dict(facecolor='red', shrink=0.05, alpha=0.7),\n",
        "                    fontsize=9, color='red')\n",
        "\n",
        "\n",
        "    ax.set_ylabel(f'Recession Probability (Predicted for t + {prediction_horizon} Months)')\n",
        "    ax.set_xlabel('Date (Prediction Made at Time t)') # Clarify axis meaning\n",
        "    ax.set_title(f'NBER Recessions vs. Predicted Probability ({chosen_model} on {chosen_input})')\n",
        "\n",
        "    # Adjust legend position if needed\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    # Filter out duplicate labels if NBER span triggered multiple times\n",
        "    unique_labels = {}\n",
        "    for handle, label in zip(handles, labels):\n",
        "      if label not in unique_labels:\n",
        "        unique_labels[label] = handle\n",
        "    ax.legend(unique_labels.values(), unique_labels.keys(), loc='upper right', frameon=True)\n",
        "\n",
        "\n",
        "    ax.grid(True, axis='y', linestyle=':')\n",
        "    ax.set_xlim(plot_start_date, plot_end_date) # Ensure plot range matches evaluation\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "      if aligned:\n",
        "        plt.savefig(f'{graph_folder}{chosen_model}_{chosen_input}_{prediction_horizon}mo_aligned.png')\n",
        "      else:\n",
        "        plt.savefig(f'{graph_folder}{chosen_model}_{chosen_input}_{prediction_horizon}mo.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  else:\n",
        "      print(\"Could not plot - probabilities not found.\")\n",
        "\n",
        "# for input in ['Factors', 'CBDI', 'Full', 'FBDI', 'FBDI_Recursive', 'Yield']:\n",
        "#   for model in ['Logit', 'Logit_L2', 'RandomForest', 'XGBoost', 'HGBoost']:\n",
        "visualize('CBDI', 'HGBoost', aligned=True, save=False)\n"
      ],
      "metadata": {
        "id": "bqrbyz8eogcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_tuned"
      ],
      "metadata": {
        "id": "ca7CBegTFm7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics_df = pd.DataFrame(all_metrics_list)"
      ],
      "metadata": {
        "id": "eouZDX7_08z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Preparing data for bar chart ---\")\n",
        "plot_data = []\n",
        "\n",
        "input_order_plot1 = ['CBDI']\n",
        "model_order = ['RandomForest', 'XGBoost', 'HGBoost']\n",
        "all_inputs_ordered = input_order_plot1\n",
        "\n",
        "\n",
        "models_present = set()\n",
        "for input_name in all_inputs_ordered:\n",
        "    if input_name in results_df_rec.index.get_level_values(0):\n",
        "        models_present.update(results_df_rec.loc[input_name].index)\n",
        "\n",
        "print(f\"Input Sets to Plot: {all_inputs_ordered}\")\n",
        "print(f\"Models to Plot: {model_order}\")\n",
        "\n",
        "# Extract data\n",
        "for input_name in all_inputs_ordered:\n",
        "     if input_name in results_df_rec.index.get_level_values(0):\n",
        "         for model_name in model_order:\n",
        "\n",
        "             pr_auc = results_df_rec.loc[input_name].loc[model_name]['PR AUC']\n",
        "             plot_group = 1 if input_name in input_order_plot1 else 2\n",
        "             plot_data.append({'Input Set': input_name,\n",
        "                               'Model': model_name,\n",
        "                               'PR AUC': pr_auc,\n",
        "                               'Plot Group': plot_group})\n",
        "\n",
        "# Convert to DataFrame\n",
        "plot_df_full = pd.DataFrame(plot_data)\n",
        "plot_df_full.dropna(subset=['PR AUC'], inplace=True) # Drop if metric is missing\n",
        "\n",
        "# Ensure categorical order for plots\n",
        "plot_df_full['Input Set'] = pd.Categorical(plot_df_full['Input Set'], categories=all_inputs_ordered, ordered=True)\n",
        "plot_df_full['Model'] = pd.Categorical(plot_df_full['Model'], categories=model_order, ordered=True)\n",
        "\n",
        "print(\"\\nPrepared DataFrame for plotting (first few rows):\")\n",
        "print(plot_df_full.head())\n",
        "\n",
        "\n",
        "print(\"\\n--- Generating Bar Charts (Split) ---\")\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "num_models_plot = len(plot_df_full['Model'].unique())\n",
        "try:\n",
        "    if num_models_plot <= 10: palette_name = 'viridis' # Viridis often good contrast\n",
        "    elif num_models_plot <= 20: palette_name = 'tab20'\n",
        "    else: palette_name = 'viridis'\n",
        "    palette = sns.color_palette(palette_name, n_colors=num_models_plot)\n",
        "except Exception as e:\n",
        "    palette = sns.color_palette(n_colors=num_models_plot)\n",
        "\n",
        "\n",
        "for plot_num in [1, 2]:\n",
        "    print(f\"\\n Generating Plot {plot_num}...\")\n",
        "    plot_df_subset = plot_df_full[plot_df_full['Plot Group'] == plot_num].copy()\n",
        "\n",
        "    if plot_df_subset.empty:\n",
        "         print(f\" No data for Plot {plot_num}. Skipping.\")\n",
        "         continue\n",
        "\n",
        "    input_sets_in_plot = plot_df_subset['Input Set'].unique().tolist()\n",
        "\n",
        "\n",
        "    fig_width = max(8, 2.5 * len(input_sets_in_plot))\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, 7))\n",
        "\n",
        "\n",
        "    barplot = sns.barplot(x='Input Set', y='PR AUC', hue='Model',\n",
        "                          data=plot_df_subset, palette=palette, ax=ax, errorbar=None)\n",
        "\n",
        "\n",
        "    for container in ax.containers:\n",
        "        try:\n",
        "             ax.bar_label(container, fmt='%.3f', fontsize=8, padding=3, rotation=0)\n",
        "        except Exception as e:\n",
        "             print(f\" Warning: Could not add bar labels - {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    ax.set_title(f'Out-of-Sample Precision-Recall AUC (h={prediction_horizon} Months)', fontsize=14, pad=15)\n",
        "    ax.set_xlabel('Input Data Representation', fontsize=12, labelpad=10)\n",
        "    ax.set_ylabel('Average Precision (PR AUC)', fontsize=12, labelpad=10)\n",
        "    ax.tick_params(axis='x', rotation=0, labelsize=11)\n",
        "    ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1.01, 0.5), fontsize='medium', title='Model')\n",
        "\n",
        "\n",
        "    min_auc = max(0, plot_df_subset['PR AUC'].min() - 0.05)\n",
        "    max_auc = min(1, plot_df_subset['PR AUC'].max() + 0.05)\n",
        "    if max_auc - min_auc < 0.1:\n",
        "         min_auc = max(0, min_auc - 0.05)\n",
        "         max_auc = min(1, max_auc + 0.05)\n",
        "    ax.set_ylim(min_auc, max_auc)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 0.88, 0.95])\n",
        "\n",
        "\n",
        "    graph_folder = '/content/drive/MyDrive/Diffusion Indices/Visuals/'\n",
        "    os.makedirs(graph_folder, exist_ok=True)\n",
        "    save_path = os.path.join(graph_folder, f'PR_AUC_Comparison_BarChart_Plot{plot_num}_CBDI_h{prediction_horizon}.png')\n",
        "    try:\n",
        "        plt.savefig(save_path, dpi=500)\n",
        "        print(f\" Saved Bar Chart Plot {plot_num} to: {save_path}\")\n",
        "    except Exception as e:\n",
        "         print(f\" ERROR saving Bar Chart Plot {plot_num}: {e}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NDiUaPl1KDdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_for_avg = ['Logit', 'Logit_L2']\n",
        "metrics_to_avg = ['PR AUC']\n",
        "\n",
        "\n",
        "filtered_results = results_df_rec[results_df_rec.index.get_level_values('Model').isin(models_for_avg)]\n",
        "\n",
        "\n",
        "avg_performance = filtered_results.groupby(level='Input')[metrics_to_avg].mean().round(3)\n",
        "avg_performance = avg_performance.sort_values(by='PR AUC', ascending=False)\n",
        "\n",
        "print(\"\\\\n--- Average Performance Across Top Models ---\")\n",
        "avg_performance"
      ],
      "metadata": {
        "id": "4sHjRaBx8HJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRIC_TO_PLOT_HM = 'PR AUC'\n",
        "PLOT_TITLE_HM = f'Model Performance Heatmap ({METRIC_TO_PLOT_HM})'\n",
        "\n",
        "if METRIC_TO_PLOT_HM not in results_df_tuned.columns:\n",
        "  print(f\"ERROR: Metric '{METRIC_TO_PLOT_HM}' not found in results DataFrame columns.\")\n",
        "  exit()\n",
        "\n",
        "\n",
        "try:\n",
        "  heatmap_data = results_df_tuned[METRIC_TO_PLOT_HM].unstack(level='Model')\n",
        "  model_order = ['Logit', 'Logit_L2', 'RandomForest', 'XGBoost', 'HGBoost']\n",
        "  input_order = ['Yield', 'Factors', 'Full', 'CBDI', 'FBDI', 'FBDI_Recursive']\n",
        "  models_present = [m for m in model_order if m in heatmap_data.columns]\n",
        "  inputs_present = [i for i in input_order if i in heatmap_data.index]\n",
        "  heatmap_data = heatmap_data.loc[inputs_present, models_present]\n",
        "  print(\"\\nPivoted DataFrame for Heatmap:\")\n",
        "  print(heatmap_data)\n",
        "except KeyError as e:\n",
        "  print(f\"ERROR unstacking DataFrame, potentially missing combinations or incorrect index levels: {e}\")\n",
        "  exit()\n",
        "except Exception as e:\n",
        "  print(f\"Error preparing heatmap data: {e}\")\n",
        "  exit()\n",
        "\n",
        "if heatmap_data.empty:\n",
        "  print(\"ERROR: No data available for heatmap after pivoting/filtering.\")\n",
        "  exit()\n",
        "\n",
        "print(\"\\n--- Generating Heatmap ---\")\n",
        "\n",
        "\n",
        "num_rows = len(heatmap_data.index)\n",
        "num_cols = len(heatmap_data.columns)\n",
        "fig_width = max(8, 1.5 * num_cols)\n",
        "fig_height = max(6, 0.8 * num_rows)\n",
        "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "cmap_heatmap = \"viridis\"\n",
        "\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    annot=True,\n",
        "    fmt=\".3f\",\n",
        "    linewidths=.5,\n",
        "    cmap=cmap_heatmap,\n",
        "    ax=ax,\n",
        "    cbar_kws={'label': METRIC_TO_PLOT_HM},\n",
        "    annot_kws={\"size\": 9}\n",
        ")\n",
        "\n",
        "\n",
        "ax.set_title(PLOT_TITLE_HM, fontsize=14, pad=15)\n",
        "ax.set_xlabel('Model', fontsize=12)\n",
        "ax.set_ylabel('Input Data Representation', fontsize=12)\n",
        "ax.tick_params(axis='x', labelsize=10, rotation=45, ha='right')\n",
        "ax.tick_params(axis='y', labelsize=10, rotation=0)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "\n",
        "\n",
        "graph_folder = '/content/drive/MyDrive/Diffusion Indices/Visuals/'\n",
        "os.makedirs(graph_folder, exist_ok=True)\n",
        "save_path = os.path.join(graph_folder, f'{METRIC_TO_PLOT_HM.replace(\" \",\"\")}_Comparison_Heatmap_h{prediction_horizon}.png')\n",
        "try:\n",
        "  # plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "  print(f\"\\nSaved Heatmap to: {save_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR saving Heatmap: {e}\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x5DHBbvTq5Uz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}